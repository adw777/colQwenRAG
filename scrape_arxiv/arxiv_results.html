<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/1.0.0a5/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/1.0.0a5/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/1.0.0a5/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>

  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/1.0.0a5/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><span id="support-ack-url">We gratefully acknowledge support from<br /> the Simons Foundation, <a href="https://info.arxiv.org/about/ourmembers.html">member institutions</a>, and all contributors. <a href="https://info.arxiv.org/about/donate.html">Donate</a></span></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo">
        <img src="https://static.arxiv.org/static/base/1.0.0a5/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;"/>
      </a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://info.arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;178 of 178 results for all: <span class="mathjax">AI in Legal Analysis</span>
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
    </div>
  </div>
    <div class="content">
      
  <form method="GET" action="/search/"  aria-role="search">
    

    
    <div class="field has-addons-tablet">
      <div class="control is-expanded">
        <label for="query" class="hidden-label">Search term or terms</label>
        
          <input class="input is-medium" id="query" name="query" placeholder="Search term..." type="text" value="AI in Legal Analysis">
        
        
      </div>
      <div class="select control is-medium">
        <label class="is-hidden" for="searchtype">Field</label>
        <select class="is-medium" id="searchtype" name="searchtype"><option selected value="all">All fields</option><option value="title">Title</option><option value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
      </div>
      <div class="control">
          <button class="button is-link is-medium">Search</button>
      </div>
    </div>
    <div class="field">
      <div class="control is-size-7">
        
        <label class="radio">
          <input checked id="abstracts-0" name="abstracts" type="radio" value="show"> Show abstracts
        </label>
        
        <label class="radio">
          <input id="abstracts-1" name="abstracts" type="radio" value="hide"> Hide abstracts
        </label>
        
      </div>
    </div>
    <div class="is-clearfix" style="height: 2.5em"> 
      <div class="is-pulled-right">
        
        <a href="/search/advanced?terms-0-term=AI+in+Legal+Analysis&amp;terms-0-field=all&amp;size=200&amp;order=-announced_date_first">Advanced Search</a>
        
      </div>
    </div>
    <input type="hidden" name="order" value="-announced_date_first">
    <input type="hidden" name="size" value="200">
  </form>

  

  
      
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/">
      <div style="display: none;">
        
          
            <select id="searchtype" name="searchtype"><option selected value="all">All fields</option><option value="title">Title</option><option value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
          
        
          
            <input id="query" name="query" type="text" value="AI in Legal Analysis">
          
        
          
        
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option value="50">50</option><option value="100">100</option><option selected value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
      




<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2505.02174">arXiv:2505.02174</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2505.02174">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1613/jair.1.17619">10.1613/jair.1.17619 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">AI</span> Governance in the GCC States: A Comparative <span class="search-hit mathjax">Analysis</span> of National <span class="search-hit mathjax">AI</span> Strategies
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Albous%2C+M+R">Mohammad Rashed Albous</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Al-Jayyousi%2C+O+R">Odeh Rashed Al-Jayyousi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Stephens%2C+M">Melodena Stephens</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2505.02174v1-abstract-short" style="display: inline;">
        Gulf Cooperation Council (GCC) states increasingly adopt Artificial Intelligence (<span class="search-hit mathjax">AI</span>) to drive economic diversification and enhance services. This paper investigates the evolving&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2505.02174v1-abstract-full').style.display = 'inline'; document.getElementById('2505.02174v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2505.02174v1-abstract-full" style="display: none;">
        Gulf Cooperation Council (GCC) states increasingly adopt Artificial Intelligence (<span class="search-hit mathjax">AI</span>) to drive economic diversification and enhance services. This paper investigates the evolving <span class="search-hit mathjax">AI</span> governance landscape across the six GCC nations, the United Arab Emirates, Saudi Arabia, Qatar, Oman, Bahrain, and Kuwait, through an in-depth document <span class="search-hit mathjax">analysis</span> of six National <span class="search-hit mathjax">AI</span> Strategies (NASs) and related policies published between 2018 and 2024. Drawing on the Multiple Streams Framework (MSF) and Multi-stakeholder Governance theory, the findings highlight a &#34;soft regulation&#34; approach that emphasizes national strategies and ethical principles rather than binding regulations. While this approach fosters rapid innovation, it also raises concerns regarding the enforceability of ethical standards, potential ethicswashing, and alignment with global frameworks, particularly the EU <span class="search-hit mathjax">AI</span> Act. Common challenges include data limitations, talent shortages, and reconciling <span class="search-hit mathjax">AI</span> applications with cultural values. Despite these hurdles, GCC governments aspire to leverage <span class="search-hit mathjax">AI</span> for robust economic growth, better public services, and regional leadership in responsible <span class="search-hit mathjax">AI</span>. The <span class="search-hit mathjax">analysis</span> suggests that strengthening <span class="search-hit mathjax">legal</span> mechanisms, enhancing stakeholder engagement, and aligning policies with local contexts and international norms will be essential for harnessing <span class="search-hit mathjax">AI&#39;s</span> transformative potential in the GCC.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2505.02174v1-abstract-full').style.display = 'none'; document.getElementById('2505.02174v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 May, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">33 pages,6 figures, 11 tables</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Journal of Artificial Intelligence Research, 82, 2389-2422 (2025)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.21297">arXiv:2504.21297</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.21297">pdf</a>, <a href="https://arxiv.org/format/2504.21297">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Emerging Technologies">cs.ET</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Participatory <span class="search-hit mathjax">AI</span>, Public Sector <span class="search-hit mathjax">AI</span>, Differential Privacy, Conversational Interfaces, Explainable <span class="search-hit mathjax">AI</span>, Citizen Engagement in <span class="search-hit mathjax">AI</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+W">Wenjun Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Al-Masri%2C+E">Eyhab Al-Masri</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.21297v1-abstract-short" style="display: inline;">
        This paper introduces a conversational interface system that enables participatory design of differentially private <span class="search-hit mathjax">AI</span> systems in public sector applications. Addressing the challenge of balancing mathematical privacy guarantees with democratic accountability, we propose three key contributions: (1) an adaptive $ε$-selection protocol leveraging TOPSIS multi-c&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.21297v1-abstract-full').style.display = 'inline'; document.getElementById('2504.21297v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.21297v1-abstract-full" style="display: none;">
        This paper introduces a conversational interface system that enables participatory design of differentially private <span class="search-hit mathjax">AI</span> systems in public sector applications. Addressing the challenge of balancing mathematical privacy guarantees with democratic accountability, we propose three key contributions: (1) an adaptive $ε$-selection protocol leveraging TOPSIS multi-criteria decision <span class="search-hit mathjax">analysis</span> to align citizen preferences with differential privacy (DP) parameters, (2) an explainable noise-injection framework featuring real-time Mean Absolute Error (MAE) visualizations and GPT-4-powered impact <span class="search-hit mathjax">analysis</span>, and (3) an integrated <span class="search-hit mathjax">legal</span>-compliance mechanism that dynamically modulates privacy budgets based on evolving regulatory constraints. Our results advance participatory <span class="search-hit mathjax">AI</span> practices by demonstrating how conversational interfaces can enhance public engagement in algorithmic privacy mechanisms, ensuring that privacy-preserving <span class="search-hit mathjax">AI</span> in public sector governance remains both mathematically robust and democratically accountable.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.21297v1-abstract-full').style.display = 'none'; document.getElementById('2504.21297v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.19284">arXiv:2504.19284</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.19284">pdf</a>, <a href="https://arxiv.org/ps/2504.19284">ps</a>, <a href="https://arxiv.org/format/2504.19284">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Ethical Challenges of Using Artificial Intelligence in Judiciary
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=John%2C+A+M">Angel Mary John</a>, 
      
      <a href="/search/?searchtype=author&amp;query=U.%2C+A+M">Aiswarya M. U.</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Panachakel%2C+J+T">Jerrin Thomas Panachakel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.19284v1-abstract-short" style="display: inline;">
        Artificial intelligence (<span class="search-hit mathjax">AI</span>) has emerged as a ubiquitous concept in numerous domains, including the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.19284v1-abstract-full').style.display = 'inline'; document.getElementById('2504.19284v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.19284v1-abstract-full" style="display: none;">
        Artificial intelligence (<span class="search-hit mathjax">AI</span>) has emerged as a ubiquitous concept in numerous domains, including the <span class="search-hit mathjax">legal</span> system. <span class="search-hit mathjax">AI</span> has the potential to revolutionize the functioning of the judiciary and the dispensation of justice. Incorporating <span class="search-hit mathjax">AI</span> into the <span class="search-hit mathjax">legal</span> system offers the prospect of enhancing decision-making for judges, lawyers, and <span class="search-hit mathjax">legal</span> professionals, while concurrently providing the public with more streamlined, efficient, and cost-effective services. The integration of <span class="search-hit mathjax">AI</span> into the <span class="search-hit mathjax">legal</span> landscape offers manifold benefits, encompassing tasks such as document review, <span class="search-hit mathjax">legal</span> research, contract <span class="search-hit mathjax">analysis</span>, case prediction, and decision-making. By automating laborious and error-prone procedures, <span class="search-hit mathjax">AI</span> has the capacity to alleviate the burden associated with these arduous tasks. Consequently, courts around the world have begun embracing <span class="search-hit mathjax">AI</span> technology as a means to enhance the administration of justice. However, alongside its potential advantages, the use of <span class="search-hit mathjax">AI</span> in the judiciary poses a range of ethical challenges. These ethical quandaries must be duly addressed to ensure the responsible and equitable deployment of <span class="search-hit mathjax">AI</span> systems. This article delineates the principal ethical challenges entailed in employing <span class="search-hit mathjax">AI</span> within the judiciary and provides recommendations to effectively address these issues.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.19284v1-abstract-full').style.display = 'none'; document.getElementById('2504.19284v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">2023 IEEE MetroXRAINE 2023</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.18762">arXiv:2504.18762</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.18762">pdf</a>, <a href="https://arxiv.org/format/2504.18762">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        SynLexLM: Scaling <span class="search-hit mathjax">Legal</span> LLMs with Synthetic Data and Curriculum Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Upadhyay%2C+O">Ojasw Upadhyay</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Saravanakumar%2C+A">Abishek Saravanakumar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ismail%2C+A">Ayman Ismail</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.18762v2-abstract-short" style="display: inline;">
        &hellip;Language Models (LLMs) are powerful but often require extensive fine-tuning and large datasets for specialized domains like law. General-purpose pre-training may not capture <span class="search-hit mathjax">legal</span> nuances, and acquiring sufficient&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.18762v2-abstract-full').style.display = 'inline'; document.getElementById('2504.18762v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.18762v2-abstract-full" style="display: none;">
        Large Language Models (LLMs) are powerful but often require extensive fine-tuning and large datasets for specialized domains like law. General-purpose pre-training may not capture <span class="search-hit mathjax">legal</span> nuances, and acquiring sufficient <span class="search-hit mathjax">legal</span> data is challenging. We introduce SynLexLM, a novel approach to efficiently pre-train a <span class="search-hit mathjax">legal</span> LLM. Our method employs curriculum learning, progressing from simple to complex <span class="search-hit mathjax">legal</span> texts and queries, combined with synthetic data augmentation using models like Gemini Pro to address data scarcity. We aim to achieve improved performance on <span class="search-hit mathjax">legal</span> benchmarks (BigLaw-Bench, EUR-Lex-Sum) compared to traditional models and fine-tuned versions. Preliminary work involves generating synthetic QA pairs reflecting <span class="search-hit mathjax">legal</span> reasoning. This work aims to enhance <span class="search-hit mathjax">legal</span> document <span class="search-hit mathjax">analysis</span> and research tools, potentially democratizing access to advanced <span class="search-hit mathjax">legal</span> <span class="search-hit mathjax">AI</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.18762v2-abstract-full').style.display = 'none'; document.getElementById('2504.18762v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 April, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 25 April, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, 4 figures, 4 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.16204">arXiv:2504.16204</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.16204">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Emerging Technologies">cs.ET</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Reflexive Prompt Engineering: A Framework for Responsible Prompt Engineering and Interaction Design
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Djeffal%2C+C">Christian Djeffal</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.16204v1-abstract-short" style="display: inline;">
        Responsible prompt engineering has emerged as a critical framework for ensuring that generative artificial intelligence (<span class="search-hit mathjax">AI</span>) systems serve society&#39;s needs while minimizing potential harms. As generative&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.16204v1-abstract-full').style.display = 'inline'; document.getElementById('2504.16204v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.16204v1-abstract-full" style="display: none;">
        Responsible prompt engineering has emerged as a critical framework for ensuring that generative artificial intelligence (<span class="search-hit mathjax">AI</span>) systems serve society&#39;s needs while minimizing potential harms. As generative <span class="search-hit mathjax">AI</span> applications become increasingly powerful and ubiquitous, the way we instruct and interact with them through prompts has profound implications for fairness, accountability, and transparency. This article examines how strategic prompt engineering can embed ethical and <span class="search-hit mathjax">legal</span> considerations and societal values directly into <span class="search-hit mathjax">AI</span> interactions, moving beyond mere technical optimization for functionality. This article proposes a comprehensive framework for responsible prompt engineering that encompasses five interconnected components: prompt design, system selection, system configuration, performance evaluation, and prompt management. Drawing from empirical evidence, the paper demonstrates how each component can be leveraged to promote improved societal outcomes while mitigating potential risks. The <span class="search-hit mathjax">analysis</span> reveals that effective prompt engineering requires a delicate balance between technical precision and ethical consciousness, combining the systematic rigor and focus on functionality with the nuanced understanding of social impact. Through examination of real-world and emerging practices, the article illustrates how responsible prompt engineering serves as a crucial bridge between <span class="search-hit mathjax">AI</span> development and deployment, enabling organizations to fine-tune <span class="search-hit mathjax">AI</span> outputs without modifying underlying model architectures. This approach aligns with broader &#34;Responsibility by Design&#34; principles, embedding ethical considerations directly into the implementation process rather than treating them as post-hoc additions. The article concludes by identifying key research directions and practical guidelines for advancing the field of responsible prompt engineering.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.16204v1-abstract-full').style.display = 'none'; document.getElementById('2504.16204v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">20 pages one figure</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.15181">arXiv:2504.15181</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.15181">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Existing Industry Practice for the EU <span class="search-hit mathjax">AI</span> Act&#39;s General-Purpose <span class="search-hit mathjax">AI</span> Code of Practice Safety and Security Measures
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Stelling%2C+L">Lily Stelling</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+M">Mick Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gipi%C5%A1kis%2C+R">Rokas Gipiškis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Staufer%2C+L">Leon Staufer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chin%2C+Z+S">Ze Shen Chin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Campos%2C+S">Siméon Campos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+M">Michael Chen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.15181v1-abstract-short" style="display: inline;">
        This report provides a detailed comparison between the measures proposed in the EU <span class="search-hit mathjax">AI</span> Act&#39;s General-Purpose&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.15181v1-abstract-full').style.display = 'inline'; document.getElementById('2504.15181v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.15181v1-abstract-full" style="display: none;">
        This report provides a detailed comparison between the measures proposed in the EU <span class="search-hit mathjax">AI</span> Act&#39;s General-Purpose <span class="search-hit mathjax">AI</span> (GPAI) Code of Practice (Third Draft) and current practices adopted by leading <span class="search-hit mathjax">AI</span> companies. As the EU moves toward enforcing binding obligations for GPAI model providers, the Code of Practice will be key to bridging <span class="search-hit mathjax">legal</span> requirements with concrete technical commitments. Our <span class="search-hit mathjax">analysis</span> focuses on the draft&#39;s Safety and Security section which is only relevant for the providers of the most advanced models (Commitments II.1-II.16) and excerpts from current public-facing documents quotes that are relevant to each individual measure.
  We systematically reviewed different document types - including companies&#39; frontier safety frameworks and model cards - from over a dozen companies, including OpenAI, Anthropic, Google DeepMind, Microsoft, Meta, Amazon, and others. This report is not meant to be an indication of <span class="search-hit mathjax">legal</span> compliance nor does it take any prescriptive viewpoint about the Code of Practice or companies&#39; policies. Instead, it aims to inform the ongoing dialogue between regulators and GPAI model providers by surfacing evidence of precedent.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.15181v1-abstract-full').style.display = 'none'; document.getElementById('2504.15181v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">158 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.14815">arXiv:2504.14815</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.14815">pdf</a>, <a href="https://arxiv.org/format/2504.14815">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        What Lurks Within? Concept Auditing for Shared Diffusion Models at Scale
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yuan%2C+X">Xiaoyong Yuan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+X">Xiaolong Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guo%2C+L">Linke Guo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+L">Lan Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.14815v1-abstract-short" style="display: inline;">
        &hellip;now customize powerful pre-trained models using minimal computational resources. However, the widespread sharing of fine-tuned DMs on open platforms raises growing ethical and <span class="search-hit mathjax">legal</span> concerns, as these models may inadvertently or deliberately generate sensitive or unauthorized content, such as copyrighted material, private individuals, or harmful content. Des&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.14815v1-abstract-full').style.display = 'inline'; document.getElementById('2504.14815v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.14815v1-abstract-full" style="display: none;">
        Diffusion models (DMs) have revolutionized text-to-image generation, enabling the creation of highly realistic and customized images from text prompts. With the rise of parameter-efficient fine-tuning (PEFT) techniques like LoRA, users can now customize powerful pre-trained models using minimal computational resources. However, the widespread sharing of fine-tuned DMs on open platforms raises growing ethical and <span class="search-hit mathjax">legal</span> concerns, as these models may inadvertently or deliberately generate sensitive or unauthorized content, such as copyrighted material, private individuals, or harmful content. Despite the increasing regulatory attention on generative <span class="search-hit mathjax">AI</span>, there are currently no practical tools for systematically auditing these models before deployment. In this paper, we address the problem of concept auditing: determining whether a fine-tuned DM has learned to generate a specific target concept. Existing approaches typically rely on prompt-based input crafting and output-based image classification but suffer from critical limitations, including prompt uncertainty, concept drift, and poor scalability. To overcome these challenges, we introduce Prompt-Agnostic Image-Free Auditing (PAIA), a novel, model-centric concept auditing framework. By treating the DM as the object of inspection, PAIA enables direct <span class="search-hit mathjax">analysis</span> of internal model behavior, bypassing the need for optimized prompts or generated images. We evaluate PAIA on 320 controlled model and 690 real-world community models sourced from a public DM sharing platform. PAIA achieves over 90% detection accuracy while reducing auditing time by 18-40x compared to existing baselines. To our knowledge, PAIA is the first scalable and practical solution for pre-deployment concept auditing of diffusion models, providing a practical foundation for safer and more transparent diffusion model sharing.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.14815v1-abstract-full').style.display = 'none'; document.getElementById('2504.14815v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">17 pages, 15 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.07766">arXiv:2504.07766</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.07766">pdf</a>, <a href="https://arxiv.org/format/2504.07766">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Theoretical Economics">econ.TH</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Realigning Incentives to Build Better Software: a Holistic Approach to Vendor Accountability
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bicz%C3%B3k%2C+G">Gergely Biczók</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Romanosky%2C+S">Sasha Romanosky</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+M">Mingyan Liu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.07766v1-abstract-short" style="display: inline;">
        &hellip;and more secure software development. At the heart of the incentive realignment is the concept of software liability. This framework touches on various components, including <span class="search-hit mathjax">legal</span>, technical, and financial, that are needed for software liability to work in practice; some currently exist, some will need to be re-imagined or established. This is primarily a ma&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.07766v1-abstract-full').style.display = 'inline'; document.getElementById('2504.07766v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.07766v1-abstract-full" style="display: none;">
        In this paper, we ask the question of why the quality of commercial software, in terms of security and safety, does not measure up to that of other (durable) consumer goods we have come to expect. We examine this question through the lens of incentives. We argue that the challenge around better quality software is due in no small part to a sequence of misaligned incentives, the most critical of which being that the harm caused by software problems is by and large shouldered by consumers, not developers. This lack of liability means software vendors have every incentive to rush low-quality software onto the market and no incentive to enhance quality control. Within this context, this paper outlines a holistic technical and policy framework we believe is needed to incentivize better and more secure software development. At the heart of the incentive realignment is the concept of software liability. This framework touches on various components, including <span class="search-hit mathjax">legal</span>, technical, and financial, that are needed for software liability to work in practice; some currently exist, some will need to be re-imagined or established. This is primarily a market-driven approach that emphasizes voluntary participation but highlights the role appropriate regulation can play. We connect and contrast this with the EU <span class="search-hit mathjax">legal</span> environment and discuss what this framework means for open-source software (OSS) development and emerging <span class="search-hit mathjax">AI</span> risks. Moreover, we present a CrowdStrike case study complete with a what-if <span class="search-hit mathjax">analysis</span> had our proposed framework been in effect. Our intention is very much to stimulate a robust conversation among both researchers and practitioners.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.07766v1-abstract-full').style.display = 'none'; document.getElementById('2504.07766v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">accepted to WEIS 2025</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.05358">arXiv:2504.05358</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.05358">pdf</a>, <a href="https://arxiv.org/format/2504.05358">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Debate-Feedback: A Multi-Agent Framework for Efficient <span class="search-hit mathjax">Legal</span> Judgment Prediction
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+X">Xi Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mao%2C+M">Mao Mao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+S">Shuo Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shangguan%2C+H">Haotian Shangguan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.05358v1-abstract-short" style="display: inline;">
        The use of <span class="search-hit mathjax">AI</span> in&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05358v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05358v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.05358v1-abstract-full" style="display: none;">
        The use of <span class="search-hit mathjax">AI</span> in <span class="search-hit mathjax">legal</span> <span class="search-hit mathjax">analysis</span> and prediction (LegalAI) has gained widespread attention, with past research focusing on retrieval-based methods and fine-tuning large models. However, these approaches often require large datasets and underutilize the capabilities of modern large language models (LLMs). In this paper, inspired by the debate phase of real courtroom trials, we propose a novel <span class="search-hit mathjax">legal</span> judgment prediction model based on the Debate-Feedback architecture, which integrates LLM multi-agent debate and reliability evaluation models. Unlike traditional methods, our model achieves significant improvements in efficiency by minimizing the need for large historical datasets, thus offering a lightweight yet robust solution. Comparative experiments show that it outperforms several general-purpose and domain-specific <span class="search-hit mathjax">legal</span> models, offering a dynamic reasoning process and a promising direction for future LegalAI research.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05358v1-abstract-full').style.display = 'none'; document.getElementById('2504.05358v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.04737">arXiv:2504.04737</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.04737">pdf</a>, <a href="https://arxiv.org/format/2504.04737">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        TathyaNyaya and FactLegalLlama: Advancing Factual Judgment Prediction and Explanation in the Indian <span class="search-hit mathjax">Legal</span> Context
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Nigam%2C+S+K">Shubham Kumar Nigam</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Patnaik%2C+B+D">Balaramamahanthi Deepak Patnaik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mishra%2C+S">Shivam Mishra</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shallum%2C+N">Noel Shallum</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ghosh%2C+K">Kripabandhu Ghosh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bhattacharya%2C+A">Arnab Bhattacharya</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.04737v1-abstract-short" style="display: inline;">
        In the landscape of Fact-based Judgment Prediction and Explanation (FJPE), reliance on factual data is essential for developing robust and realistic <span class="search-hit mathjax">AI</span>-driven decision-making tools. This paper introduces TathyaNyaya, the largest annotated dataset for FJPE tailored to the Indian&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.04737v1-abstract-full').style.display = 'inline'; document.getElementById('2504.04737v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.04737v1-abstract-full" style="display: none;">
        In the landscape of Fact-based Judgment Prediction and Explanation (FJPE), reliance on factual data is essential for developing robust and realistic <span class="search-hit mathjax">AI</span>-driven decision-making tools. This paper introduces TathyaNyaya, the largest annotated dataset for FJPE tailored to the Indian <span class="search-hit mathjax">legal</span> context, encompassing judgments from the Supreme Court of India and various High Courts. Derived from the Hindi terms &#34;Tathya&#34; (fact) and &#34;Nyaya&#34; (justice), the TathyaNyaya dataset is uniquely designed to focus on factual statements rather than complete <span class="search-hit mathjax">legal</span> texts, reflecting real-world judicial processes where factual data drives outcomes. Complementing this dataset, we present FactLegalLlama, an instruction-tuned variant of the LLaMa-3-8B Large Language Model (LLM), optimized for generating high-quality explanations in FJPE tasks. Finetuned on the factual data in TathyaNyaya, FactLegalLlama integrates predictive accuracy with coherent, contextually relevant explanations, addressing the critical need for transparency and interpretability in <span class="search-hit mathjax">AI</span>-assisted <span class="search-hit mathjax">legal</span> systems. Our methodology combines transformers for binary judgment prediction with FactLegalLlama for explanation generation, creating a robust framework for advancing FJPE in the Indian <span class="search-hit mathjax">legal</span> domain. TathyaNyaya not only surpasses existing datasets in scale and diversity but also establishes a benchmark for building explainable <span class="search-hit mathjax">AI</span> systems in <span class="search-hit mathjax">legal</span> <span class="search-hit mathjax">analysis</span>. The findings underscore the importance of factual precision and domain-specific tuning in enhancing predictive performance and interpretability, positioning TathyaNyaya and FactLegalLlama as foundational resources for <span class="search-hit mathjax">AI</span>-assisted <span class="search-hit mathjax">legal</span> decision-making.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.04737v1-abstract-full').style.display = 'none'; document.getElementById('2504.04737v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.02898">arXiv:2504.02898</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.02898">pdf</a>, <a href="https://arxiv.org/ps/2504.02898">ps</a>, <a href="https://arxiv.org/format/2504.02898">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Practical Synthesis of Detecting <span class="search-hit mathjax">AI</span>-Generated Textual, Visual, and Audio Content
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cao%2C+L">Lele Cao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.02898v1-abstract-short" style="display: inline;">
        Advances in <span class="search-hit mathjax">AI</span>-generated content have led to wide adoption of large language models, diffusion-based visual generators, and synthetic audio tools. However, these developments raise critical concerns about misinformation, copyright infringement, security threats, and the erosion of public trust. In this paper, we explore an extensive range of methods designed&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.02898v1-abstract-full').style.display = 'inline'; document.getElementById('2504.02898v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.02898v1-abstract-full" style="display: none;">
        Advances in <span class="search-hit mathjax">AI</span>-generated content have led to wide adoption of large language models, diffusion-based visual generators, and synthetic audio tools. However, these developments raise critical concerns about misinformation, copyright infringement, security threats, and the erosion of public trust. In this paper, we explore an extensive range of methods designed to detect and mitigate <span class="search-hit mathjax">AI</span>-generated textual, visual, and audio content. We begin by discussing motivations and potential impacts associated with <span class="search-hit mathjax">AI</span>-based content generation, including real-world risks and ethical dilemmas. We then outline detection techniques spanning observation-based strategies, linguistic and statistical <span class="search-hit mathjax">analysis</span>, model-based pipelines, watermarking and fingerprinting, as well as emergent ensemble approaches. We also present new perspectives on robustness, adaptation to rapidly improving generative architectures, and the critical role of human-in-the-loop verification. By surveying state-of-the-art research and highlighting case studies in academic, journalistic, <span class="search-hit mathjax">legal</span>, and industrial contexts, this paper aims to inform robust solutions and policymaking. We conclude by discussing open challenges, including adversarial transformations, domain generalization, and ethical concerns, thereby offering a holistic guide for researchers, practitioners, and regulators to preserve content authenticity in the face of increasingly sophisticated <span class="search-hit mathjax">AI</span>-generated media.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.02898v1-abstract-full').style.display = 'none'; document.getElementById('2504.02898v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68T50; 68T45; 68T10; 68T30; 94A08; 62H30; 68U10
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.7; I.2.10; I.2.6; H.5.5; K.6.5; K.4.1; I.4.9; H.3.1
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.02127">arXiv:2504.02127</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.02127">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Reinsuring <span class="search-hit mathjax">AI</span>: Energy, Agriculture, Finance &amp; Medicine as Precedents for Scalable Governance of Frontier Artificial Intelligence
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Stetler%2C+N">Nicholas Stetler</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.02127v1-abstract-short" style="display: inline;">
        The governance of frontier artificial intelligence (<span class="search-hit mathjax">AI</span>) systems--particularly those capable of catastrophic misuse or systemic failure--requires institutional structures that are robust, adaptive, and innovation-preserving. This paper proposes a novel framework for governing such high-stakes models through a three-tiered insurance architecture: (1) mandatory&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.02127v1-abstract-full').style.display = 'inline'; document.getElementById('2504.02127v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.02127v1-abstract-full" style="display: none;">
        The governance of frontier artificial intelligence (<span class="search-hit mathjax">AI</span>) systems--particularly those capable of catastrophic misuse or systemic failure--requires institutional structures that are robust, adaptive, and innovation-preserving. This paper proposes a novel framework for governing such high-stakes models through a three-tiered insurance architecture: (1) mandatory private liability insurance for frontier model developers; (2) an industry-administered risk pool to absorb recurring, non-catastrophic losses; and (3) federally backed reinsurance for tail-risk events. Drawing from historical precedents in nuclear energy (Price-Anderson), terrorism risk (TRIA), agricultural crop insurance, flood reinsurance, and medical malpractice, the proposal shows how the federal government can stabilize private <span class="search-hit mathjax">AI</span> insurance markets without resorting to brittle regulation or predictive licensing regimes. The structure aligns incentives between <span class="search-hit mathjax">AI</span> developers and downstream stakeholders, transforms safety practices into insurable standards, and enables modular oversight through adaptive eligibility criteria. By focusing on risk-transfer mechanisms rather than prescriptive rules, this framework seeks to render <span class="search-hit mathjax">AI</span> safety a structural feature of the innovation ecosystem itself--integrated into capital markets, not external to them. The paper concludes with a <span class="search-hit mathjax">legal</span> and administrative feasibility <span class="search-hit mathjax">analysis</span>, proposing avenues for statutory authorization and agency placement within existing federal structures.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.02127v1-abstract-full').style.display = 'none'; document.getElementById('2504.02127v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Working paper version (35 pages). Submitted to So. Ill. Law Journal; full-form citations retained for editorial review. Not peer-reviewed. Subject to revision</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          91B30; 91B62
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.0; K.4.1; K.5.2; K.7.m
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.02000">arXiv:2504.02000</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.02000">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Emerging Technologies">cs.ET</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">AI</span> Regulation and Capitalist Growth: Balancing Innovation, Ethics, and Global Governance
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kulothungan%2C+V">Vikram Kulothungan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mohan%2C+P+R">Priya Ranjani Mohan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gupta%2C+D">Deepti Gupta</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.02000v1-abstract-short" style="display: inline;">
        Artificial Intelligence (<span class="search-hit mathjax">AI</span>) is increasingly central to economic growth, promising new efficiencies and markets. This economic significance has sparked debate over&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.02000v1-abstract-full').style.display = 'inline'; document.getElementById('2504.02000v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.02000v1-abstract-full" style="display: none;">
        Artificial Intelligence (<span class="search-hit mathjax">AI</span>) is increasingly central to economic growth, promising new efficiencies and markets. This economic significance has sparked debate over <span class="search-hit mathjax">AI</span> regulation: do rules and oversight bolster long term growth by building trust and safeguarding the public, or do they constrain innovation and free enterprise? This paper examines the balance between <span class="search-hit mathjax">AI</span> regulation and capitalist ideals, focusing on how different approaches to <span class="search-hit mathjax">AI</span> data privacy can impact innovation in <span class="search-hit mathjax">AI</span>-driven applications. The central question is whether <span class="search-hit mathjax">AI</span> regulation enhances or inhibits growth in a capitalist economy. Our <span class="search-hit mathjax">analysis</span> synthesizes historical precedents, the current U.S. regulatory landscape, economic projections, <span class="search-hit mathjax">legal</span> challenges, and case studies of recent <span class="search-hit mathjax">AI</span> policies. We discuss that carefully calibrated <span class="search-hit mathjax">AI</span> data privacy regulations-balancing innovation incentives with the public interest can foster sustainable growth by building trust and ensuring responsible data use, while excessive regulation may risk stifling innovation and entrenching incumbents.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.02000v1-abstract-full').style.display = 'none'; document.getElementById('2504.02000v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted for IEEE BigDataSecurity 2025 Conference</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.18156">arXiv:2503.18156</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.18156">pdf</a>, <a href="https://arxiv.org/format/2503.18156">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Adoption of Watermarking for Generative <span class="search-hit mathjax">AI</span> Systems in Practice and Implications under the new EU <span class="search-hit mathjax">AI</span> Act
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rijsbosch%2C+B">Bram Rijsbosch</a>, 
      
      <a href="/search/?searchtype=author&amp;query=van+Dijck%2C+G">Gijs van Dijck</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kollnig%2C+K">Konrad Kollnig</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.18156v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">AI</span>-generated images have become so good in recent years that individuals cannot distinguish them any more from &#34;real&#34; images. This development creates a series of societal risks, and challenges our perception of what is true and what is not, particularly with the emergence of &#34;deep fakes&#34; that impersonate real individuals. Watermarking, a tec&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.18156v1-abstract-full').style.display = 'inline'; document.getElementById('2503.18156v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.18156v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">AI</span>-generated images have become so good in recent years that individuals cannot distinguish them any more from &#34;real&#34; images. This development creates a series of societal risks, and challenges our perception of what is true and what is not, particularly with the emergence of &#34;deep fakes&#34; that impersonate real individuals. Watermarking, a technique that involves embedding identifying information within images to indicate their <span class="search-hit mathjax">AI</span>-generated nature, has emerged as a primary mechanism to address the risks posed by <span class="search-hit mathjax">AI</span>-generated images. The implementation of watermarking techniques is now becoming a <span class="search-hit mathjax">legal</span> requirement in many jurisdictions, including under the new 2024 EU <span class="search-hit mathjax">AI</span> Act. Despite the widespread use of <span class="search-hit mathjax">AI</span> image generation systems, the current status of watermarking implementation remains largely unexamined. Moreover, the practical implications of the <span class="search-hit mathjax">AI</span> Act&#39;s watermarking requirements have not previously been studied. The present paper therefore both provides an empirical <span class="search-hit mathjax">analysis</span> of 50 of the most widely used <span class="search-hit mathjax">AI</span> systems for image generation, and embeds this empirical <span class="search-hit mathjax">analysis</span> into a <span class="search-hit mathjax">legal</span> <span class="search-hit mathjax">analysis</span> of the <span class="search-hit mathjax">AI</span> Act. We identify four categories of generative <span class="search-hit mathjax">AI</span> image systems relevant under the <span class="search-hit mathjax">AI</span> Act, outline the <span class="search-hit mathjax">legal</span> obligations for each category, and find that only a minority number of providers currently implement adequate watermarking practices.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.18156v1-abstract-full').style.display = 'none'; document.getElementById('2503.18156v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 March, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages, 7 figures, note that this work has not been published in a peer reviewed venue yet. While we have made our best effort to ensure the validity of our findings, it is therefore still work in progress and potentially subject to change</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.17428">arXiv:2503.17428</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.17428">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/s00146-007-0177-3">10.1007/s00146-007-0177-3 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Would you mind being watched by machines? Privacy concerns in data mining
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=M%C3%BCller%2C+V+C">Vincent C. Müller</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.17428v1-abstract-short" style="display: inline;">
        &hellip;purposes. After a clarification of the relevant nature of privacy, it is argued that access by machines cannot warrant the access to further information, since the <span class="search-hit mathjax">analysis</span> will have to be made either by humans or by machines that understand. It concludes that the current data mining violates the right to privacy and should be subject to the standard&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.17428v1-abstract-full').style.display = 'inline'; document.getElementById('2503.17428v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.17428v1-abstract-full" style="display: none;">
        Data mining is not an invasion of privacy because access to data is only by machines, not by people: this is the argument that is investigated here. The current importance of this problem is developed in a case study of data mining in the USA for counterterrorism and other surveillance purposes. After a clarification of the relevant nature of privacy, it is argued that access by machines cannot warrant the access to further information, since the <span class="search-hit mathjax">analysis</span> will have to be made either by humans or by machines that understand. It concludes that the current data mining violates the right to privacy and should be subject to the standard <span class="search-hit mathjax">legal</span> constraints for access to private information by people.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.17428v1-abstract-full').style.display = 'none'; document.getElementById('2503.17428v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 March, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        (2009) <span class="search-hit mathjax">AI</span> & Society, 23 (4), 529-44
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.14540">arXiv:2503.14540</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.14540">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Role of <span class="search-hit mathjax">Legal</span> Frameworks in Shaping Ethical Artificial Intelligence Use in Corporate Governance
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mirishli%2C+S">Shahmar Mirishli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.14540v1-abstract-short" style="display: inline;">
        This article examines the evolving role of <span class="search-hit mathjax">legal</span> frameworks in shaping ethical artificial intelligence (&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.14540v1-abstract-full').style.display = 'inline'; document.getElementById('2503.14540v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.14540v1-abstract-full" style="display: none;">
        This article examines the evolving role of <span class="search-hit mathjax">legal</span> frameworks in shaping ethical artificial intelligence (<span class="search-hit mathjax">AI</span>) use in corporate governance. As <span class="search-hit mathjax">AI</span> systems become increasingly prevalent in business operations and decision-making, there is a growing need for robust governance structures to ensure their responsible development and deployment. Through <span class="search-hit mathjax">analysis</span> of recent legislative initiatives, industry standards, and scholarly perspectives, this paper explores key <span class="search-hit mathjax">legal</span> and regulatory approaches aimed at promoting transparency, accountability, and fairness in corporate <span class="search-hit mathjax">AI</span> applications. It evaluates the strengths and limitations of current frameworks, identifies emerging best practices, and offers recommendations for developing more comprehensive and effective <span class="search-hit mathjax">AI</span> governance regimes. The findings highlight the importance of adaptable, principle-based regulations coupled with sector-specific guidance to address the unique challenges posed by <span class="search-hit mathjax">AI</span> technologies in the corporate sphere.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.14540v1-abstract-full').style.display = 'none'; document.getElementById('2503.14540v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 March, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.13510">arXiv:2503.13510</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.13510">pdf</a>, <a href="https://arxiv.org/format/2503.13510">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Prompt Sentiment: The Catalyst for LLM Change
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gandhi%2C+V">Vishal Gandhi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gandhi%2C+S">Sagar Gandhi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.13510v1-abstract-short" style="display: inline;">
        &hellip;how sentiment variations in prompts affect LLM-generated outputs in terms of coherence, factuality, and bias. Leveraging both lexicon-based and transformer-based sentiment <span class="search-hit mathjax">analysis</span> methods, we categorize prompts and evaluate responses from five leading LLMs: Claude, DeepSeek, GPT-4, Gemini, and LLaMA. Our&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.13510v1-abstract-full').style.display = 'inline'; document.getElementById('2503.13510v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.13510v1-abstract-full" style="display: none;">
        The rise of large language models (LLMs) has revolutionized natural language processing (NLP), yet the influence of prompt sentiment, a latent affective characteristic of input text, remains underexplored. This study systematically examines how sentiment variations in prompts affect LLM-generated outputs in terms of coherence, factuality, and bias. Leveraging both lexicon-based and transformer-based sentiment <span class="search-hit mathjax">analysis</span> methods, we categorize prompts and evaluate responses from five leading LLMs: Claude, DeepSeek, GPT-4, Gemini, and LLaMA. Our <span class="search-hit mathjax">analysis</span> spans six <span class="search-hit mathjax">AI</span>-driven applications, including content generation, conversational <span class="search-hit mathjax">AI</span>, <span class="search-hit mathjax">legal</span> and financial <span class="search-hit mathjax">analysis</span>, healthcare <span class="search-hit mathjax">AI</span>, creative writing, and technical documentation. By transforming prompts, we assess their impact on output quality. Our findings reveal that prompt sentiment significantly influences model responses, with negative prompts often reducing factual accuracy and amplifying bias, while positive prompts tend to increase verbosity and sentiment propagation. These results highlight the importance of sentiment-aware prompt engineering for ensuring fair and reliable <span class="search-hit mathjax">AI</span>-generated content.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.13510v1-abstract-full').style.display = 'none'; document.getElementById('2503.13510v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 March, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.11898">arXiv:2503.11898</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.11898">pdf</a>, <a href="https://arxiv.org/format/2503.11898">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        LLMs for Translation: Historical, Low-Resourced Languages and Contemporary <span class="search-hit mathjax">AI</span> Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Tekgurler%2C+M">Merve Tekgurler</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.11898v1-abstract-short" style="display: inline;">
        &hellip;recounts the experiences of Osman Agha, an Ottoman subject who spent 11 years as a prisoner of war in Austria, and includes his accounts of warfare and violence. Our <span class="search-hit mathjax">analysis</span> reveals that Gemini&#39;s safety mechanisms flagged between 14 and 23 percent of the manuscript as harmful, resulting in untranslated passages. These safety settings, while effective in&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.11898v1-abstract-full').style.display = 'inline'; document.getElementById('2503.11898v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.11898v1-abstract-full" style="display: none;">
        Large Language Models (LLMs) have demonstrated remarkable adaptability in performing various tasks, including machine translation (MT), without explicit training. Models such as OpenAI&#39;s GPT-4 and Google&#39;s Gemini are frequently evaluated on translation benchmarks and utilized as translation tools due to their high performance. This paper examines Gemini&#39;s performance in translating an 18th-century Ottoman Turkish manuscript, Prisoner of the Infidels: The Memoirs of Osman Agha of Timisoara, into English. The manuscript recounts the experiences of Osman Agha, an Ottoman subject who spent 11 years as a prisoner of war in Austria, and includes his accounts of warfare and violence. Our <span class="search-hit mathjax">analysis</span> reveals that Gemini&#39;s safety mechanisms flagged between 14 and 23 percent of the manuscript as harmful, resulting in untranslated passages. These safety settings, while effective in mitigating potential harm, hinder the model&#39;s ability to provide complete and accurate translations of historical texts. Through real historical examples, this study highlights the inherent challenges and limitations of current LLM safety implementations in the handling of sensitive and context-rich materials. These real-world instances underscore potential failures of LLMs in contemporary translation scenarios, where accurate and comprehensive translations are crucial-for example, translating the accounts of modern victims of war for <span class="search-hit mathjax">legal</span> proceedings or humanitarian documentation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.11898v1-abstract-full').style.display = 'none'; document.getElementById('2503.11898v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 March, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to LaTeCH-CLfL 2025, held in conjunction with NAACL 2025</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.07172">arXiv:2503.07172</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.07172">pdf</a>, <a href="https://arxiv.org/format/2503.07172">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Lawful and Accountable Personal Data Processing with GDPR-based Access and Usage Control in Distributed Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=van+Binsbergen%2C+L+T">L. Thomas van Binsbergen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Steketee%2C+M+C">Marten C. Steketee</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kebede%2C+M+G">Milen G. Kebede</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Janssen%2C+H+L">Heleen L. Janssen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=van+Engers%2C+T+M">Tom M. van Engers</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.07172v1-abstract-short" style="display: inline;">
        &hellip;and in large-scale international data spaces.
  This paper addresses these concerns by proposing a case-generic method for automated normative reasoning that establishes <span class="search-hit mathjax">legal</span> arguments for the lawfulness of data processing activities. The arguments are established on the basis of case-specific&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.07172v1-abstract-full').style.display = 'inline'; document.getElementById('2503.07172v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.07172v1-abstract-full" style="display: none;">
        Compliance with the GDPR privacy regulation places a significant burden on organisations regarding the handling of personal data. The perceived efforts and risks of complying with the GDPR further increase when data processing activities span across organisational boundaries, as is the case in both small-scale data sharing settings and in large-scale international data spaces.
  This paper addresses these concerns by proposing a case-generic method for automated normative reasoning that establishes <span class="search-hit mathjax">legal</span> arguments for the lawfulness of data processing activities. The arguments are established on the basis of case-specific <span class="search-hit mathjax">legal</span> qualifications made by privacy experts, bringing the human in the loop. The obtained expert system promotes transparency and accountability, remains adaptable to extended or altered interpretations of the GDPR, and integrates into novel or existing distributed data processing systems.
  This result is achieved by defining a formal ontology and semantics for automated normative reasoning based on an <span class="search-hit mathjax">analysis</span> of the purpose-limitation principle of the GDPR. The ontology and semantics are implemented in eFLINT, a domain-specific language for specifying and reasoning with norms. The XACML architecture standard, applicable to both access and usage control, is extended, demonstrating how GDPR-based normative reasoning can integrate into (existing, distributed) systems for data processing. The resulting system is designed and critically assessed in reference to requirements extracted from the GPDR.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.07172v1-abstract-full').style.display = 'none'; document.getElementById('2503.07172v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 March, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted for review to the Journal of <span class="search-hit mathjax">AI</span> and Law, 49 pages (including)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.06054">arXiv:2503.06054</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.06054">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Fine-Grained Bias Detection in LLM: Enhancing detection mechanisms for nuanced biases
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mohanty%2C+S">Suvendu Mohanty</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.06054v1-abstract-short" style="display: inline;">
        &hellip;and reinforce stereotypes, raising ethical concerns. This study presents a detection framework to identify nuanced biases in LLMs. The approach integrates contextual <span class="search-hit mathjax">analysis</span>, interpretability via attention mechanisms, and counterfactual data augmentation to capture hidden biases across linguistic contexts. The methodology employs contrastive prompts and sy&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.06054v1-abstract-full').style.display = 'inline'; document.getElementById('2503.06054v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.06054v1-abstract-full" style="display: none;">
        Recent advancements in Artificial Intelligence, particularly in Large Language Models (LLMs), have transformed natural language processing by improving generative capabilities. However, detecting biases embedded within these models remains a challenge. Subtle biases can propagate misinformation, influence decision-making, and reinforce stereotypes, raising ethical concerns. This study presents a detection framework to identify nuanced biases in LLMs. The approach integrates contextual <span class="search-hit mathjax">analysis</span>, interpretability via attention mechanisms, and counterfactual data augmentation to capture hidden biases across linguistic contexts. The methodology employs contrastive prompts and synthetic datasets to analyze model behaviour across cultural, ideological, and demographic scenarios.
  Quantitative <span class="search-hit mathjax">analysis</span> using benchmark datasets and qualitative assessments through expert reviews validate the effectiveness of the framework. Results show improvements in detecting subtle biases compared to conventional methods, which often fail to highlight disparities in model responses to race, gender, and socio-political contexts. The framework also identifies biases arising from imbalances in training data and model architectures. Continuous user feedback ensures adaptability and refinement. This research underscores the importance of proactive bias mitigation strategies and calls for collaboration between policymakers, <span class="search-hit mathjax">AI</span> developers, and regulators. The proposed detection mechanisms enhance model transparency and support responsible LLM deployment in sensitive applications such as education, <span class="search-hit mathjax">legal</span> systems, and healthcare. Future work will focus on real-time bias monitoring and cross-linguistic generalization to improve fairness and inclusivity in <span class="search-hit mathjax">AI</span>-driven communication tools.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.06054v1-abstract-full').style.display = 'none'; document.getElementById('2503.06054v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 March, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Bias detection, Large Language Models, nuanced biases, fine-grained mechanisms, model transparency, ethical <span class="search-hit mathjax">AI</span></span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.05571">arXiv:2503.05571</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.05571">pdf</a>, <a href="https://arxiv.org/format/2503.05571">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Emerging Technologies">cs.ET</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Compliance of <span class="search-hit mathjax">AI</span> Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sch%C3%B6ning%2C+J">Julius Schöning</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kruse%2C+N">Niklas Kruse</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.05571v1-abstract-short" style="display: inline;">
        The increasing integration of artificial intelligence (<span class="search-hit mathjax">AI</span>) systems in various fields requires solid concepts to ensure compliance with upcoming legislation. This paper systematically examines the compliance of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.05571v1-abstract-full').style.display = 'inline'; document.getElementById('2503.05571v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.05571v1-abstract-full" style="display: none;">
        The increasing integration of artificial intelligence (<span class="search-hit mathjax">AI</span>) systems in various fields requires solid concepts to ensure compliance with upcoming legislation. This paper systematically examines the compliance of <span class="search-hit mathjax">AI</span> systems with relevant legislation, focusing on the EU&#39;s <span class="search-hit mathjax">AI</span> Act and the compliance of data sets. The <span class="search-hit mathjax">analysis</span> highlighted many challenges associated with edge devices, which are increasingly being used to deploy <span class="search-hit mathjax">AI</span> applications closer and closer to the data sources. Such devices often face unique issues due to their decentralized nature and limited computing resources for implementing sophisticated compliance mechanisms. By analyzing <span class="search-hit mathjax">AI</span> implementations, the paper identifies challenges and proposes the first best practices for <span class="search-hit mathjax">legal</span> compliance when developing, deploying, and running <span class="search-hit mathjax">AI</span>. The importance of data set compliance is highlighted as a cornerstone for ensuring the trustworthiness, transparency, and explainability of <span class="search-hit mathjax">AI</span> systems, which must be aligned with ethical standards set forth in regulatory frameworks such as the <span class="search-hit mathjax">AI</span> Act. The insights gained should contribute to the ongoing discourse on the responsible development and deployment of embedded <span class="search-hit mathjax">AI</span> systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.05571v1-abstract-full').style.display = 'none'; document.getElementById('2503.05571v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 March, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">5 pages, 3 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.1; H.4.0
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.04766">arXiv:2503.04766</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.04766">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Global <span class="search-hit mathjax">AI</span> Governance: Where the Challenge is the Solution- An Interdisciplinary, Multilateral, and Vertically Coordinated Approach
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhong%2C+H">Huixin Zhong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Do%2C+T">Thao Do</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jie%2C+Y">Ynagliu Jie</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Neuwirth%2C+R+J">Rostam J. Neuwirth</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shen%2C+H">Hong Shen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.04766v1-abstract-short" style="display: inline;">
        Current global <span class="search-hit mathjax">AI</span> governance frameworks struggle with fragmented disciplinary collaboration, ineffective multilateral coordination, and disconnects between policy design and grassroots implementation. This study, guided by Integration and Implementation Science (IIS) initiated a structured interdisciplinary dialogue at the UN Science Summit, convening&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.04766v1-abstract-full').style.display = 'inline'; document.getElementById('2503.04766v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.04766v1-abstract-full" style="display: none;">
        Current global <span class="search-hit mathjax">AI</span> governance frameworks struggle with fragmented disciplinary collaboration, ineffective multilateral coordination, and disconnects between policy design and grassroots implementation. This study, guided by Integration and Implementation Science (IIS) initiated a structured interdisciplinary dialogue at the UN Science Summit, convening <span class="search-hit mathjax">legal</span>, NGO, and HCI experts to tackle those challenges. Drawing on the common ground of the experts: dynamism, experimentation, inclusivity, and paradoxical governance, this study, through thematic <span class="search-hit mathjax">analysis</span> and interdisciplinary comparison <span class="search-hit mathjax">analysis</span>, identifies four core principles of global <span class="search-hit mathjax">AI</span> governance. Furthermore, we translate these abstract principles into concrete action plans leveraging the distinct yet complementary perspectives of each discipline. These principles and action plans are then integrated into a five-phase, time-sequential framework including foundation building, experimental verification, collaborative optimization, global adaptation, and continuous evolution phases. This multilevel framework offers a novel and concrete pathway toward establishing interdisciplinary, multilateral, and vertically coordinated <span class="search-hit mathjax">AI</span> governance, transforming global <span class="search-hit mathjax">AI</span> governance challenges into opportunities for political actions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.04766v1-abstract-full').style.display = 'none'; document.getElementById('2503.04766v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 February, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.04739">arXiv:2503.04739</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.04739">pdf</a>, <a href="https://arxiv.org/format/2503.04739">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Responsible Artificial Intelligence Systems: A Roadmap to Society&#39;s Trust through Trustworthy <span class="search-hit mathjax">AI</span>, Auditability, Accountability, and Governance
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Herrera-Poyatos%2C+A">Andrés Herrera-Poyatos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Del+Ser%2C+J">Javier Del Ser</a>, 
      
      <a href="/search/?searchtype=author&amp;query=de+Prado%2C+M+L">Marcos López de Prado</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+F">Fei-Yue Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Herrera-Viedma%2C+E">Enrique Herrera-Viedma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Herrera%2C+F">Francisco Herrera</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.04739v1-abstract-short" style="display: inline;">
        Artificial intelligence (<span class="search-hit mathjax">AI</span>) has matured as a technology, necessitating the development of responsibility frameworks that are fair, inclusive, trustworthy, safe and secure, transparent, and accountable. By establishing such frameworks, we can harness the full potential of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.04739v1-abstract-full').style.display = 'inline'; document.getElementById('2503.04739v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.04739v1-abstract-full" style="display: none;">
        Artificial intelligence (<span class="search-hit mathjax">AI</span>) has matured as a technology, necessitating the development of responsibility frameworks that are fair, inclusive, trustworthy, safe and secure, transparent, and accountable. By establishing such frameworks, we can harness the full potential of <span class="search-hit mathjax">AI</span> while mitigating its risks, particularly in high-risk scenarios. This requires the design of responsible <span class="search-hit mathjax">AI</span> systems based on trustworthy <span class="search-hit mathjax">AI</span> technologies and ethical principles, with the aim of ensuring auditability and accountability throughout their design, development, and deployment, adhering to domain-specific regulations and standards.
  This paper explores the concept of a responsible <span class="search-hit mathjax">AI</span> system from a holistic perspective, which encompasses four key dimensions: 1) regulatory context; 2) trustworthy <span class="search-hit mathjax">AI</span> technology along with standardization and assessments; 3) auditability and accountability; and 4) <span class="search-hit mathjax">AI</span> governance. The aim of this paper is double. First, we analyze and understand these four dimensions and their interconnections in the form of an <span class="search-hit mathjax">analysis</span> and overview. Second, the final goal of the paper is to propose a roadmap in the design of responsible <span class="search-hit mathjax">AI</span> systems, ensuring that they can gain society&#39;s trust. To achieve this trustworthiness, this paper also fosters interdisciplinary discussions on the ethical, <span class="search-hit mathjax">legal</span>, social, economic, and cultural aspects of <span class="search-hit mathjax">AI</span> from a global governance perspective. Last but not least, we also reflect on the current state and those aspects that need to be developed in the near future, as ten lessons learned.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.04739v1-abstract-full').style.display = 'none'; document.getElementById('2503.04739v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 February, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">22 pages, 7 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.0
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.03877">arXiv:2503.03877</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.03877">pdf</a>, <a href="https://arxiv.org/format/2503.03877">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Hardware Architecture">cs.AR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        CRAFT: Characterizing and Root-Causing Fault Injection Threats at Pre-Silicon
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Malik%2C+A+A">Arsalan Ali Malik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mihir%2C+H">Harshvadan Mihir</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aysu%2C+A">Aydin Aysu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.03877v3-abstract-short" style="display: inline;">
        &hellip;is critical to secure the cyberinfrastructure. This work presents a comprehensive methodology for conducting controlled fault injection attacks at the pre-silicon level and an <span class="search-hit mathjax">analysis</span> of the underlying system for root-causing behavior. As the driving application, we use the clock glitch attacks in&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.03877v3-abstract-full').style.display = 'inline'; document.getElementById('2503.03877v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.03877v3-abstract-full" style="display: none;">
        Fault injection attacks represent a class of threats that can compromise embedded systems across multiple layers of abstraction, such as system software, instruction set architecture (ISA), microarchitecture, and physical implementation. Early detection of these vulnerabilities and understanding their root causes, along with their propagation from the physical layer to the system software, is critical to secure the cyberinfrastructure. This work presents a comprehensive methodology for conducting controlled fault injection attacks at the pre-silicon level and an <span class="search-hit mathjax">analysis</span> of the underlying system for root-causing behavior. As the driving application, we use the clock glitch attacks in <span class="search-hit mathjax">AI</span>/ML applications for critical misclassification. Our study aims to characterize and diagnose the impact of faults within the RISC-V instruction set and pipeline stages, while tracing fault propagation from the circuit level to the <span class="search-hit mathjax">AI</span>/ML application software. This <span class="search-hit mathjax">analysis</span> resulted in discovering two new vulnerabilities through controlled clock glitch parameters. First, we reveal a novel method for causing instruction skips, thereby preventing the loading of critical values from memory. This can cause disruption and affect program continuity and correctness. Second, we demonstrate an attack that converts <span class="search-hit mathjax">legal</span> instructions into illegal ones, thereby diverting control flow in a manner exploitable by attackers. Our work underscores the complexity of fault injection attack exploits and emphasizes the importance of preemptive security <span class="search-hit mathjax">analysis</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.03877v3-abstract-full').style.display = 'none'; document.getElementById('2503.03877v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 May, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 5 March, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">6 Pages, 8 Figures, 2 Tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.02784">arXiv:2503.02784</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.02784">pdf</a>, <a href="https://arxiv.org/format/2503.02784">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Do Not Trust Licenses You See: Dataset Compliance Requires Massive-Scale <span class="search-hit mathjax">AI</span>-Powered Lifecycle Tracing
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+J">Jaekyeom Kim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sohn%2C+S">Sungryull Sohn</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jo%2C+G+J">Gerrard Jeongwon Jo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Choi%2C+J">Jihoon Choi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bae%2C+K">Kyunghoon Bae</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lee%2C+H">Hwayoung Lee</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Park%2C+Y">Yongmin Park</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lee%2C+H">Honglak Lee</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.02784v3-abstract-short" style="display: inline;">
        This paper argues that a dataset&#39;s <span class="search-hit mathjax">legal</span> risk cannot be accurately assessed by its license terms alone; instead, tracking dataset redistribution and its full lifecycle is essential. However, this process is too complex for&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.02784v3-abstract-full').style.display = 'inline'; document.getElementById('2503.02784v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.02784v3-abstract-full" style="display: none;">
        This paper argues that a dataset&#39;s <span class="search-hit mathjax">legal</span> risk cannot be accurately assessed by its license terms alone; instead, tracking dataset redistribution and its full lifecycle is essential. However, this process is too complex for <span class="search-hit mathjax">legal</span> experts to handle manually at scale. Tracking dataset provenance, verifying redistribution rights, and assessing evolving <span class="search-hit mathjax">legal</span> risks across multiple stages require a level of precision and efficiency that exceeds human capabilities. Addressing this challenge effectively demands <span class="search-hit mathjax">AI</span> agents that can systematically trace dataset redistribution, analyze compliance, and identify <span class="search-hit mathjax">legal</span> risks. We develop an automated data compliance system called NEXUS and show that <span class="search-hit mathjax">AI</span> can perform these tasks with higher accuracy, efficiency, and cost-effectiveness than human experts. Our massive <span class="search-hit mathjax">legal</span> <span class="search-hit mathjax">analysis</span> of 17,429 unique entities and 8,072 license terms using this approach reveals the discrepancies in <span class="search-hit mathjax">legal</span> rights between the original datasets before redistribution and their redistributed subsets, underscoring the necessity of the data lifecycle-aware compliance. For instance, we find that out of 2,852 datasets with commercially viable individual license terms, only 605 (21%) are <span class="search-hit mathjax">legally</span> permissible for commercialization. This work sets a new standard for <span class="search-hit mathjax">AI</span> data governance, advocating for a framework that systematically examines the entire lifecycle of dataset redistribution to ensure transparent, <span class="search-hit mathjax">legal</span>, and responsible dataset management.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.02784v3-abstract-full').style.display = 'none'; document.getElementById('2503.02784v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 March, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 4 March, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.00841">arXiv:2503.00841</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.00841">pdf</a>, <a href="https://arxiv.org/format/2503.00841">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Law Reasoning Benchmark for LLM with Tree-Organized Structures including Factum Probandum, Evidence and Experiences
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Shen%2C+J">Jiaxin Shen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+J">Jinan Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+H">Huiqi Hu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lin%2C+L">Luyi Lin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zheng%2C+F">Fei Zheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+G">Guoyang Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Meng%2C+F">Fandong Meng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+J">Jie Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Han%2C+W">Wenjuan Han</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.00841v1-abstract-short" style="display: inline;">
        While progress has been made in <span class="search-hit mathjax">legal</span> applications, law reasoning, crucial for fair adjudication, remains unexplored. We propose a transparent law reasoning schema enriched with hierarchical factum probandum, evidence, and implicit experience, enabling public scrutiny and preventing bias. Inspired by this schema, we introduce the challenging task, which take&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.00841v1-abstract-full').style.display = 'inline'; document.getElementById('2503.00841v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.00841v1-abstract-full" style="display: none;">
        While progress has been made in <span class="search-hit mathjax">legal</span> applications, law reasoning, crucial for fair adjudication, remains unexplored. We propose a transparent law reasoning schema enriched with hierarchical factum probandum, evidence, and implicit experience, enabling public scrutiny and preventing bias. Inspired by this schema, we introduce the challenging task, which takes a textual case description and outputs a hierarchical structure justifying the final decision. We also create the first crowd-sourced dataset for this task, enabling comprehensive evaluation. Simultaneously, we propose an agent framework that employs a comprehensive suite of <span class="search-hit mathjax">legal</span> <span class="search-hit mathjax">analysis</span> tools to address the challenge task. This benchmark paves the way for transparent and accountable <span class="search-hit mathjax">AI</span>-assisted law reasoning in the ``Intelligent Court&#39;&#39;.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.00841v1-abstract-full').style.display = 'none'; document.getElementById('2503.00841v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 March, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">20 pages, 13 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.00664">arXiv:2503.00664</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.00664">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/s43681-025-00688-7">10.1007/s43681-025-00688-7 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Generative Artificial Intelligence for Academic Research: Evidence from Guidance Issued for Researchers by Higher Education Institutions in the United States
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ganguly%2C+A">Amrita Ganguly</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Johri%2C+A">Aditya Johri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ali%2C+A">Areej Ali</a>, 
      
      <a href="/search/?searchtype=author&amp;query=McDonald%2C+N">Nora McDonald</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.00664v1-abstract-short" style="display: inline;">
        The recent development and use of generative <span class="search-hit mathjax">AI</span> (GenAI) has signaled a significant shift in research activities such as brainstorming, proposal writing, dissemination, and even reviewing. This has raised questions about how to balance the seemingly productive uses of GenAI with ethical concerns such as authorship and copyright issues, use of biased training&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.00664v1-abstract-full').style.display = 'inline'; document.getElementById('2503.00664v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.00664v1-abstract-full" style="display: none;">
        The recent development and use of generative <span class="search-hit mathjax">AI</span> (GenAI) has signaled a significant shift in research activities such as brainstorming, proposal writing, dissemination, and even reviewing. This has raised questions about how to balance the seemingly productive uses of GenAI with ethical concerns such as authorship and copyright issues, use of biased training data, lack of transparency, and impact on user privacy. To address these concerns, many Higher Education Institutions (HEIs) have released institutional guidance for researchers. To better understand the guidance that is being provided we report findings from a thematic <span class="search-hit mathjax">analysis</span> of guidelines from thirty HEIs in the United States that are classified as R1 or &#39;very high research activity.&#39; We found that guidance provided to researchers: (1) asks them to refer to external sources of information such as funding agencies and publishers to keep updated and use institutional resources for training and education; (2) asks them to understand and learn about specific GenAI attributes that shape research such as predictive modeling, knowledge cutoff date, data provenance, and model limitations, and educate themselves about ethical concerns such as authorship, attribution, privacy, and intellectual property issues; and (3) includes instructions on how to acknowledge sources and disclose the use of GenAI, how to communicate effectively about their GenAI use, and alerts researchers to long term implications such as over reliance on GenAI, <span class="search-hit mathjax">legal</span> consequences, and risks to their institutions from GenAI use. Overall, guidance places the onus of compliance on individual researchers making them accountable for any lapses, thereby increasing their responsibility.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.00664v1-abstract-full').style.display = 'none'; document.getElementById('2503.00664v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 March, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.00433">arXiv:2503.00433</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.00433">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Unveiling <span class="search-hit mathjax">AI&#39;s</span> Threats to Child Protection: Regulatory efforts to Criminalize <span class="search-hit mathjax">AI</span>-Generated CSAM and Emerging Children&#39;s Rights Violations
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kokolaki%2C+E">Emmanouela Kokolaki</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fragopoulou%2C+P">Paraskevi Fragopoulou</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.00433v1-abstract-short" style="display: inline;">
        &hellip;in the field of cybercrime, child sexual abuse material and the protection of children&#39;s rights to safe online experiences. It focuses primarily on the phenomenon of <span class="search-hit mathjax">AI</span>-generated CSAM, sophisticated ways employed for its production which are discussed in dark web forums and the crucial role that the open-source&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.00433v1-abstract-full').style.display = 'inline'; document.getElementById('2503.00433v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.00433v1-abstract-full" style="display: none;">
        This paper aims to present new alarming trends in the field of child sexual abuse through imagery, as part of SafeLine&#39;s research activities in the field of cybercrime, child sexual abuse material and the protection of children&#39;s rights to safe online experiences. It focuses primarily on the phenomenon of <span class="search-hit mathjax">AI</span>-generated CSAM, sophisticated ways employed for its production which are discussed in dark web forums and the crucial role that the open-source <span class="search-hit mathjax">AI</span> models play in the evolution of this overwhelming phenomenon. The paper&#39;s main contribution is a correlation <span class="search-hit mathjax">analysis</span> between the hotline&#39;s reports and domain names identified in dark web forums, where users&#39; discussions focus on exchanging information specifically related to the generation of <span class="search-hit mathjax">AI</span>-CSAM. The objective was to reveal the close connection of clear net and dark web content, which was accomplished through the use of the ATLAS dataset of the Voyager system. Furthermore, through the <span class="search-hit mathjax">analysis</span> of a set of posts&#39; content drilled from the above dataset, valuable conclusions on forum members&#39; techniques employed for the production of <span class="search-hit mathjax">AI</span>-generated CSAM are also drawn, while users&#39; views on this type of content and routes followed in order to overcome technological barriers set with the aim of preventing malicious purposes are also presented. As the ultimate contribution of this research, an overview of the current legislative developments in all country members of the INHOPE organization and the issues arising in the process of regulating the <span class="search-hit mathjax">AI</span>- CSAM is presented, shedding light in the <span class="search-hit mathjax">legal</span> challenges regarding the regulation and limitation of the phenomenon.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.00433v1-abstract-full').style.display = 'none'; document.getElementById('2503.00433v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 March, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.20640">arXiv:2502.20640</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.20640">pdf</a>, <a href="https://arxiv.org/format/2502.20640">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        LexRAG: Benchmarking Retrieval-Augmented Generation in Multi-Turn <span class="search-hit mathjax">Legal</span> Consultation Conversation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+H">Haitao Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Yifan Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+Y">Yiran Hu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ai%2C+Q">Qingyao Ai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+J">Junjie Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+X">Xiaoyu Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+J">Jianhui Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+Y">Yueyue Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Z">Zeyang Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yiqun Liu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.20640v1-abstract-short" style="display: inline;">
        &hellip;highly effective in improving large language models (LLMs) across various domains. However, there is no benchmark specifically designed to assess the effectiveness of RAG in the <span class="search-hit mathjax">legal</span> domain, which restricts progress in this area. To fill this gap, we propose LexRAG, the first benchmark to evaluate RAG systems for multi-turn&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.20640v1-abstract-full').style.display = 'inline'; document.getElementById('2502.20640v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.20640v1-abstract-full" style="display: none;">
        Retrieval-augmented generation (RAG) has proven highly effective in improving large language models (LLMs) across various domains. However, there is no benchmark specifically designed to assess the effectiveness of RAG in the <span class="search-hit mathjax">legal</span> domain, which restricts progress in this area. To fill this gap, we propose LexRAG, the first benchmark to evaluate RAG systems for multi-turn <span class="search-hit mathjax">legal</span> consultations. LexRAG consists of 1,013 multi-turn dialogue samples and 17,228 candidate <span class="search-hit mathjax">legal</span> articles. Each sample is annotated by <span class="search-hit mathjax">legal</span> experts and consists of five rounds of progressive questioning. LexRAG includes two key tasks: (1) Conversational knowledge retrieval, requiring accurate retrieval of relevant <span class="search-hit mathjax">legal</span> articles based on multi-turn context. (2) Response generation, focusing on producing <span class="search-hit mathjax">legally</span> sound answers. To ensure reliable reproducibility, we develop LexiT, a <span class="search-hit mathjax">legal</span> RAG toolkit that provides a comprehensive implementation of RAG system components tailored for the <span class="search-hit mathjax">legal</span> domain. Additionally, we introduce an LLM-as-a-judge evaluation pipeline to enable detailed and effective assessment. Through experimental <span class="search-hit mathjax">analysis</span> of various LLMs and retrieval methods, we reveal the key limitations of existing RAG systems in handling <span class="search-hit mathjax">legal</span> consultation conversations. LexRAG establishes a new benchmark for the practical application of RAG systems in the <span class="search-hit mathjax">legal</span> domain, with its code and data available at https://github.com/CSHaitao/LexRAG.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.20640v1-abstract-full').style.display = 'none'; document.getElementById('2502.20640v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 February, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.17638">arXiv:2502.17638</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.17638">pdf</a>, <a href="https://arxiv.org/format/2502.17638">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards Robust <span class="search-hit mathjax">Legal</span> Reasoning: Harnessing Logical LLMs in Law
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kant%2C+M">Manuj Kant</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nabi%2C+S">Sareh Nabi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kant%2C+M">Manav Kant</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Scharrer%2C+R">Roland Scharrer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+M">Megan Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nabi%2C+M">Marzieh Nabi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.17638v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Legal</span> services rely heavily on text processing. While large language models (LLMs) show promise, their application in&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.17638v1-abstract-full').style.display = 'inline'; document.getElementById('2502.17638v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.17638v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Legal</span> services rely heavily on text processing. While large language models (LLMs) show promise, their application in <span class="search-hit mathjax">legal</span> contexts demands higher accuracy, repeatability, and transparency. Logic programs, by encoding <span class="search-hit mathjax">legal</span> concepts as structured rules and facts, offer reliable automation, but require sophisticated text extraction. We propose a neuro-symbolic approach that integrates LLMs&#39; natural language understanding with logic-based reasoning to address these limitations.
  As a <span class="search-hit mathjax">legal</span> document case study, we applied neuro-symbolic <span class="search-hit mathjax">AI</span> to coverage-related queries in insurance contracts using both closed and open-source LLMs. While LLMs have improved in <span class="search-hit mathjax">legal</span> reasoning, they still lack the accuracy and consistency required for complex contract <span class="search-hit mathjax">analysis</span>. In our <span class="search-hit mathjax">analysis</span>, we tested three methodologies to evaluate whether a specific claim is covered under a contract: a vanilla LLM, an unguided approach that leverages LLMs to encode both the contract and the claim, and a guided approach that uses a framework for the LLM to encode the contract. We demonstrated the promising capabilities of LLM + Logic in the guided approach.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.17638v1-abstract-full').style.display = 'none'; document.getElementById('2502.17638v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 February, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.16184">arXiv:2502.16184</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.16184">pdf</a>, <a href="https://arxiv.org/format/2502.16184">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Robustness and Cybersecurity in the EU Artificial Intelligence Act
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Nolte%2C+H">Henrik Nolte</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rateike%2C+M">Miriam Rateike</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Finck%2C+M">Michèle Finck</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.16184v1-abstract-short" style="display: inline;">
        The EU Artificial Intelligence Act (AIA) establishes different <span class="search-hit mathjax">legal</span> principles for different types of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.16184v1-abstract-full').style.display = 'inline'; document.getElementById('2502.16184v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.16184v1-abstract-full" style="display: none;">
        The EU Artificial Intelligence Act (AIA) establishes different <span class="search-hit mathjax">legal</span> principles for different types of <span class="search-hit mathjax">AI</span> systems. While prior work has sought to clarify some of these principles, little attention has been paid to robustness and cybersecurity. This paper aims to fill this gap. We identify <span class="search-hit mathjax">legal</span> challenges and shortcomings in provisions related to robustness and cybersecurity for high-risk <span class="search-hit mathjax">AI</span> systems (Art. 15 AIA) and general-purpose <span class="search-hit mathjax">AI</span> models (Art. 55 AIA). We show that robustness and cybersecurity demand resilience against performance disruptions. Furthermore, we assess potential challenges in implementing these provisions in light of recent advancements in the machine learning (ML) literature. Our <span class="search-hit mathjax">analysis</span> informs efforts to develop harmonized standards, guidelines by the European Commission, as well as benchmarks and measurement methodologies under Art. 15(2) AIA. With this, we seek to bridge the gap between <span class="search-hit mathjax">legal</span> terminology and ML research, fostering a better alignment between research and implementation efforts.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.16184v1-abstract-full').style.display = 'none'; document.getElementById('2502.16184v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 February, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.15838">arXiv:2502.15838</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.15838">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A novel approach to the relationships between data features -- based on comprehensive examination of mathematical, technological, and causal methodology
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+J">JaeHong Kim</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.15838v1-abstract-short" style="display: inline;">
        The expansion of artificial intelligence (<span class="search-hit mathjax">AI</span>) has raised concerns about transparency, accountability, and interpretability, with counterfactual reasoning emerging as a key approach to addressing these issues. However, current mathematical, technological, and causal methodologies rely on externalization techniques that normalize feature relationships within a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.15838v1-abstract-full').style.display = 'inline'; document.getElementById('2502.15838v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.15838v1-abstract-full" style="display: none;">
        The expansion of artificial intelligence (<span class="search-hit mathjax">AI</span>) has raised concerns about transparency, accountability, and interpretability, with counterfactual reasoning emerging as a key approach to addressing these issues. However, current mathematical, technological, and causal methodologies rely on externalization techniques that normalize feature relationships within a single coordinate space, often distorting intrinsic interactions. This study proposes the Convergent Fusion Paradigm (CFP) theory, a framework integrating mathematical, technological, and causal perspectives to provide a more precise and comprehensive <span class="search-hit mathjax">analysis</span> of feature relationships. CFP theory introduces Hilbert space and backward causation to reinterpret the feature relationships as emergent structures, offering a potential solution to the common cause problem -- a fundamental challenge in causal modeling. From a mathematical -- technical perspective, it utilizes a Riemannian manifold-based framework, thereby improving the structural representation of high- and low-dimensional data interactions. From a causal inference perspective, CFP theory adopts abduction as a methodological foundation, employing Hilbert space for a dynamic causal reasoning approach, where causal relationships are inferred abductively, and feature relationships evolve as emergent properties. Ultimately, CFP theory introduces a novel <span class="search-hit mathjax">AI</span> modeling methodology that integrates Hilbert space, backward causation, and Riemannian geometry, strengthening <span class="search-hit mathjax">AI</span> governance and transparency in counterfactual reasoning.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.15838v1-abstract-full').style.display = 'none'; document.getElementById('2502.15838v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 February, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">59 pages, 6 figures, 2 tables</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68T27 (Primary) 00A30; 03A05 (Secondary)
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.3; F.4.1
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.15719">arXiv:2502.15719</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.15719">pdf</a>, <a href="https://arxiv.org/ps/2502.15719">ps</a>, <a href="https://arxiv.org/format/2502.15719">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Governing <span class="search-hit mathjax">AI</span> Beyond the Pretraining Frontier
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Caputo%2C+N+A">Nicholas A. Caputo</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.15719v1-abstract-short" style="display: inline;">
        This year, jurisdictions worldwide, including the United States, the European Union, the United Kingdom, and China, are set to enact or revise laws governing frontier <span class="search-hit mathjax">AI</span>. Their efforts largely rely on the assumption that increasing model scale through pretraining is the path to more advanced&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.15719v1-abstract-full').style.display = 'inline'; document.getElementById('2502.15719v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.15719v1-abstract-full" style="display: none;">
        This year, jurisdictions worldwide, including the United States, the European Union, the United Kingdom, and China, are set to enact or revise laws governing frontier <span class="search-hit mathjax">AI</span>. Their efforts largely rely on the assumption that increasing model scale through pretraining is the path to more advanced <span class="search-hit mathjax">AI</span> capabilities. Yet growing evidence suggests that this &#34;pretraining paradigm&#34; may be hitting a wall and major <span class="search-hit mathjax">AI</span> companies are turning to alternative approaches, like inference-time &#34;reasoning,&#34; to boost capabilities instead.
  This paradigm shift presents fundamental challenges for the frontier <span class="search-hit mathjax">AI</span> governance frameworks that target pretraining scale as a key bottleneck useful for monitoring, control, and exclusion, threatening to undermine this new <span class="search-hit mathjax">legal</span> order as it emerges. This essay seeks to identify these challenges and point to new paths forward for regulation. First, we examine the existing frontier <span class="search-hit mathjax">AI</span> regulatory regime and analyze some key traits and vulnerabilities. Second, we introduce the concept of the &#34;pretraining frontier,&#34; the capabilities threshold made possible by scaling up pretraining alone, and demonstrate how it could make the regulatory field more diffuse and complex and lead to new forms of competition. Third, we lay out a regulatory approach that focuses on increasing transparency and leveraging new natural technical bottlenecks to effectively oversee changing frontier <span class="search-hit mathjax">AI</span> development while minimizing regulatory burdens and protecting fundamental rights. Our <span class="search-hit mathjax">analysis</span> provides concrete mechanisms for governing frontier <span class="search-hit mathjax">AI</span> systems across diverse technical paradigms, offering policymakers tools for addressing both current and future regulatory challenges in frontier <span class="search-hit mathjax">AI</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.15719v1-abstract-full').style.display = 'none'; document.getElementById('2502.15719v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 January, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">14 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.14296">arXiv:2502.14296</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.14296">pdf</a>, <a href="https://arxiv.org/format/2502.14296">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On the Trustworthiness of Generative Foundation Models: Guideline, Assessment, and Perspective
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+Y">Yue Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+C">Chujie Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+S">Siyuan Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+H">Haoran Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+X">Xiangqi Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+Y">Yujun Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yanbo Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ye%2C+J">Jiayi Ye</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shi%2C+J">Jiawen Shi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Q">Qihui Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Y">Yuan Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bao%2C+H">Han Bao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Z">Zhaoyi Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guan%2C+T">Tianrui Guan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+D">Dongping Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+R">Ruoxi Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guo%2C+K">Kehan Guo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zou%2C+A">Andy Zou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kuen-Yew%2C+B+H">Bryan Hooi Kuen-Yew</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiong%2C+C">Caiming Xiong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Stengel-Eskin%2C+E">Elias Stengel-Eskin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+H">Hongyang Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yin%2C+H">Hongzhi Yin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+H">Huan Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yao%2C+H">Huaxiu Yao</a>
      , et al. (41 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.14296v3-abstract-short" style="display: inline;">
        &hellip;across dimensions. This paper presents a comprehensive framework to address these challenges through three key contributions. First, we systematically review global <span class="search-hit mathjax">AI</span> governance laws and policies from governments and regulatory bodies, as well as industry practices and standards. Based on this&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.14296v3-abstract-full').style.display = 'inline'; document.getElementById('2502.14296v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.14296v3-abstract-full" style="display: none;">
        Generative Foundation Models (GenFMs) have emerged as transformative tools. However, their widespread adoption raises critical concerns regarding trustworthiness across dimensions. This paper presents a comprehensive framework to address these challenges through three key contributions. First, we systematically review global <span class="search-hit mathjax">AI</span> governance laws and policies from governments and regulatory bodies, as well as industry practices and standards. Based on this <span class="search-hit mathjax">analysis</span>, we propose a set of guiding principles for GenFMs, developed through extensive multidisciplinary collaboration that integrates technical, ethical, <span class="search-hit mathjax">legal</span>, and societal perspectives. Second, we introduce TrustGen, the first dynamic benchmarking platform designed to evaluate trustworthiness across multiple dimensions and model types, including text-to-image, large language, and vision-language models. TrustGen leverages modular components--metadata curation, test case generation, and contextual variation--to enable adaptive and iterative assessments, overcoming the limitations of static evaluation methods. Using TrustGen, we reveal significant progress in trustworthiness while identifying persistent challenges. Finally, we provide an in-depth discussion of the challenges and future directions for trustworthy GenFMs, which reveals the complex, evolving nature of trustworthiness, highlighting the nuanced trade-offs between utility and trustworthiness, and consideration for various downstream applications, identifying persistent challenges and providing a strategic roadmap for future research. This work establishes a holistic framework for advancing trustworthiness in GenAI, paving the way for safer and more responsible integration of GenFMs into critical applications. To facilitate advancement in the community, we release the toolkit for dynamic evaluation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.14296v3-abstract-full').style.display = 'none'; document.getElementById('2502.14296v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 May, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 20 February, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.12193">arXiv:2502.12193</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.12193">pdf</a>, <a href="https://arxiv.org/format/2502.12193">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">AI</span> and the Law: Evaluating ChatGPT&#39;s Performance in <span class="search-hit mathjax">Legal</span> Classification
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Weichbroth%2C+P">Pawel Weichbroth</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.12193v1-abstract-short" style="display: inline;">
        &hellip;this issue has not been studied in the context of the Polish language. This study addresses this research gap by evaluating the effectiveness of ChatGPT in classifying <span class="search-hit mathjax">legal</span> cases under the Polish Penal Code. The results show excellent binary classification accuracy, with all positive and negative cases correctly categorized. In addition, a qualitative eval&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.12193v1-abstract-full').style.display = 'inline'; document.getElementById('2502.12193v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.12193v1-abstract-full" style="display: none;">
        The use of ChatGPT to analyze and classify evidence in criminal proceedings has been a topic of ongoing discussion. However, to the best of our knowledge, this issue has not been studied in the context of the Polish language. This study addresses this research gap by evaluating the effectiveness of ChatGPT in classifying <span class="search-hit mathjax">legal</span> cases under the Polish Penal Code. The results show excellent binary classification accuracy, with all positive and negative cases correctly categorized. In addition, a qualitative evaluation confirms that the <span class="search-hit mathjax">legal</span> basis provided for each case, along with the relevant <span class="search-hit mathjax">legal</span> content, was appropriate. The results obtained suggest that ChatGPT can effectively analyze and classify evidence while applying the appropriate <span class="search-hit mathjax">legal</span> rules. In conclusion, ChatGPT has the potential to assist interested parties in the <span class="search-hit mathjax">analysis</span> of evidence and serve as a valuable <span class="search-hit mathjax">legal</span> resource for individuals with less experience or knowledge in this area.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.12193v1-abstract-full').style.display = 'none'; document.getElementById('2502.12193v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 February, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">15 pages; 1 figure; 2 tables; 32 references</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.12102">arXiv:2502.12102</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.12102">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Emerging Technologies">cs.ET</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Relational Norms for Human-<span class="search-hit mathjax">AI</span> Cooperation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Earp%2C+B+D">Brian D. Earp</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mann%2C+S+P">Sebastian Porsdam Mann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aboy%2C+M">Mateo Aboy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Awad%2C+E">Edmond Awad</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Betzler%2C+M">Monika Betzler</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Botes%2C+M">Marietjie Botes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Calcott%2C+R">Rachel Calcott</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Caraccio%2C+M">Mina Caraccio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chater%2C+N">Nick Chater</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Coeckelbergh%2C+M">Mark Coeckelbergh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Constantinescu%2C+M">Mihaela Constantinescu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dabbagh%2C+H">Hossein Dabbagh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Devlin%2C+K">Kate Devlin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+X">Xiaojun Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dranseika%2C+V">Vilius Dranseika</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Everett%2C+J+A+C">Jim A. C. Everett</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fan%2C+R">Ruiping Fan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Feroz%2C+F">Faisal Feroz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Francis%2C+K+B">Kathryn B. Francis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Friedman%2C+C">Cindy Friedman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Friedrich%2C+O">Orsolya Friedrich</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gabriel%2C+I">Iason Gabriel</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hannikainen%2C+I">Ivar Hannikainen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hellmann%2C+J">Julie Hellmann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jahrome%2C+A+K">Arasj Khodadade Jahrome</a>
      , et al. (37 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.12102v1-abstract-short" style="display: inline;">
        How we should design and interact with social artificial intelligence depends on the socio-relational role the <span class="search-hit mathjax">AI</span> is meant to emulate or occupy. In human society, relationships such as teacher-student, parent-child, neighbors, siblings, or employer-employee are governed by specific norms that prescribe or proscribe cooperative functions including hierarchy,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.12102v1-abstract-full').style.display = 'inline'; document.getElementById('2502.12102v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.12102v1-abstract-full" style="display: none;">
        How we should design and interact with social artificial intelligence depends on the socio-relational role the <span class="search-hit mathjax">AI</span> is meant to emulate or occupy. In human society, relationships such as teacher-student, parent-child, neighbors, siblings, or employer-employee are governed by specific norms that prescribe or proscribe cooperative functions including hierarchy, care, transaction, and mating. These norms shape our judgments of what is appropriate for each partner. For example, workplace norms may allow a boss to give orders to an employee, but not vice versa, reflecting hierarchical and transactional expectations. As <span class="search-hit mathjax">AI</span> agents and chatbots powered by large language models are increasingly designed to serve roles analogous to human positions - such as assistant, mental health provider, tutor, or romantic partner - it is imperative to examine whether and how human relational norms should extend to human-<span class="search-hit mathjax">AI</span> interactions. Our <span class="search-hit mathjax">analysis</span> explores how differences between <span class="search-hit mathjax">AI</span> systems and humans, such as the absence of conscious experience and immunity to fatigue, may affect an <span class="search-hit mathjax">AI&#39;s</span> capacity to fulfill relationship-specific functions and adhere to corresponding norms. This <span class="search-hit mathjax">analysis</span>, which is a collaborative effort by philosophers, psychologists, relationship scientists, ethicists, <span class="search-hit mathjax">legal</span> experts, and <span class="search-hit mathjax">AI</span> researchers, carries important implications for <span class="search-hit mathjax">AI</span> systems design, user behavior, and regulation. While we accept that <span class="search-hit mathjax">AI</span> systems can offer significant benefits such as increased availability and consistency in certain socio-relational roles, they also risk fostering unhealthy dependencies or unrealistic expectations that could spill over into human-human relationships. We propose that understanding and thoughtfully shaping (or implementing) suitable human-<span class="search-hit mathjax">AI</span> relational norms will be crucial for ensuring that human-<span class="search-hit mathjax">AI</span> interactions are ethical, trustworthy, and favorable to human well-being.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.12102v1-abstract-full').style.display = 'none'; document.getElementById('2502.12102v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 February, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">76 pages, 2 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.10413">arXiv:2502.10413</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.10413">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.6084/m9.figshare.28259810">10.6084/m9.figshare.28259810 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Machine Learning-Driven Convergence <span class="search-hit mathjax">Analysis</span> in Multijurisdictional Compliance Using BERT and K-Means Clustering
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sonani%2C+R">Raj Sonani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Prayas%2C+L">Lohalekar Prayas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.10413v1-abstract-short" style="display: inline;">
        &hellip;lessons from this report, as it outlines strategies for better enforcement of laws across different nations. Additionally, the paper discusses the challenges of utilizing NLP in <span class="search-hit mathjax">legal</span> literature and proposes methods to enhance the model-ability of machine learning models for studying regulations. The study&#39;s objective is to &#34;bridge the gap between&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.10413v1-abstract-full').style.display = 'inline'; document.getElementById('2502.10413v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.10413v1-abstract-full" style="display: none;">
        Digital data continues to grow, there has been a shift towards using effective regulatory mechanisms to safeguard personal information. The CCPA of California and the General Data Protection Regulation (GDPR) of the European Union are two of the most important privacy laws. The regulation is intended to safeguard consumer privacy, but it varies greatly in scope, definitions, and methods of enforcement. This paper presents a fresh approach to adaptive compliance, using machine learning and emphasizing natural language processing (NLP) as the primary focus of comparison between the GDPR and CCPA. Using NLP, this study compares various regulations to identify areas where they overlap or diverge. This includes the &#34;right to be forgotten&#34; provision in the GDPR and the &#34;opt-out of sale&#34; provision under CCPA. International companies can learn valuable lessons from this report, as it outlines strategies for better enforcement of laws across different nations. Additionally, the paper discusses the challenges of utilizing NLP in <span class="search-hit mathjax">legal</span> literature and proposes methods to enhance the model-ability of machine learning models for studying regulations. The study&#39;s objective is to &#34;bridge the gap between <span class="search-hit mathjax">legal</span> knowledge and technical expertise&#34; by developing regulatory compliance strategies that are more efficient in operation and more effective in data protection.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.10413v1-abstract-full').style.display = 'none'; document.getElementById('2502.10413v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 January, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">16 pages, 5 figures, 4 tables</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Aitoz Journal of <span class="search-hit mathjax">AI</span> Research 3 (2024) 126-141
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.10036">arXiv:2502.10036</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.10036">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Automation Bias in the <span class="search-hit mathjax">AI</span> Act: On the <span class="search-hit mathjax">Legal</span> Implications of Attempting to De-Bias Human Oversight of <span class="search-hit mathjax">AI</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Laux%2C+J">Johann Laux</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ruschemeier%2C+H">Hannah Ruschemeier</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.10036v1-abstract-short" style="display: inline;">
        This paper examines the <span class="search-hit mathjax">legal</span> implications of the explicit mentioning of automation bias (AB) in the Artificial Intelligence Act (AIA). The AIA mandates human oversight for high-risk&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.10036v1-abstract-full').style.display = 'inline'; document.getElementById('2502.10036v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.10036v1-abstract-full" style="display: none;">
        This paper examines the <span class="search-hit mathjax">legal</span> implications of the explicit mentioning of automation bias (AB) in the Artificial Intelligence Act (AIA). The AIA mandates human oversight for high-risk <span class="search-hit mathjax">AI</span> systems and requires providers to enable awareness of AB, i.e., the tendency to over-rely on <span class="search-hit mathjax">AI</span> outputs. The paper analyses how this extra-juridical concept is embedded in the AIA, the division of responsibility between <span class="search-hit mathjax">AI</span> providers and deployers, and the challenges of <span class="search-hit mathjax">legally</span> enforcing this novel awareness requirement. The <span class="search-hit mathjax">analysis</span> shows that the AIA&#39;s focus on providers does not adequately address design and context as causes of AB, and questions whether the AIA should directly regulate the risk of AB rather than just mandating awareness. As the AIA&#39;s approach requires a balance between <span class="search-hit mathjax">legal</span> mandates and behavioural science, the paper proposes that harmonised standards should reference the state of research on AB and human-<span class="search-hit mathjax">AI</span> interaction. Ultimately, further empirical research will be essential for effective safeguards.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.10036v1-abstract-full').style.display = 'none'; document.getElementById('2502.10036v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 February, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.08652">arXiv:2502.08652</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.08652">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        LegalScore: Development of a Benchmark for Evaluating <span class="search-hit mathjax">AI</span> Models in <span class="search-hit mathjax">Legal</span> Career Exams in Brazil
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Caparroz%2C+R">Roberto Caparroz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Roitman%2C+M">Marcelo Roitman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chow%2C+B+G">Beatriz G. Chow</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Giusti%2C+C">Caroline Giusti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Torhacs%2C+L">Larissa Torhacs</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sola%2C+P+A">Pedro A. Sola</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Diogo%2C+J+H+M">João H. M. Diogo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Balby%2C+L">Luiza Balby</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vasconcelos%2C+C+D+L">Carolina D. L. Vasconcelos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Caparroz%2C+L+R">Leonardo R. Caparroz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Franco%2C+A+P">Albano P. Franco</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.08652v1-abstract-short" style="display: inline;">
        This research introduces LegalScore, a specialized index for assessing how generative artificial intelligence models perform in a selected range of career exams that require a <span class="search-hit mathjax">legal</span> background in Brazil. The index evaluates fourteen different types of artificial intelligence models&#39; performance, from proprietary to open-source models, in answering object&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.08652v1-abstract-full').style.display = 'inline'; document.getElementById('2502.08652v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.08652v1-abstract-full" style="display: none;">
        This research introduces LegalScore, a specialized index for assessing how generative artificial intelligence models perform in a selected range of career exams that require a <span class="search-hit mathjax">legal</span> background in Brazil. The index evaluates fourteen different types of artificial intelligence models&#39; performance, from proprietary to open-source models, in answering objective questions applied to these exams. The research uncovers the response of the models when applying English-trained large language models to Brazilian <span class="search-hit mathjax">legal</span> contexts, leading us to reflect on the importance and the need for Brazil-specific training data in generative artificial intelligence models. Performance <span class="search-hit mathjax">analysis</span> shows that while proprietary and most known models achieved better results overall, local and smaller models indicated promising performances due to their Brazilian context alignment in training. By establishing an evaluation framework with metrics including accuracy, confidence intervals, and normalized scoring, LegalScore enables systematic assessment of artificial intelligence performance in <span class="search-hit mathjax">legal</span> examinations in Brazil. While the study demonstrates artificial intelligence&#39;s potential value for exam preparation and question development, it concludes that significant improvements are needed before <span class="search-hit mathjax">AI</span> can match human performance in advanced <span class="search-hit mathjax">legal</span> assessments. The benchmark creates a foundation for continued research, highlighting the importance of local adaptation in artificial intelligence development.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.08652v1-abstract-full').style.display = 'none'; document.getElementById('2502.08652v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 January, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Main article 25 pages, Appendices from page 26</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.07771">arXiv:2502.07771</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.07771">pdf</a>, <a href="https://arxiv.org/format/2502.07771">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Breaking Down Bias: On The Limits of Generalizable Pruning Strategies
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+S">Sibo Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Salinas%2C+A">Alejandro Salinas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Henderson%2C+P">Peter Henderson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nyarko%2C+J">Julian Nyarko</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.07771v1-abstract-short" style="display: inline;">
        We employ model pruning to examine how LLMs conceptualize racial biases, and whether a generalizable mitigation strategy for such biases appears feasible. Our <span class="search-hit mathjax">analysis</span> yields several novel insights. We find that pruning can be an effective method to reduce bias without significantly increasing anomalous model behavior. Neuron-based pruning strategies general&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.07771v1-abstract-full').style.display = 'inline'; document.getElementById('2502.07771v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.07771v1-abstract-full" style="display: none;">
        We employ model pruning to examine how LLMs conceptualize racial biases, and whether a generalizable mitigation strategy for such biases appears feasible. Our <span class="search-hit mathjax">analysis</span> yields several novel insights. We find that pruning can be an effective method to reduce bias without significantly increasing anomalous model behavior. Neuron-based pruning strategies generally yield better results than approaches pruning entire attention heads. However, our results also show that the effectiveness of either approach quickly deteriorates as pruning strategies become more generalized. For instance, a model that is trained on removing racial biases in the context of financial decision-making poorly generalizes to biases in commercial transactions. Overall, our <span class="search-hit mathjax">analysis</span> suggests that racial biases are only partially represented as a general concept within language models. The other part of these biases is highly context-specific, suggesting that generalizable mitigation strategies may be of limited effectiveness. Our findings have important implications for <span class="search-hit mathjax">legal</span> frameworks surrounding <span class="search-hit mathjax">AI</span>. In particular, they suggest that an effective mitigation strategy should include the allocation of <span class="search-hit mathjax">legal</span> responsibility on those that deploy models in a specific use case.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.07771v1-abstract-full').style.display = 'none'; document.getElementById('2502.07771v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 February, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">28 pages, 9 figures, 1 table</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.03487">arXiv:2502.03487</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.03487">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Artificial Intelligence and <span class="search-hit mathjax">Legal</span> <span class="search-hit mathjax">Analysis</span>: Implications for <span class="search-hit mathjax">Legal</span> Education and the Profession
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Peoples%2C+L">Lee Peoples</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.03487v1-abstract-short" style="display: inline;">
        This article reports the results of a study examining the ability of <span class="search-hit mathjax">legal</span> and non-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.03487v1-abstract-full').style.display = 'inline'; document.getElementById('2502.03487v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.03487v1-abstract-full" style="display: none;">
        This article reports the results of a study examining the ability of <span class="search-hit mathjax">legal</span> and non-<span class="search-hit mathjax">legal</span> Large Language Models to perform <span class="search-hit mathjax">legal</span> <span class="search-hit mathjax">analysis</span> using the Issue-Rule-Application-Conclusion framework. LLMs were tested on <span class="search-hit mathjax">legal</span> reasoning tasks involving rule <span class="search-hit mathjax">analysis</span> and analogical reasoning. The results show that LLMs can conduct basic IRAC <span class="search-hit mathjax">analysis</span>, but are limited by brief responses lacking detail, an inability to commit to answers, false confidence, and hallucinations. The study compares <span class="search-hit mathjax">legal</span> and nonlegal LLMs, identifies shortcomings, and explores traits that may hinder their ability to think like a lawyer. It also discusses the implications for <span class="search-hit mathjax">legal</span> education and practice, highlighting the need for critical thinking skills in future lawyers and the potential pitfalls of overreliance on artificial intelligence <span class="search-hit mathjax">AI</span> resulting in a loss of logic, reasoning, and critical thinking skills.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.03487v1-abstract-full').style.display = 'none'; document.getElementById('2502.03487v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 February, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        117 Law Library Journal No. 1 2025
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.03376">arXiv:2502.03376</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.03376">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Ethical Considerations for the Military Use of Artificial Intelligence in Visual Reconnaissance
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Anneken%2C+M">Mathias Anneken</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Burkart%2C+N">Nadia Burkart</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jeschke%2C+F">Fabian Jeschke</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kuwertz-Wolf%2C+A">Achim Kuwertz-Wolf</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mueller%2C+A">Almuth Mueller</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schumann%2C+A">Arne Schumann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Teutsch%2C+M">Michael Teutsch</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.03376v1-abstract-short" style="display: inline;">
        This white paper underscores the critical importance of responsibly deploying Artificial Intelligence (<span class="search-hit mathjax">AI</span>) in military contexts, emphasizing a commitment to ethical and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.03376v1-abstract-full').style.display = 'inline'; document.getElementById('2502.03376v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.03376v1-abstract-full" style="display: none;">
        This white paper underscores the critical importance of responsibly deploying Artificial Intelligence (<span class="search-hit mathjax">AI</span>) in military contexts, emphasizing a commitment to ethical and <span class="search-hit mathjax">legal</span> standards. The evolving role of <span class="search-hit mathjax">AI</span> in the military goes beyond mere technical applications, necessitating a framework grounded in ethical principles. The discussion within the paper delves into ethical <span class="search-hit mathjax">AI</span> principles, particularly focusing on the Fairness, Accountability, Transparency, and Ethics (FATE) guidelines. Noteworthy considerations encompass transparency, justice, non-maleficence, and responsibility. Importantly, the paper extends its examination to military-specific ethical considerations, drawing insights from the Just War theory and principles established by prominent entities. In addition to the identified principles, the paper introduces further ethical considerations specifically tailored for military <span class="search-hit mathjax">AI</span> applications. These include traceability, proportionality, governability, responsibility, and reliability. The application of these ethical principles is discussed on the basis of three use cases in the domains of sea, air, and land. Methods of automated sensor data <span class="search-hit mathjax">analysis</span>, eXplainable <span class="search-hit mathjax">AI</span> (XAI), and intuitive user experience are utilized to specify the use cases close to real-world scenarios. This comprehensive approach to ethical considerations in military <span class="search-hit mathjax">AI</span> reflects a commitment to aligning technological advancements with established ethical frameworks. It recognizes the need for a balance between leveraging <span class="search-hit mathjax">AI&#39;s</span> potential benefits in military operations while upholding moral and <span class="search-hit mathjax">legal</span> standards. The inclusion of these ethical principles serves as a foundation for responsible and accountable use of <span class="search-hit mathjax">AI</span> in the complex and dynamic landscape of military scenarios.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.03376v1-abstract-full').style.display = 'none'; document.getElementById('2502.03376v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 February, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">White Paper, 30 pages, 7 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.01306">arXiv:2502.01306</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.01306">pdf</a>, <a href="https://arxiv.org/format/2502.01306">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Expert-Generated Privacy Q&amp;A Dataset for Conversational <span class="search-hit mathjax">AI</span> and User Study Insights
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Leschanowsky%2C+A">Anna Leschanowsky</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Salamatjoo%2C+F">Farnaz Salamatjoo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kolagar%2C+Z">Zahra Kolagar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Popp%2C+B">Birgit Popp</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.01306v1-abstract-short" style="display: inline;">
        &hellip;process personal data and must comply with data protection regulations that require providers to be transparent with users about how their data is handled. Transparency, in a <span class="search-hit mathjax">legal</span> sense, demands preciseness, comprehensibility and accessibility, yet existing solutions fail to meet these requirements. To address this, we introduce a new human-expert-generated&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.01306v1-abstract-full').style.display = 'inline'; document.getElementById('2502.01306v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.01306v1-abstract-full" style="display: none;">
        Conversational assistants process personal data and must comply with data protection regulations that require providers to be transparent with users about how their data is handled. Transparency, in a <span class="search-hit mathjax">legal</span> sense, demands preciseness, comprehensibility and accessibility, yet existing solutions fail to meet these requirements. To address this, we introduce a new human-expert-generated dataset for Privacy Question-Answering (Q&amp;A), developed through an iterative process involving <span class="search-hit mathjax">legal</span> professionals and conversational designers. We evaluate this dataset through linguistic <span class="search-hit mathjax">analysis</span> and a user study, comparing it to privacy policy excerpts and state-of-the-art responses from Amazon Alexa. Our findings show that the proposed answers improve usability and clarity compared to existing solutions while achieving <span class="search-hit mathjax">legal</span> preciseness, thereby enhancing the accessibility of data processing information for Conversational <span class="search-hit mathjax">AI</span> and Natural Language Processing applications.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.01306v1-abstract-full').style.display = 'none'; document.getElementById('2502.01306v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 February, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted to CHI&#39;25</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.00289">arXiv:2502.00289</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.00289">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Agentic <span class="search-hit mathjax">AI</span>: Autonomy, Accountability, and the Algorithmic Society
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mukherjee%2C+A">Anirban Mukherjee</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chang%2C+H+H">Hannah Hanwen Chang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.00289v3-abstract-short" style="display: inline;">
        Agentic Artificial Intelligence (<span class="search-hit mathjax">AI</span>) can autonomously pursue long-term goals, make decisions, and execute complex, multi-turn workflows. Unlike traditional generative&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.00289v3-abstract-full').style.display = 'inline'; document.getElementById('2502.00289v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.00289v3-abstract-full" style="display: none;">
        Agentic Artificial Intelligence (<span class="search-hit mathjax">AI</span>) can autonomously pursue long-term goals, make decisions, and execute complex, multi-turn workflows. Unlike traditional generative <span class="search-hit mathjax">AI</span>, which responds reactively to prompts, agentic <span class="search-hit mathjax">AI</span> proactively orchestrates processes, such as autonomously managing complex tasks or making real-time decisions. This transition from advisory roles to proactive execution challenges established <span class="search-hit mathjax">legal</span>, economic, and creative frameworks. In this paper, we explore challenges in three interrelated domains: creativity and intellectual property, <span class="search-hit mathjax">legal</span> and ethical considerations, and competitive effects. Central to our <span class="search-hit mathjax">analysis</span> is the tension between novelty and usefulness in <span class="search-hit mathjax">AI</span>-generated creative outputs, as well as the intellectual property and authorship challenges arising from <span class="search-hit mathjax">AI</span> autonomy. We highlight gaps in responsibility attribution and liability that create a &#34;moral crumple zone&#34;--a condition where accountability is diffused across multiple actors, leaving end-users and developers in precarious <span class="search-hit mathjax">legal</span> and ethical positions. We examine the competitive dynamics of two-sided algorithmic markets, where both sellers and buyers deploy <span class="search-hit mathjax">AI</span> agents, potentially mitigating or amplifying tacit collusion risks. We explore the potential for emergent self-regulation within networks of agentic <span class="search-hit mathjax">AI</span>--the development of an &#34;algorithmic society&#34;--raising critical questions: To what extent would these norms align with societal values? What unintended consequences might arise? How can transparency and accountability be ensured? Addressing these challenges will necessitate interdisciplinary collaboration to redefine <span class="search-hit mathjax">legal</span> accountability, align <span class="search-hit mathjax">AI</span>-driven choices with stakeholder values, and maintain ethical safeguards. We advocate for frameworks that balance autonomy with accountability, ensuring all parties can harness agentic <span class="search-hit mathjax">AI&#39;s</span> potential while preserving trust, fairness, &amp; societal welfare.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.00289v3-abstract-full').style.display = 'none'; document.getElementById('2502.00289v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 February, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 31 January, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2501.14579">arXiv:2501.14579</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2501.14579">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Knowledge Graphs Construction from Criminal Court Appeals: Insights from the French Cassation Court
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Belikov%2C+A+V">Alexander V. Belikov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Raoult%2C+S">Sacha Raoult</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2501.14579v1-abstract-short" style="display: inline;">
        &hellip;growing interest, accurately and reliably representing unstructured data, such as court decisions, in a structured form, remains a challenge. Recent advancements in generative <span class="search-hit mathjax">AI</span> applied to language modeling enabled the transformation of text into knowledge graphs, unlocking new opportunities for&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.14579v1-abstract-full').style.display = 'inline'; document.getElementById('2501.14579v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2501.14579v1-abstract-full" style="display: none;">
        Despite growing interest, accurately and reliably representing unstructured data, such as court decisions, in a structured form, remains a challenge. Recent advancements in generative <span class="search-hit mathjax">AI</span> applied to language modeling enabled the transformation of text into knowledge graphs, unlocking new opportunities for <span class="search-hit mathjax">analysis</span> and modeling. This paper presents a framework for constructing knowledge graphs from appeals to the French Cassation Court. The framework includes a domain-specific ontology and a derived dataset, offering a foundation for structured <span class="search-hit mathjax">legal</span> data representation and <span class="search-hit mathjax">analysis</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.14579v1-abstract-full').style.display = 'none'; document.getElementById('2501.14579v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 January, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2501.12962">arXiv:2501.12962</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2501.12962">pdf</a>, <a href="https://arxiv.org/format/2501.12962">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        It&#39;s complicated. The relationship of algorithmic fairness and non-discrimination regulations in the EU <span class="search-hit mathjax">AI</span> Act
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Meding%2C+K">Kristof Meding</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2501.12962v2-abstract-short" style="display: inline;">
        What constitutes a fair decision? This question is not only difficult for humans but becomes more challenging when Artificial Intelligence (<span class="search-hit mathjax">AI</span>) models are used. In light of discriminatory algorithmic behaviors, the EU has recently passed the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.12962v2-abstract-full').style.display = 'inline'; document.getElementById('2501.12962v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2501.12962v2-abstract-full" style="display: none;">
        What constitutes a fair decision? This question is not only difficult for humans but becomes more challenging when Artificial Intelligence (<span class="search-hit mathjax">AI</span>) models are used. In light of discriminatory algorithmic behaviors, the EU has recently passed the <span class="search-hit mathjax">AI</span> Act, which mandates specific rules for <span class="search-hit mathjax">AI</span> models, incorporating both traditional <span class="search-hit mathjax">legal</span> non-discrimination regulations and machine learning based algorithmic fairness concepts. This paper aims to bridge these two different concepts in the <span class="search-hit mathjax">AI</span> Act through: First a high-level introduction of both concepts targeting <span class="search-hit mathjax">legal</span> and computer science-oriented scholars, and second an in-depth <span class="search-hit mathjax">analysis</span> of the <span class="search-hit mathjax">AI</span> Act&#39;s relationship between <span class="search-hit mathjax">legal</span> non-discrimination regulations and algorithmic fairness. Our <span class="search-hit mathjax">analysis</span> reveals three key findings: (1.), most non-discrimination regulations target only high-risk <span class="search-hit mathjax">AI</span> systems. (2.), the regulation of high-risk systems encompasses both data input requirements and output monitoring, though these regulations are often inconsistent and raise questions of computational feasibility. (3.) Regulations for General Purpose <span class="search-hit mathjax">AI</span> Models, such as Large Language Models that are not simultaneously classified as high-risk systems, currently lack specificity compared to other regulations. Based on these findings, we recommend developing more specific auditing and testing methodologies for <span class="search-hit mathjax">AI</span> systems. This paper aims to serve as a foundation for future interdisciplinary collaboration between <span class="search-hit mathjax">legal</span> scholars and computer science-oriented machine learning researchers studying discrimination in <span class="search-hit mathjax">AI</span> systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.12962v2-abstract-full').style.display = 'none'; document.getElementById('2501.12962v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 March, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 22 January, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2501.11447">arXiv:2501.11447</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2501.11447">pdf</a>, <a href="https://arxiv.org/format/2501.11447">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Analysis, Statistics and Probability">physics.data-an</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Decomposing Interventional Causality into Synergistic, Redundant, and Unique Components
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Jansma%2C+A">Abel Jansma</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2501.11447v1-abstract-short" style="display: inline;">
        &hellip;complex systems by revealing how causal influences are shared and combined among multiple variables, with potential applications ranging from attribution of responsibility in <span class="search-hit mathjax">legal</span> or <span class="search-hit mathjax">AI</span> systems, to the <span class="search-hit mathjax">analysis</span> of biological networks or climate models.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.11447v1-abstract-full').style.display = 'inline'; document.getElementById('2501.11447v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2501.11447v1-abstract-full" style="display: none;">
        We introduce a novel framework for decomposing interventional causal effects into synergistic, redundant, and unique components, building on the intuition of Partial Information Decomposition (PID) and the principle of Möbius inversion. While recent work has explored a similar decomposition of an observational measure, we argue that a proper causal decomposition must be interventional in nature. We develop a mathematical approach that systematically quantifies how causal power is distributed among variables in a system, using a recently derived closed-form expression for the Möbius function of the redundancy lattice. The formalism is then illustrated by decomposing the causal power in logic gates, cellular automata, and chemical reaction networks. Our results reveal how the distribution of causal power can be context- and parameter-dependent. This decomposition provides new insights into complex systems by revealing how causal influences are shared and combined among multiple variables, with potential applications ranging from attribution of responsibility in <span class="search-hit mathjax">legal</span> or <span class="search-hit mathjax">AI</span> systems, to the <span class="search-hit mathjax">analysis</span> of biological networks or climate models.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.11447v1-abstract-full').style.display = 'none'; document.getElementById('2501.11447v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 January, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages, 6 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68T01 (Primary) 06A11; 62D20 (Secondary)
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.4; F.2.1; G.2.1
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2501.10915">arXiv:2501.10915</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2501.10915">pdf</a>, <a href="https://arxiv.org/format/2501.10915">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        LegalGuardian: A Privacy-Preserving Framework for Secure Integration of Large Language Models in <span class="search-hit mathjax">Legal</span> Practice
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Demir%2C+M+M">M. Mikail Demir</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Otal%2C+H+T">Hakan T. Otal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Canbaz%2C+M+A">M. Abdullah Canbaz</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2501.10915v1-abstract-short" style="display: inline;">
        Large Language Models (LLMs) hold promise for advancing <span class="search-hit mathjax">legal</span> practice by automating complex tasks and improving access to justice. However, their adoption is limited by concerns over client confidentiality, especially when lawyers include sensitive Personally Identifiable Information (PII) in prompts, risking unauthorized data exposure. To mitigate this, we&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.10915v1-abstract-full').style.display = 'inline'; document.getElementById('2501.10915v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2501.10915v1-abstract-full" style="display: none;">
        Large Language Models (LLMs) hold promise for advancing <span class="search-hit mathjax">legal</span> practice by automating complex tasks and improving access to justice. However, their adoption is limited by concerns over client confidentiality, especially when lawyers include sensitive Personally Identifiable Information (PII) in prompts, risking unauthorized data exposure. To mitigate this, we introduce LegalGuardian, a lightweight, privacy-preserving framework tailored for lawyers using LLM-based tools. LegalGuardian employs Named Entity Recognition (NER) techniques and local LLMs to mask and unmask confidential PII within prompts, safeguarding sensitive data before any external interaction. We detail its development and assess its effectiveness using a synthetic prompt library in immigration law scenarios. Comparing traditional NER models with one-shot prompted local LLM, we find that LegalGuardian achieves a F1-score of 93% with GLiNER and 97% with Qwen2.5-14B in PII detection. Semantic similarity <span class="search-hit mathjax">analysis</span> confirms that the framework maintains high fidelity in outputs, ensuring robust utility of LLM-based tools. Our findings indicate that <span class="search-hit mathjax">legal</span> professionals can harness advanced <span class="search-hit mathjax">AI</span> technologies without compromising client confidentiality or the quality of <span class="search-hit mathjax">legal</span> documents.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.10915v1-abstract-full').style.display = 'none'; document.getElementById('2501.10915v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 January, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages, 3 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68T50; 68U35
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.7; K.5.0; I.7.0
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2501.08046">arXiv:2501.08046</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2501.08046">pdf</a>, <a href="https://arxiv.org/format/2501.08046">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Building Symbiotic <span class="search-hit mathjax">AI</span>: Reviewing the <span class="search-hit mathjax">AI</span> Act for a Human-Centred, Principle-Based Framework
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Calvano%2C+M">Miriana Calvano</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Curci%2C+A">Antonio Curci</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Desolda%2C+G">Giuseppe Desolda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Esposito%2C+A">Andrea Esposito</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lanzilotti%2C+R">Rosa Lanzilotti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Piccinno%2C+A">Antonio Piccinno</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2501.08046v2-abstract-short" style="display: inline;">
        Artificial Intelligence (<span class="search-hit mathjax">AI</span>) spreads quickly as new technologies and services take over modern society. The need to regulate&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.08046v2-abstract-full').style.display = 'inline'; document.getElementById('2501.08046v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2501.08046v2-abstract-full" style="display: none;">
        Artificial Intelligence (<span class="search-hit mathjax">AI</span>) spreads quickly as new technologies and services take over modern society. The need to regulate <span class="search-hit mathjax">AI</span> design, development, and use is strictly necessary to avoid unethical and potentially dangerous consequences to humans. The European Union (EU) has released a new <span class="search-hit mathjax">legal</span> framework, the <span class="search-hit mathjax">AI</span> Act, to regulate <span class="search-hit mathjax">AI</span> by undertaking a risk-based approach to safeguard humans during interaction. At the same time, researchers offer a new perspective on <span class="search-hit mathjax">AI</span> systems, commonly known as Human-Centred <span class="search-hit mathjax">AI</span> (HCAI), highlighting the need for a human-centred approach to their design. In this context, Symbiotic <span class="search-hit mathjax">AI</span> (a subtype of HCAI) promises to enhance human capabilities through a deeper and continuous collaboration between human intelligence and <span class="search-hit mathjax">AI</span>. This article presents the results of a Systematic Literature Review (SLR) that aims to identify principles that characterise the design and development of Symbiotic <span class="search-hit mathjax">AI</span> systems while considering humans as the core of the process. Through content <span class="search-hit mathjax">analysis</span>, four principles emerged from the review that must be applied to create Human-Centred <span class="search-hit mathjax">AI</span> systems that can establish a symbiotic relationship with humans. In addition, current trends and challenges were defined to indicate open questions that may guide future research for the development of SAI systems that comply with the <span class="search-hit mathjax">AI</span> Act.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.08046v2-abstract-full').style.display = 'none'; document.getElementById('2501.08046v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 February, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 14 January, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Second version: 34 pages, 5 figures, 2 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2501.01711">arXiv:2501.01711</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2501.01711">pdf</a>, <a href="https://arxiv.org/format/2501.01711">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        LLMs &amp; <span class="search-hit mathjax">Legal</span> Aid: Understanding <span class="search-hit mathjax">Legal</span> Needs Exhibited Through User Queries
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kuk%2C+M">Michal Kuk</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Harasta%2C+J">Jakub Harasta</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2501.01711v1-abstract-short" style="display: inline;">
        The paper presents a preliminary <span class="search-hit mathjax">analysis</span> of an experiment conducted by Frank Bold, a Czech expert group, to explore user interactions with GPT-4 for addressing&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.01711v1-abstract-full').style.display = 'inline'; document.getElementById('2501.01711v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2501.01711v1-abstract-full" style="display: none;">
        The paper presents a preliminary <span class="search-hit mathjax">analysis</span> of an experiment conducted by Frank Bold, a Czech expert group, to explore user interactions with GPT-4 for addressing <span class="search-hit mathjax">legal</span> queries. Between May 3, 2023, and July 25, 2023, 1,252 users submitted 3,847 queries. Unlike studies that primarily focus on the accuracy, factuality, or hallucination tendencies of large language models (LLMs), our <span class="search-hit mathjax">analysis</span> focuses on the user query dimension of the interaction. Using GPT-4o for zero-shot classification, we categorized queries on (1) whether users provided factual information about their issue (29.95%) or not (70.05%), (2) whether they sought <span class="search-hit mathjax">legal</span> information (64.93%) or advice on the course of action (35.07\%), and (3) whether they imposed requirements to shape or control the model&#39;s answer (28.57%) or not (71.43%). We provide both quantitative and qualitative insight into user needs and contribute to a better understanding of user engagement with LLMs.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.01711v1-abstract-full').style.display = 'none'; document.getElementById('2501.01711v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 January, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at <span class="search-hit mathjax">AI</span> for Access to Justice Workshop at Jurix 2024, Brno, Czechia</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2501.00106">arXiv:2501.00106</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2501.00106">pdf</a>, <a href="https://arxiv.org/format/2501.00106">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        LicenseGPT: A Fine-tuned Foundation Model for Publicly Available Dataset License Compliance
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Tan%2C+J">Jingwen Tan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rajbahadur%2C+G+K">Gopi Krishnan Rajbahadur</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Z">Zi Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Song%2C+X">Xiangfu Song</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lin%2C+J">Jianshan Lin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+D">Dan Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zheng%2C+Z">Zibin Zheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hassan%2C+A+E">Ahmed E. Hassan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2501.00106v1-abstract-short" style="display: inline;">
        Dataset license compliance is a critical yet complex aspect of developing commercial <span class="search-hit mathjax">AI</span> products, particularly with the increasing use of publicly available datasets. Ambiguities in dataset licenses pose significant&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.00106v1-abstract-full').style.display = 'inline'; document.getElementById('2501.00106v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2501.00106v1-abstract-full" style="display: none;">
        Dataset license compliance is a critical yet complex aspect of developing commercial <span class="search-hit mathjax">AI</span> products, particularly with the increasing use of publicly available datasets. Ambiguities in dataset licenses pose significant <span class="search-hit mathjax">legal</span> risks, making it challenging even for software IP lawyers to accurately interpret rights and obligations. In this paper, we introduce LicenseGPT, a fine-tuned foundation model (FM) specifically designed for dataset license compliance <span class="search-hit mathjax">analysis</span>. We first evaluate existing <span class="search-hit mathjax">legal</span> FMs (i.e., FMs specialized in understanding and processing <span class="search-hit mathjax">legal</span> texts) and find that the best-performing model achieves a Prediction Agreement (PA) of only 43.75%. LicenseGPT, fine-tuned on a curated dataset of 500 licenses annotated by <span class="search-hit mathjax">legal</span> experts, significantly improves PA to 64.30%, outperforming both <span class="search-hit mathjax">legal</span> and general-purpose FMs. Through an A/B test and user study with software IP lawyers, we demonstrate that LicenseGPT reduces <span class="search-hit mathjax">analysis</span> time by 94.44%, from 108 seconds to 6 seconds per license, without compromising accuracy. Software IP lawyers perceive LicenseGPT as a valuable supplementary tool that enhances efficiency while acknowledging the need for human oversight in complex cases. Our work underscores the potential of specialized <span class="search-hit mathjax">AI</span> tools in <span class="search-hit mathjax">legal</span> practice and offers a publicly available resource for practitioners and researchers.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.00106v1-abstract-full').style.display = 'none'; document.getElementById('2501.00106v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 December, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.17259">arXiv:2412.17259</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.17259">pdf</a>, <a href="https://arxiv.org/format/2412.17259">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        LegalAgentBench: Evaluating LLM Agents in <span class="search-hit mathjax">Legal</span> Domain
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+H">Haitao Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+J">Junjie Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+J">Jingli Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ai%2C+Q">Qingyao Ai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jia%2C+W">Wei Jia</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Youfeng Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lin%2C+K">Kai Lin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+Y">Yueyue Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yuan%2C+G">Guozhi Yuan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+Y">Yiran Hu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+W">Wuyue Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yiqun Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+M">Minlie Huang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.17259v1-abstract-short" style="display: inline;">
        With the increasing intelligence and autonomy of LLM agents, their potential applications in the <span class="search-hit mathjax">legal</span> domain are becoming increasingly apparent. However, existing general-domain benchmarks cannot fully capture the complexity and subtle nuances of real-world judicial cognition and decision-making. Therefore, we propose LegalAgentBench, a comprehensive benchm&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.17259v1-abstract-full').style.display = 'inline'; document.getElementById('2412.17259v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.17259v1-abstract-full" style="display: none;">
        With the increasing intelligence and autonomy of LLM agents, their potential applications in the <span class="search-hit mathjax">legal</span> domain are becoming increasingly apparent. However, existing general-domain benchmarks cannot fully capture the complexity and subtle nuances of real-world judicial cognition and decision-making. Therefore, we propose LegalAgentBench, a comprehensive benchmark specifically designed to evaluate LLM Agents in the Chinese <span class="search-hit mathjax">legal</span> domain. LegalAgentBench includes 17 corpora from real-world <span class="search-hit mathjax">legal</span> scenarios and provides 37 tools for interacting with external knowledge. We designed a scalable task construction framework and carefully annotated 300 tasks. These tasks span various types, including multi-hop reasoning and writing, and range across different difficulty levels, effectively reflecting the complexity of real-world <span class="search-hit mathjax">legal</span> scenarios. Moreover, beyond evaluating final success, LegalAgentBench incorporates keyword <span class="search-hit mathjax">analysis</span> during intermediate processes to calculate progress rates, enabling more fine-grained evaluation. We evaluated eight popular LLMs, highlighting the strengths, limitations, and potential areas for improvement of existing models and methods. LegalAgentBench sets a new benchmark for the practical application of LLMs in the <span class="search-hit mathjax">legal</span> domain, with its code and data available at \url{https://github.com/CSHaitao/LegalAgentBench}.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.17259v1-abstract-full').style.display = 'none'; document.getElementById('2412.17259v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 December, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">23 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.16694">arXiv:2412.16694</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.16694">pdf</a>, <a href="https://arxiv.org/format/2412.16694">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        DragonVerseQA: Open-Domain Long-Form Context-Aware Question-Answering
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lahiri%2C+A+K">Aritra Kumar Lahiri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+Q+V">Qinmin Vivian Hu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.16694v1-abstract-short" style="display: inline;">
        &hellip;dataset that combines full episode summaries sourced from HBO and fandom wiki websites, user reviews from sources like IMDb and Rotten Tomatoes, and high-quality, open-domain, <span class="search-hit mathjax">legally</span> admissible sources, and structured data from repositories like WikiData into one dataset. The dataset provides a multi-dimensional context, reflecting complex character dynamic&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.16694v1-abstract-full').style.display = 'inline'; document.getElementById('2412.16694v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.16694v1-abstract-full" style="display: none;">
        This paper proposes a novel approach to develop an open-domain and long-form Over-The-Top (OTT) Question-Answering (QA) dataset, DragonVerseQA, specifically oriented to the fantasy universe of &#34;House of the Dragon&#34; and &#34;Game Of Thrones&#34; TV series. Most existing QA datasets focus on short, fact-based answers sourced almost solely from Wikipedia articles, devoid of depth and contextual richness for sophisticated narrative understanding. We curate a dataset that combines full episode summaries sourced from HBO and fandom wiki websites, user reviews from sources like IMDb and Rotten Tomatoes, and high-quality, open-domain, <span class="search-hit mathjax">legally</span> admissible sources, and structured data from repositories like WikiData into one dataset. The dataset provides a multi-dimensional context, reflecting complex character dynamics and plot developments from these varied sources. That means, on equal footing, only after heavy data preprocessing and filtering methods will meaningful, non-spam unbiased reviews be available in this enriched dataset. The comprehensive insights are given through the long-form answers generated from this enriched context. This is what makes this valuable dataset for improving conversational <span class="search-hit mathjax">AI</span>, narrative <span class="search-hit mathjax">analysis</span>, sentiment <span class="search-hit mathjax">analysis</span>, summarization techniques, and relation extraction.
  A comparative <span class="search-hit mathjax">analysis</span> with state-of-the-art QA datasets such as SQuAD 2.0, TriviaQA, and Natural Questions brings to light the unique advantages of our dataset in terms of contextual complexity and answer length. Detailed reviews add layers to audience sentiment and narrative interpretation, raising the bar for domain-specific QA with a new quality benchmark. Our work also allows a deeper understanding of entertainment-industry content and opens the door to more knowledgeable and creative <span class="search-hit mathjax">AI</span>-driven interactions within digital media environments.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.16694v1-abstract-full').style.display = 'none'; document.getElementById('2412.16694v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 December, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.15260">arXiv:2412.15260</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.15260">pdf</a>, <a href="https://arxiv.org/format/2412.15260">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multimedia">cs.MM</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Analyzing Images of <span class="search-hit mathjax">Legal</span> Documents: Toward Multi-Modal LLMs for Access to Justice
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Westermann%2C+H">Hannes Westermann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Savelka%2C+J">Jaromir Savelka</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.15260v1-abstract-short" style="display: inline;">
        Interacting with the <span class="search-hit mathjax">legal</span> system and the government requires the assembly and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.15260v1-abstract-full').style.display = 'inline'; document.getElementById('2412.15260v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.15260v1-abstract-full" style="display: none;">
        Interacting with the <span class="search-hit mathjax">legal</span> system and the government requires the assembly and <span class="search-hit mathjax">analysis</span> of various pieces of information that can be spread across different (paper) documents, such as forms, certificates and contracts (e.g. leases). This information is required in order to understand one&#39;s <span class="search-hit mathjax">legal</span> rights, as well as to fill out forms to file claims in court or obtain government benefits. However, finding the right information, locating the correct forms and filling them out can be challenging for laypeople. Large language models (LLMs) have emerged as a powerful technology that has the potential to address this gap, but still rely on the user to provide the correct information, which may be challenging and error-prone if the information is only available in complex paper documents. We present an investigation into utilizing multi-modal LLMs to analyze images of handwritten paper forms, in order to automatically extract relevant information in a structured format. Our initial results are promising, but reveal some limitations (e.g., when the image quality is low). Our work demonstrates the potential of integrating multi-modal LLMs to support laypeople and self-represented litigants in finding and assembling relevant information.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.15260v1-abstract-full').style.display = 'none'; document.getElementById('2412.15260v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 December, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at <span class="search-hit mathjax">AI</span> for Access to Justice Workshop at Jurix 2024, Brno, Czechia. Code and Data available at: https://github.com/hwestermann/AI4A2J_analyzing_images_of_legal_documents</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.08385">arXiv:2412.08385</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.08385">pdf</a>, <a href="https://arxiv.org/format/2412.08385">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        NyayaAnumana &amp; INLegalLlama: The Largest Indian <span class="search-hit mathjax">Legal</span> Judgment Prediction Dataset and Specialized Language Model for Enhanced Decision <span class="search-hit mathjax">Analysis</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Nigam%2C+S+K">Shubham Kumar Nigam</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Patnaik%2C+B+D">Balaramamahanthi Deepak Patnaik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mishra%2C+S">Shivam Mishra</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shallum%2C+N">Noel Shallum</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ghosh%2C+K">Kripabandhu Ghosh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bhattacharya%2C+A">Arnab Bhattacharya</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.08385v1-abstract-short" style="display: inline;">
        The integration of artificial intelligence (<span class="search-hit mathjax">AI</span>) in&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.08385v1-abstract-full').style.display = 'inline'; document.getElementById('2412.08385v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.08385v1-abstract-full" style="display: none;">
        The integration of artificial intelligence (<span class="search-hit mathjax">AI</span>) in <span class="search-hit mathjax">legal</span> judgment prediction (LJP) has the potential to transform the <span class="search-hit mathjax">legal</span> landscape, particularly in jurisdictions like India, where a significant backlog of cases burdens the <span class="search-hit mathjax">legal</span> system. This paper introduces NyayaAnumana, the largest and most diverse corpus of Indian <span class="search-hit mathjax">legal</span> cases compiled for LJP, encompassing a total of 7,02,945 preprocessed cases. NyayaAnumana, which combines the words &#34;Nyay&#34; (judgment) and &#34;Anuman&#34; (prediction or inference) respectively for most major Indian languages, includes a wide range of cases from the Supreme Court, High Courts, Tribunal Courts, District Courts, and Daily Orders and, thus, provides unparalleled diversity and coverage. Our dataset surpasses existing datasets like PredEx and ILDC, offering a comprehensive foundation for advanced <span class="search-hit mathjax">AI</span> research in the <span class="search-hit mathjax">legal</span> domain.
  In addition to the dataset, we present INLegalLlama, a domain-specific generative large language model (LLM) tailored to the intricacies of the Indian <span class="search-hit mathjax">legal</span> system. It is developed through a two-phase training approach over a base LLaMa model. First, Indian <span class="search-hit mathjax">legal</span> documents are injected using continual pretraining. Second, task-specific supervised finetuning is done. This method allows the model to achieve a deeper understanding of <span class="search-hit mathjax">legal</span> contexts.
  Our experiments demonstrate that incorporating diverse court data significantly boosts model accuracy, achieving approximately 90% F1-score in prediction tasks. INLegalLlama not only improves prediction accuracy but also offers comprehensible explanations, addressing the need for explainability in <span class="search-hit mathjax">AI</span>-assisted <span class="search-hit mathjax">legal</span> decisions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.08385v1-abstract-full').style.display = 'none'; document.getElementById('2412.08385v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 December, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted on COLING 2025</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.07782">arXiv:2412.07782</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.07782">pdf</a>, <a href="https://arxiv.org/format/2412.07782">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Trustworthy artificial intelligence in the energy sector: Landscape <span class="search-hit mathjax">analysis</span> and evaluation framework
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Pelekis%2C+S">Sotiris Pelekis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Karakolis%2C+E">Evangelos Karakolis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lampropoulos%2C+G">George Lampropoulos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mouzakitis%2C+S">Spiros Mouzakitis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Markaki%2C+O">Ourania Markaki</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ntanos%2C+C">Christos Ntanos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Askounis%2C+D">Dimitris Askounis</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.07782v1-abstract-short" style="display: inline;">
        The present study aims to evaluate the current fuzzy landscape of Trustworthy <span class="search-hit mathjax">AI</span> (TAI) within the European Union (EU), with a specific focus on the energy sector. The&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.07782v1-abstract-full').style.display = 'inline'; document.getElementById('2412.07782v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.07782v1-abstract-full" style="display: none;">
        The present study aims to evaluate the current fuzzy landscape of Trustworthy <span class="search-hit mathjax">AI</span> (TAI) within the European Union (EU), with a specific focus on the energy sector. The <span class="search-hit mathjax">analysis</span> encompasses <span class="search-hit mathjax">legal</span> frameworks, directives, initiatives, and standards like the <span class="search-hit mathjax">AI</span> Ethics Guidelines for Trustworthy <span class="search-hit mathjax">AI</span> (EGTAI), the Assessment List for Trustworthy <span class="search-hit mathjax">AI</span> (ALTAI), the <span class="search-hit mathjax">AI</span> act, and relevant CEN-CENELEC standardization efforts, as well as EU-funded projects such as AI4EU and SHERPA. Subsequently, we introduce a new TAI application framework, called E-TAI, tailored for energy applications, including smart grid and smart building systems. This framework draws inspiration from EGTAI but is customized for <span class="search-hit mathjax">AI</span> systems in the energy domain. It is designed for stakeholders in electrical power and energy systems (EPES), including researchers, developers, and energy experts linked to transmission system operators, distribution system operators, utilities, and aggregators. These stakeholders can utilize E-TAI to develop and evaluate <span class="search-hit mathjax">AI</span> services for the energy sector with a focus on ensuring trustworthiness throughout their development and iterative assessment processes.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.07782v1-abstract-full').style.display = 'none'; document.getElementById('2412.07782v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.07687">arXiv:2412.07687</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.07687">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Applications">stat.AP</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Methodology">stat.ME</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Privacy-Preserving Customer Support: A Framework for Secure and Scalable Interactions
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Awasthi%2C+A+P">Anant Prakash Awasthi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Agarwal%2C+G+G">Girdhar Gopal Agarwal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Singh%2C+C">Chandraketu Singh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Varma%2C+R">Rakshit Varma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sharma%2C+S">Sanchit Sharma</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.07687v2-abstract-short" style="display: inline;">
        The growing reliance on artificial intelligence (<span class="search-hit mathjax">AI</span>) in customer support has significantly improved operational efficiency and user experience. However, traditional machine learning (ML) approaches, which require extensive local training on sensitive datasets, pose substantial privacy risks and compliance challenges with regulations like the General Data Pro&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.07687v2-abstract-full').style.display = 'inline'; document.getElementById('2412.07687v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.07687v2-abstract-full" style="display: none;">
        The growing reliance on artificial intelligence (<span class="search-hit mathjax">AI</span>) in customer support has significantly improved operational efficiency and user experience. However, traditional machine learning (ML) approaches, which require extensive local training on sensitive datasets, pose substantial privacy risks and compliance challenges with regulations like the General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA). Existing privacy-preserving techniques, such as anonymization, differential privacy, and federated learning, address some concerns but face limitations in utility, scalability, and complexity. This paper introduces the Privacy-Preserving Zero-Shot Learning (PP-ZSL) framework, a novel approach leveraging large language models (LLMs) in a zero-shot learning mode. Unlike conventional ML methods, PP-ZSL eliminates the need for local training on sensitive data by utilizing pre-trained LLMs to generate responses directly. The framework incorporates real-time data anonymization to redact or mask sensitive information, retrieval-augmented generation (RAG) for domain-specific query resolution, and robust post-processing to ensure compliance with regulatory standards. This combination reduces privacy risks, simplifies compliance, and enhances scalability and operational efficiency. Empirical <span class="search-hit mathjax">analysis</span> demonstrates that the PP-ZSL framework provides accurate, privacy-compliant responses while significantly lowering the costs and complexities of deploying <span class="search-hit mathjax">AI</span>-driven customer support systems. The study highlights potential applications across industries, including financial services, healthcare, e-commerce, <span class="search-hit mathjax">legal</span> support, telecommunications, and government services. By addressing the dual challenges of privacy and performance, this framework establishes a foundation for secure, efficient, and regulatory-compliant <span class="search-hit mathjax">AI</span> applications in customer interactions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.07687v2-abstract-full').style.display = 'none'; document.getElementById('2412.07687v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 December, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 10 December, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.04498">arXiv:2412.04498</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.04498">pdf</a>, <a href="https://arxiv.org/ps/2412.04498">ps</a>, <a href="https://arxiv.org/format/2412.04498">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Large Language Models in Politics and Democracy: A Comprehensive Survey
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Aoki%2C+G">Goshi Aoki</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.04498v2-abstract-short" style="display: inline;">
        The advancement of generative <span class="search-hit mathjax">AI</span>, particularly large language models (LLMs), has a significant impact on politics and democracy, offering potential across various domains, including policymaking, political communication,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.04498v2-abstract-full').style.display = 'inline'; document.getElementById('2412.04498v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.04498v2-abstract-full" style="display: none;">
        The advancement of generative <span class="search-hit mathjax">AI</span>, particularly large language models (LLMs), has a significant impact on politics and democracy, offering potential across various domains, including policymaking, political communication, <span class="search-hit mathjax">analysis</span>, and governance. This paper surveys the recent and potential applications of LLMs in politics, examining both their promises and the associated challenges. This paper examines the ways in which LLMs are being employed in legislative processes, political communication, and political <span class="search-hit mathjax">analysis</span>. Moreover, we investigate the potential of LLMs in diplomatic and national security contexts, economic and social modeling, and <span class="search-hit mathjax">legal</span> applications. While LLMs offer opportunities to enhance efficiency, inclusivity, and decision-making in political processes, they also present challenges related to bias, transparency, and accountability. The paper underscores the necessity for responsible development, ethical considerations, and governance frameworks to ensure that the integration of LLMs into politics aligns with democratic values and promotes a more just and equitable society.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.04498v2-abstract-full').style.display = 'none'; document.getElementById('2412.04498v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 December, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 1 December, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.03349">arXiv:2412.03349</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.03349">pdf</a>, <a href="https://arxiv.org/format/2412.03349">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Fairer <span class="search-hit mathjax">Analysis</span> and Demographically Balanced Face Generation for Fairer Face Verification
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Fournier-Montgieux%2C+A">Alexandre Fournier-Montgieux</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soumm%2C+M">Michael Soumm</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Popescu%2C+A">Adrian Popescu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Luvison%2C+B">Bertrand Luvison</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Borgne%2C+H+L">Hervé Le Borgne</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.03349v1-abstract-short" style="display: inline;">
        Face recognition and verification are two computer vision tasks whose performances have advanced with the introduction of deep representations. However, ethical, <span class="search-hit mathjax">legal</span>, and technical challenges due to the sensitive nature of face data and biases in real-world training datasets hinder their development. Generative&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03349v1-abstract-full').style.display = 'inline'; document.getElementById('2412.03349v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.03349v1-abstract-full" style="display: none;">
        Face recognition and verification are two computer vision tasks whose performances have advanced with the introduction of deep representations. However, ethical, <span class="search-hit mathjax">legal</span>, and technical challenges due to the sensitive nature of face data and biases in real-world training datasets hinder their development. Generative <span class="search-hit mathjax">AI</span> addresses privacy by creating fictitious identities, but fairness problems remain. Using the existing DCFace SOTA framework, we introduce a new controlled generation pipeline that improves fairness. Through classical fairness metrics and a proposed in-depth statistical <span class="search-hit mathjax">analysis</span> based on logit models and ANOVA, we show that our generation pipeline improves fairness more than other bias mitigation approaches while slightly improving raw performance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.03349v1-abstract-full').style.display = 'none'; document.getElementById('2412.03349v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 December, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2411.15149">arXiv:2411.15149</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2411.15149">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1016/j.clsr.2024.106020">10.1016/j.clsr.2024.106020 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Fundamental Rights Impact Assessment (FRIA) in the <span class="search-hit mathjax">AI</span> Act: Roots, <span class="search-hit mathjax">legal</span> obligations and key elements for a model template
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mantelero%2C+A">Alessandro Mantelero</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2411.15149v1-abstract-short" style="display: inline;">
        What is the context which gave rise to the obligation to carry out a Fundamental Rights Impact Assessment (FRIA) in the <span class="search-hit mathjax">AI</span> Act? How has assessment of the impact on fundamental rights been framed by the EU legislator in the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2411.15149v1-abstract-full').style.display = 'inline'; document.getElementById('2411.15149v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2411.15149v1-abstract-full" style="display: none;">
        What is the context which gave rise to the obligation to carry out a Fundamental Rights Impact Assessment (FRIA) in the <span class="search-hit mathjax">AI</span> Act? How has assessment of the impact on fundamental rights been framed by the EU legislator in the <span class="search-hit mathjax">AI</span> Act? What methodological criteria should be followed in developing the FRIA? These are the three main research questions that this article aims to address, through both <span class="search-hit mathjax">legal</span> <span class="search-hit mathjax">analysis</span> of the relevant provisions of the <span class="search-hit mathjax">AI</span> Act and discussion of various possible models for assessment of the impact of <span class="search-hit mathjax">AI</span> on fundamental rights. The overall objective of this article is to fill existing gaps in the theoretical and methodological elaboration of the FRIA, as outlined in the <span class="search-hit mathjax">AI</span> Act. In order to facilitate the future work of EU and national bodies and <span class="search-hit mathjax">AI</span> operators in placing this key tool for human-centric and trustworthy <span class="search-hit mathjax">AI</span> at the heart of the EU approach to <span class="search-hit mathjax">AI</span> design and development, this article outlines the main building blocks of a model template for the FRIA. While this proposal is consistent with the rationale and scope of the <span class="search-hit mathjax">AI</span> Act, it is also applicable beyond the cases listed in Article 27 and can serve as a blueprint for other national and international regulatory initiatives to ensure that <span class="search-hit mathjax">AI</span> is fully consistent with human rights.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2411.15149v1-abstract-full').style.display = 'none'; document.getElementById('2411.15149v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2024.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Computer Law &amp; Security Review, Volume 54, September 2024, 106020
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2411.10877">arXiv:2411.10877</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2411.10877">pdf</a>, <a href="https://arxiv.org/format/2411.10877">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Developer Perspectives on Licensing and Copyright Issues Arising from Generative <span class="search-hit mathjax">AI</span> for Software Development
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Stalnaker%2C+T">Trevor Stalnaker</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wintersgill%2C+N">Nathan Wintersgill</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chaparro%2C+O">Oscar Chaparro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Heymann%2C+L+A">Laura A. Heymann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Di+Penta%2C+M">Massimiliano Di Penta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=German%2C+D+M">Daniel M German</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Poshyvanyk%2C+D">Denys Poshyvanyk</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2411.10877v3-abstract-short" style="display: inline;">
        Despite the utility that Generative <span class="search-hit mathjax">AI</span> (GenAI) tools provide for tasks such as writing code, the use of these tools raises important&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2411.10877v3-abstract-full').style.display = 'inline'; document.getElementById('2411.10877v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2411.10877v3-abstract-full" style="display: none;">
        Despite the utility that Generative <span class="search-hit mathjax">AI</span> (GenAI) tools provide for tasks such as writing code, the use of these tools raises important <span class="search-hit mathjax">legal</span> questions and potential risks, particularly those associated with copyright law. As lawmakers and regulators engage with those questions, the views of users can provide relevant perspectives. In this paper, we provide: (1) a survey of 574 developers on the licensing and copyright aspects of GenAI for coding, as well as follow-up interviews; (2) a snapshot of developers&#39; views at a time when GenAI and perceptions of it are rapidly evolving; and (3) an <span class="search-hit mathjax">analysis</span> of developers&#39; views, yielding insights and recommendations that can inform future regulatory decisions in this evolving field. Our results show the benefits developers derive from GenAI, how they view the use of <span class="search-hit mathjax">AI</span>-generated code as similar to using other existing code, the varied opinions they have on who should own or be compensated for such code, that they are concerned about data leakage via GenAI, and much more, providing organizations and policymakers with valuable insights into how the technology is being used and what concerns stakeholders would like to see addressed.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2411.10877v3-abstract-full').style.display = 'none'; document.getElementById('2411.10877v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 March, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 16 November, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2411.10137">arXiv:2411.10137</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2411.10137">pdf</a>, <a href="https://arxiv.org/format/2411.10137">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Legal</span> Evalutions and Challenges of Large Language Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+J">Jiaqi Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+H">Huan Zhao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+Z">Zhenyuan Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shu%2C+P">Peng Shu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+J">Junhao Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+H">Haobo Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liang%2C+R">Ruixi Liang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+S">Shixin Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shi%2C+P">Pengcheng Shi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+L">Longjun Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Z">Zongjia Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Z">Zhengliang Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhong%2C+T">Tianyang Zhong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Y">Yutong Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+C">Chong Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+X">Xin Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+T">Tuo Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+T">Tianli Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ren%2C+Y">Yudan Ren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+T">Tianming Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiang%2C+X">Xi Jiang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+S">Shu Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2411.10137v1-abstract-short" style="display: inline;">
        In this paper, we review <span class="search-hit mathjax">legal</span> testing methods based on Large Language Models (LLMs), using the OPENAI o1 model as a case study to evaluate the performance of large models in applying&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2411.10137v1-abstract-full').style.display = 'inline'; document.getElementById('2411.10137v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2411.10137v1-abstract-full" style="display: none;">
        In this paper, we review <span class="search-hit mathjax">legal</span> testing methods based on Large Language Models (LLMs), using the OPENAI o1 model as a case study to evaluate the performance of large models in applying <span class="search-hit mathjax">legal</span> provisions. We compare current state-of-the-art LLMs, including open-source, closed-source, and <span class="search-hit mathjax">legal</span>-specific models trained specifically for the <span class="search-hit mathjax">legal</span> domain. Systematic tests are conducted on English and Chinese <span class="search-hit mathjax">legal</span> cases, and the results are analyzed in depth. Through systematic testing of <span class="search-hit mathjax">legal</span> cases from common law systems and China, this paper explores the strengths and weaknesses of LLMs in understanding and applying <span class="search-hit mathjax">legal</span> texts, reasoning through <span class="search-hit mathjax">legal</span> issues, and predicting judgments. The experimental results highlight both the potential and limitations of LLMs in <span class="search-hit mathjax">legal</span> applications, particularly in terms of challenges related to the interpretation of <span class="search-hit mathjax">legal</span> language and the accuracy of <span class="search-hit mathjax">legal</span> reasoning. Finally, the paper provides a comprehensive <span class="search-hit mathjax">analysis</span> of the advantages and disadvantages of various types of models, offering valuable insights and references for the future application of <span class="search-hit mathjax">AI</span> in the <span class="search-hit mathjax">legal</span> field.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2411.10137v1-abstract-full').style.display = 'none'; document.getElementById('2411.10137v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2411.08363">arXiv:2411.08363</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2411.08363">pdf</a>, <a href="https://arxiv.org/ps/2411.08363">ps</a>, <a href="https://arxiv.org/format/2411.08363">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On Algorithmic Fairness and the EU Regulations
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ruohonen%2C+J">Jukka Ruohonen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2411.08363v2-abstract-short" style="display: inline;">
        &hellip;Union (EU). In addition to the EU laws addressing discrimination explicitly, the discussion is based on the EU&#39;s recently enacted regulation for artificial intelligence (<span class="search-hit mathjax">AI</span>) and the older General Data Protection Regulation (GDPR). Through a theoretical scenario&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2411.08363v2-abstract-full').style.display = 'inline'; document.getElementById('2411.08363v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2411.08363v2-abstract-full" style="display: none;">
        The short paper discusses algorithmic fairness by focusing on non-discrimination and a few important laws in the European Union (EU). In addition to the EU laws addressing discrimination explicitly, the discussion is based on the EU&#39;s recently enacted regulation for artificial intelligence (<span class="search-hit mathjax">AI</span>) and the older General Data Protection Regulation (GDPR). Through a theoretical scenario <span class="search-hit mathjax">analysis</span>, on one hand, the paper demonstrates that correcting discriminatory biases in <span class="search-hit mathjax">AI</span> systems can be <span class="search-hit mathjax">legally</span> done under the EU regulations. On the other hand, the scenarios also illustrate some practical scenarios from which <span class="search-hit mathjax">legal</span> non-compliance may follow. With these scenarios and the accompanying discussion, the paper contributes to the algorithmic fairness research with a few <span class="search-hit mathjax">legal</span> insights, enlarging and strengthening also the growing research domain of compliance in <span class="search-hit mathjax">AI</span> engineering.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2411.08363v2-abstract-full').style.display = 'none'; document.getElementById('2411.08363v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 December, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 13 November, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2410.07504">arXiv:2410.07504</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2410.07504">pdf</a>, <a href="https://arxiv.org/format/2410.07504">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Using LLMs to Discover <span class="search-hit mathjax">Legal</span> Factors
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gray%2C+M">Morgan Gray</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Savelka%2C+J">Jaromir Savelka</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Oliver%2C+W">Wesley Oliver</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ashley%2C+K">Kevin Ashley</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2410.07504v1-abstract-short" style="display: inline;">
        Factors are a foundational component of <span class="search-hit mathjax">legal</span>&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2410.07504v1-abstract-full').style.display = 'inline'; document.getElementById('2410.07504v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2410.07504v1-abstract-full" style="display: none;">
        Factors are a foundational component of <span class="search-hit mathjax">legal</span> <span class="search-hit mathjax">analysis</span> and computational models of <span class="search-hit mathjax">legal</span> reasoning. These factor-based representations enable lawyers, judges, and <span class="search-hit mathjax">AI</span> and Law researchers to reason about <span class="search-hit mathjax">legal</span> cases. In this paper, we introduce a methodology that leverages large language models (LLMs) to discover lists of factors that effectively represent a <span class="search-hit mathjax">legal</span> domain. Our method takes as input raw court opinions and produces a set of factors and associated definitions. We demonstrate that a semi-automated approach, incorporating minimal human involvement, produces factor representations that can predict case outcomes with moderate success, if not yet as well as expert-defined factors can.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2410.07504v1-abstract-full').style.display = 'none'; document.getElementById('2410.07504v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 October, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2410.04772">arXiv:2410.04772</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2410.04772">pdf</a>, <a href="https://arxiv.org/ps/2410.04772">ps</a>, <a href="https://arxiv.org/format/2410.04772">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        From Transparency to Accountability and Back: A Discussion of Access and Evidence in <span class="search-hit mathjax">AI</span> Auditing
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cen%2C+S+H">Sarah H. Cen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alur%2C+R">Rohan Alur</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2410.04772v1-abstract-short" style="display: inline;">
        Artificial intelligence (<span class="search-hit mathjax">AI</span>) is increasingly intervening in our lives, raising widespread concern about its unintended and undeclared side effects. These developments have brought attention to the problem of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2410.04772v1-abstract-full').style.display = 'inline'; document.getElementById('2410.04772v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2410.04772v1-abstract-full" style="display: none;">
        Artificial intelligence (<span class="search-hit mathjax">AI</span>) is increasingly intervening in our lives, raising widespread concern about its unintended and undeclared side effects. These developments have brought attention to the problem of <span class="search-hit mathjax">AI</span> auditing: the systematic evaluation and <span class="search-hit mathjax">analysis</span> of an <span class="search-hit mathjax">AI</span> system, its development, and its behavior relative to a set of predetermined criteria. Auditing can take many forms, including pre-deployment risk assessments, ongoing monitoring, and compliance testing. It plays a critical role in providing assurances to various <span class="search-hit mathjax">AI</span> stakeholders, from developers to end users. Audits may, for instance, be used to verify that an algorithm complies with the law, is consistent with industry standards, and meets the developer&#39;s claimed specifications. However, there are many operational challenges to <span class="search-hit mathjax">AI</span> auditing that complicate its implementation.
  In this work, we examine a key operational issue in <span class="search-hit mathjax">AI</span> auditing: what type of access to an <span class="search-hit mathjax">AI</span> system is needed to perform a meaningful audit? Addressing this question has direct policy relevance, as it can inform <span class="search-hit mathjax">AI</span> audit guidelines and requirements. We begin by discussing the factors that auditors balance when determining the appropriate type of access, and unpack the benefits and drawbacks of four types of access. We conclude that, at minimum, black-box access -- providing query access to a model without exposing its internal implementation -- should be granted to auditors, as it balances concerns related to trade secrets, data privacy, audit standardization, and audit efficiency. We then suggest a framework for determining how much further access (in addition to black-box access) to grant auditors. We show that auditing can be cast as a natural hypothesis test, draw parallels hypothesis testing and <span class="search-hit mathjax">legal</span> procedure, and argue that this framing provides clear and interpretable guidance on audit implementation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2410.04772v1-abstract-full').style.display = 'none'; document.getElementById('2410.04772v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 October, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">23 pages, 1 table</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2410.00475">arXiv:2410.00475</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2410.00475">pdf</a>, <a href="https://arxiv.org/ps/2410.00475">ps</a>, <a href="https://arxiv.org/format/2410.00475">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Probabilistic <span class="search-hit mathjax">Analysis</span> of Copyright Disputes and Generative <span class="search-hit mathjax">AI</span> Safety
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chiba-Okabe%2C+H">Hiroaki Chiba-Okabe</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2410.00475v4-abstract-short" style="display: inline;">
        &hellip;examination of issues arising in such disputes. The usefulness of this approach is showcased through its application to the ``inverse ratio rule&#39;&#39; -- a controversial <span class="search-hit mathjax">legal</span> doctrine adopted by some courts. Although this rule has faced significant criticism, a formal proof demonstrates its validity, provided it is properly defined. Furthermore, the pap&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2410.00475v4-abstract-full').style.display = 'inline'; document.getElementById('2410.00475v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2410.00475v4-abstract-full" style="display: none;">
        This paper presents a probabilistic approach to analyzing copyright infringement disputes. Under this approach, evidentiary principles shaped by case law are formalized in probabilistic terms, allowing for a mathematical examination of issues arising in such disputes. The usefulness of this approach is showcased through its application to the ``inverse ratio rule&#39;&#39; -- a controversial <span class="search-hit mathjax">legal</span> doctrine adopted by some courts. Although this rule has faced significant criticism, a formal proof demonstrates its validity, provided it is properly defined. Furthermore, the paper employs the probabilistic approach to study the copyright safety of generative <span class="search-hit mathjax">AI</span>. Specifically, the Near Access-Free (NAF) condition, previously proposed as a strategy for mitigating the heightened copyright infringement risks of generative <span class="search-hit mathjax">AI</span>, is evaluated. The <span class="search-hit mathjax">analysis</span> reveals that, while the NAF condition mitigates some infringement risks, its justifiability and efficacy are questionable in certain contexts. These findings illustrate how taking a probabilistic perspective can enhance our understanding of copyright jurisprudence and its interaction with generative <span class="search-hit mathjax">AI</span> technology.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2410.00475v4-abstract-full').style.display = 'none'; document.getElementById('2410.00475v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 January, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 1 October, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2409.19104">arXiv:2409.19104</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2409.19104">pdf</a>, <a href="https://arxiv.org/format/2409.19104">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Emerging Technologies">cs.ET</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Responsible <span class="search-hit mathjax">AI</span> in Open Ecosystems: Reconciling Innovation with Risk Assessment and Disclosure
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chakraborti%2C+M">Mahasweta Chakraborti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Prestoza%2C+B+J">Bert Joseph Prestoza</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vincent%2C+N">Nicholas Vincent</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Frey%2C+S">Seth Frey</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2409.19104v1-abstract-short" style="display: inline;">
        The rapid scaling of <span class="search-hit mathjax">AI</span> has spurred a growing emphasis on ethical considerations in both development and practice. This has led to the formulation of increasingly sophisticated model auditing and reporting requirements, as well as governance frameworks to mitigate potential risks to individuals and society. At this critical juncture, we review the practical&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2409.19104v1-abstract-full').style.display = 'inline'; document.getElementById('2409.19104v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2409.19104v1-abstract-full" style="display: none;">
        The rapid scaling of <span class="search-hit mathjax">AI</span> has spurred a growing emphasis on ethical considerations in both development and practice. This has led to the formulation of increasingly sophisticated model auditing and reporting requirements, as well as governance frameworks to mitigate potential risks to individuals and society. At this critical juncture, we review the practical challenges of promoting responsible <span class="search-hit mathjax">AI</span> and transparency in informal sectors like OSS that support vital infrastructure and see widespread use. We focus on how model performance evaluation may inform or inhibit probing of model limitations, biases, and other risks. Our controlled <span class="search-hit mathjax">analysis</span> of 7903 Hugging Face projects found that risk documentation is strongly associated with evaluation practices. Yet, submissions (N=789) from the platform&#39;s most popular competitive leaderboard showed less accountability among high performers. Our findings can inform <span class="search-hit mathjax">AI</span> providers and <span class="search-hit mathjax">legal</span> scholars in designing interventions and policies that preserve open-source innovation while incentivizing ethical uptake.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2409.19104v1-abstract-full').style.display = 'none'; document.getElementById('2409.19104v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 September, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">[Under Review][WIP]</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2409.18222">arXiv:2409.18222</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2409.18222">pdf</a>, <a href="https://arxiv.org/format/2409.18222">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.3390/ai5040134">10.3390/ai5040134 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Trustworthy <span class="search-hit mathjax">AI</span>: Securing Sensitive Data in Large Language Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Feretzakis%2C+G">Georgios Feretzakis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Verykios%2C+V+S">Vassilios S. Verykios</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2409.18222v1-abstract-short" style="display: inline;">
        &hellip;transformed natural language processing (NLP) by enabling robust text generation and understanding. However, their deployment in sensitive domains like healthcare, finance, and <span class="search-hit mathjax">legal</span> services raises critical concerns about privacy and data security. This paper proposes a comprehensive framework for embedding trust mechanisms into LLMs to dynamically control&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2409.18222v1-abstract-full').style.display = 'inline'; document.getElementById('2409.18222v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2409.18222v1-abstract-full" style="display: none;">
        Large Language Models (LLMs) have transformed natural language processing (NLP) by enabling robust text generation and understanding. However, their deployment in sensitive domains like healthcare, finance, and <span class="search-hit mathjax">legal</span> services raises critical concerns about privacy and data security. This paper proposes a comprehensive framework for embedding trust mechanisms into LLMs to dynamically control the disclosure of sensitive information. The framework integrates three core components: User Trust Profiling, Information Sensitivity Detection, and Adaptive Output Control. By leveraging techniques such as Role-Based Access Control (RBAC), Attribute-Based Access Control (ABAC), Named Entity Recognition (NER), contextual <span class="search-hit mathjax">analysis</span>, and privacy-preserving methods like differential privacy, the system ensures that sensitive information is disclosed appropriately based on the user&#39;s trust level. By focusing on balancing data utility and privacy, the proposed solution offers a novel approach to securely deploying LLMs in high-risk environments. Future work will focus on testing this framework across various domains to evaluate its effectiveness in managing sensitive data while maintaining system efficiency.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2409.18222v1-abstract-full').style.display = 'none'; document.getElementById('2409.18222v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 September, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">40 pages, 1 figure</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        <span class="search-hit mathjax">AI</span> 5(4), 2773-2800 (2024)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2409.15348">arXiv:2409.15348</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2409.15348">pdf</a>, <a href="https://arxiv.org/format/2409.15348">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        GLARE: Guided LexRank for Advanced Retrieval in <span class="search-hit mathjax">Legal</span> <span class="search-hit mathjax">Analysis</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Greg%C3%B3rio%2C+F">Fabio Gregório</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Castro%2C+R">Rafaela Castro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Belloze%2C+K">Kele Belloze</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lopes%2C+R+P">Rui Pedro Lopes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bezerra%2C+E">Eduardo Bezerra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2409.15348v1-abstract-short" style="display: inline;">
        &hellip;Citizen&#39;s Charter, provides mechanisms for citizens to petition the Judiciary, including the so-called special appeal. This specific type of appeal aims to standardize the <span class="search-hit mathjax">legal</span> interpretation of Brazilian legislation in cases where the decision contradicts federal laws. The handling of special appeals is a daily task in the Judiciary, regularly presenti&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2409.15348v1-abstract-full').style.display = 'inline'; document.getElementById('2409.15348v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2409.15348v1-abstract-full" style="display: none;">
        The Brazilian Constitution, known as the Citizen&#39;s Charter, provides mechanisms for citizens to petition the Judiciary, including the so-called special appeal. This specific type of appeal aims to standardize the <span class="search-hit mathjax">legal</span> interpretation of Brazilian legislation in cases where the decision contradicts federal laws. The handling of special appeals is a daily task in the Judiciary, regularly presenting significant demands in its courts. We propose a new method called GLARE, based on unsupervised machine learning, to help the <span class="search-hit mathjax">legal</span> analyst classify a special appeal on a topic from a list made available by the National Court of Brazil (STJ). As part of this method, we propose a modification of the graph-based LexRank algorithm, which we call Guided LexRank. This algorithm generates the summary of a special appeal. The degree of similarity between the generated summary and different topics is evaluated using the BM25 algorithm. As a result, the method presents a ranking of themes most appropriate to the analyzed special appeal. The proposed method does not require prior labeling of the text to be evaluated and eliminates the need for large volumes of data to train a model. We evaluate the effectiveness of the method by applying it to a special appeal corpus previously classified by human experts.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2409.15348v1-abstract-full').style.display = 'none'; document.getElementById('2409.15348v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 September, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">26 pages, 8 figures, submitted to <span class="search-hit mathjax">AI</span> and Law</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2409.13252">arXiv:2409.13252</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2409.13252">pdf</a>, <a href="https://arxiv.org/format/2409.13252">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3627673.3680268">10.1145/3627673.3680268 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Leveraging Knowledge Graphs and LLMs to Support and Monitor Legislative Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Colombo%2C+A">Andrea Colombo</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2409.13252v1-abstract-short" style="display: inline;">
        &hellip;and their articles with each other and the broader legislative context.
  At the same time, the rise of large language models (LLMs) such as GPT has opened new opportunities in <span class="search-hit mathjax">legal</span> applications, such as text generation and document drafting. Despite their potential, the use of LLMs in legislative contexts is critical since it requires the absence of halluc&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2409.13252v1-abstract-full').style.display = 'inline'; document.getElementById('2409.13252v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2409.13252v1-abstract-full" style="display: none;">
        Knowledge Graphs (KGs) have been used to organize large datasets into structured, interconnected information, enhancing data analytics across various fields. In the legislative context, one potential natural application of KGs is modeling the intricate set of interconnections that link laws and their articles with each other and the broader legislative context.
  At the same time, the rise of large language models (LLMs) such as GPT has opened new opportunities in <span class="search-hit mathjax">legal</span> applications, such as text generation and document drafting. Despite their potential, the use of LLMs in legislative contexts is critical since it requires the absence of hallucinations and reliance on up-to-date information, as new laws are published on a daily basis.
  This work investigates how Legislative Knowledge Graphs and LLMs can synergize and support legislative processes. We address three key questions: the benefits of using KGs for legislative systems, how LLM can support legislative activities by ensuring an accurate output, and how we can allow non-technical users to use such technologies in their activities. To this aim, we develop Legis <span class="search-hit mathjax">AI</span> Platform, an interactive platform focused on Italian legislation that enhances the possibility of conducting legislative <span class="search-hit mathjax">analysis</span> and that aims to support lawmaking activities.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2409.13252v1-abstract-full').style.display = 'none'; document.getElementById('2409.13252v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 September, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2408.15121">arXiv:2408.15121</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2408.15121">pdf</a>, <a href="https://arxiv.org/format/2408.15121">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.3233/FAIA240568">10.3233/FAIA240568 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance <span class="search-hit mathjax">Analysis</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sovrano%2C+F">Francesco Sovrano</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lognoul%2C+M">Michael Lognoul</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vilone%2C+G">Giulia Vilone</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2408.15121v1-abstract-short" style="display: inline;">
        Significant investment and development have gone into integrating Artificial Intelligence (<span class="search-hit mathjax">AI</span>) in medical and healthcare applications, leading to advanced control systems in medical technology. However, the opacity of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2408.15121v1-abstract-full').style.display = 'inline'; document.getElementById('2408.15121v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2408.15121v1-abstract-full" style="display: none;">
        Significant investment and development have gone into integrating Artificial Intelligence (<span class="search-hit mathjax">AI</span>) in medical and healthcare applications, leading to advanced control systems in medical technology. However, the opacity of <span class="search-hit mathjax">AI</span> systems raises concerns about essential characteristics needed in such sensitive applications, like transparency and trustworthiness. Our study addresses these concerns by investigating a process for selecting the most adequate Explainable <span class="search-hit mathjax">AI</span> (XAI) methods to comply with the explanation requirements of key EU regulations in the context of smart bioelectronics for medical devices. The adopted methodology starts with categorising smart devices by their control mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving into their technology. Then, we analyse these regulations to define their explainability requirements for the various devices and related goals. Simultaneously, we classify XAI methods by their explanatory objectives. This allows for matching <span class="search-hit mathjax">legal</span> explainability requirements with XAI explanatory goals and determining the suitable XAI algorithms for achieving them. Our findings provide a nuanced understanding of which XAI algorithms align better with EU regulations for different types of medical devices. We demonstrate this through practical case studies on different neural implants, from chronic disease management to advanced prosthetics. This study fills a crucial gap in aligning XAI applications in bioelectronics with stringent provisions of EU regulations. It provides a practical framework for developers and researchers, ensuring their <span class="search-hit mathjax">AI</span> innovations advance healthcare technology and adhere to <span class="search-hit mathjax">legal</span> and ethical standards.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2408.15121v1-abstract-full').style.display = 'none'; document.getElementById('2408.15121v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 August, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted for publication at ECAI 2024, main-track</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2408.06210">arXiv:2408.06210</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2408.06210">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Certified Safe: A Schematic for Approval Regulation of Frontier <span class="search-hit mathjax">AI</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Salvador%2C+C">Cole Salvador</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2408.06210v1-abstract-short" style="display: inline;">
        Recent and unremitting capability advances have been accompanied by calls for comprehensive, rather than patchwork, regulation of frontier artificial intelligence (<span class="search-hit mathjax">AI</span>). Approval regulation is emerging as a promising candidate. An approval regulation scheme is one in which a firm cannot&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2408.06210v1-abstract-full').style.display = 'inline'; document.getElementById('2408.06210v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2408.06210v1-abstract-full" style="display: none;">
        Recent and unremitting capability advances have been accompanied by calls for comprehensive, rather than patchwork, regulation of frontier artificial intelligence (<span class="search-hit mathjax">AI</span>). Approval regulation is emerging as a promising candidate. An approval regulation scheme is one in which a firm cannot <span class="search-hit mathjax">legally</span> market, or in some cases develop, a product without explicit approval from a regulator on the basis of experiments performed upon the product that demonstrate its safety. This approach is used successfully by the FDA and FAA. Further, its application to frontier <span class="search-hit mathjax">AI</span> has been publicly supported by many prominent stakeholders. This report proposes an approval regulation schematic for only the largest <span class="search-hit mathjax">AI</span> projects in which scrutiny begins before training and continues through to post-deployment monitoring. The centerpieces of the schematic are two major approval gates, the first requiring approval for large-scale training and the second for deployment. Five main challenges make implementation difficult: noncompliance through unsanctioned deployment, specification of deployment readiness requirements, reliable model experimentation, filtering out safe models before the process, and minimizing regulatory overhead. This report makes a number of crucial recommendations to increase the feasibility of approval regulation, some of which must be followed urgently if such a regime is to succeed in the near future. Further recommendations, produced by this report&#39;s <span class="search-hit mathjax">analysis</span>, may improve the effectiveness of any regulatory regime for frontier <span class="search-hit mathjax">AI</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2408.06210v1-abstract-full').style.display = 'none'; document.getElementById('2408.06210v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 August, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2408.04689">arXiv:2408.04689</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2408.04689">pdf</a>, <a href="https://arxiv.org/format/2408.04689">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Design of a Quality Management System based on the EU Artificial Intelligence Act
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mustroph%2C+H">Henryk Mustroph</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rinderle-Ma%2C+S">Stefanie Rinderle-Ma</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2408.04689v2-abstract-short" style="display: inline;">
        The EU <span class="search-hit mathjax">AI</span> Act mandates that providers and deployers of high-risk&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2408.04689v2-abstract-full').style.display = 'inline'; document.getElementById('2408.04689v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2408.04689v2-abstract-full" style="display: none;">
        The EU <span class="search-hit mathjax">AI</span> Act mandates that providers and deployers of high-risk <span class="search-hit mathjax">AI</span> systems establish a quality management system (QMS). Among other criteria, a QMS shall help verify and document the <span class="search-hit mathjax">AI</span> system design and quality and monitor the proper implementation of all high-risk <span class="search-hit mathjax">AI</span> system requirements. Current research rarely explores practical solutions for implementing the EU <span class="search-hit mathjax">AI</span> Act. Instead, it tends to focus on theoretical concepts. As a result, more attention must be paid to tools that help humans actively check and document <span class="search-hit mathjax">AI</span> systems and orchestrate the implementation of all high-risk <span class="search-hit mathjax">AI</span> system requirements. Therefore, this paper introduces a new design concept and prototype for a QMS as a microservice Software as a Service web application. It connects directly to the <span class="search-hit mathjax">AI</span> system for verification and documentation and enables the orchestration and integration of various sub-services, which can be individually designed, each tailored to specific high-risk <span class="search-hit mathjax">AI</span> system requirements. The first version of the prototype connects to the Phi-3-mini-128k-instruct LLM as an example of an <span class="search-hit mathjax">AI</span> system and integrates a risk management system and a data management system. The prototype is evaluated through a qualitative assessment of the implemented requirements, a GPU memory and performance <span class="search-hit mathjax">analysis</span>, and an evaluation with IT, <span class="search-hit mathjax">AI</span>, and <span class="search-hit mathjax">legal</span> experts.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2408.04689v2-abstract-full').style.display = 'none'; document.getElementById('2408.04689v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 November, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 8 August, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2408.01460">arXiv:2408.01460</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2408.01460">pdf</a>, <a href="https://arxiv.org/format/2408.01460">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        LocalValueBench: A Collaboratively Built and Extensible Benchmark for Evaluating Localized Value Alignment and Ethical Safety in Large Language Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Meadows%2C+G+I">Gwenyth Isobel Meadows</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lau%2C+N+W+L">Nicholas Wai Long Lau</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Susanto%2C+E+A">Eva Adelina Susanto</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+C+L">Chi Lok Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Paul%2C+A">Aditya Paul</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2408.01460v1-abstract-short" style="display: inline;">
        &hellip;large language models (LLMs) requires robust evaluation of their alignment with local values and ethical standards, especially as existing benchmarks often reflect the cultural, <span class="search-hit mathjax">legal</span>, and ideological values of their creators. \textsc{LocalValueBench}, introduced in this paper, is an extensible benchmark designed to assess LLMs&#39; adherence to Australian v&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2408.01460v1-abstract-full').style.display = 'inline'; document.getElementById('2408.01460v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2408.01460v1-abstract-full" style="display: none;">
        The proliferation of large language models (LLMs) requires robust evaluation of their alignment with local values and ethical standards, especially as existing benchmarks often reflect the cultural, <span class="search-hit mathjax">legal</span>, and ideological values of their creators. \textsc{LocalValueBench}, introduced in this paper, is an extensible benchmark designed to assess LLMs&#39; adherence to Australian values, and provides a framework for regulators worldwide to develop their own LLM benchmarks for local value alignment. Employing a novel typology for ethical reasoning and an interrogation approach, we curated comprehensive questions and utilized prompt engineering strategies to probe LLMs&#39; value alignment. Our evaluation criteria quantified deviations from local values, ensuring a rigorous assessment process. Comparative <span class="search-hit mathjax">analysis</span> of three commercial LLMs by USA vendors revealed significant insights into their effectiveness and limitations, demonstrating the critical importance of value alignment. This study offers valuable tools and methodologies for regulators to create tailored benchmarks, highlighting avenues for future research to enhance ethical <span class="search-hit mathjax">AI</span> development.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2408.01460v1-abstract-full').style.display = 'none'; document.getElementById('2408.01460v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 July, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2408.01448">arXiv:2408.01448</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2408.01448">pdf</a>, <a href="https://arxiv.org/format/2408.01448">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        15 Years of Algorithmic Fairness -- Scoping Review of Interdisciplinary Developments in the Field
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lenders%2C+D">Daphne Lenders</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Oloo%2C+A">Anne Oloo</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2408.01448v1-abstract-short" style="display: inline;">
        This paper presents a scoping review of algorithmic fairness research over the past fifteen years, utilising a dataset sourced from Web of Science, HEIN Online, FAccT and <span class="search-hit mathjax">AIES</span> proceedings. All articles come from the computer science and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2408.01448v1-abstract-full').style.display = 'inline'; document.getElementById('2408.01448v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2408.01448v1-abstract-full" style="display: none;">
        This paper presents a scoping review of algorithmic fairness research over the past fifteen years, utilising a dataset sourced from Web of Science, HEIN Online, FAccT and <span class="search-hit mathjax">AIES</span> proceedings. All articles come from the computer science and <span class="search-hit mathjax">legal</span> field and focus on <span class="search-hit mathjax">AI</span> algorithms with potential discriminatory effects on population groups. Each article is annotated based on their discussed technology, demographic focus, application domain and geographical context. Our <span class="search-hit mathjax">analysis</span> reveals a growing trend towards specificity in addressed domains, approaches, and demographics, though a substantial portion of contributions remains generic. Specialised discussions often concentrate on gender- or race-based discrimination in classification tasks. Regarding the geographical context of research, the focus is overwhelming on North America and Europe (Global North Countries), with limited representation from other regions. This raises concerns about overlooking other types of <span class="search-hit mathjax">AI</span> applications, their adverse effects on different types of population groups, and the cultural considerations necessary for addressing these problems. With the help of some highlighted works, we advocate why a wider range of topics must be discussed and why domain-, technological, diverse geographical and demographic-specific approaches are needed. This paper also explores the interdisciplinary nature of algorithmic fairness research in law and computer science to gain insight into how researchers from these fields approach the topic independently or in collaboration. By examining this, we can better understand the unique contributions that both disciplines can bring.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2408.01448v1-abstract-full').style.display = 'none'; document.getElementById('2408.01448v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 July, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2407.20248">arXiv:2407.20248</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2407.20248">pdf</a>, <a href="https://arxiv.org/format/2407.20248">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        LAPIS: Language Model-Augmented Police Investigation System
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+H">Heedou Kim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+D">Dain Kim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lee%2C+J">Jiwoo Lee</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yoon%2C+C">Chanwoong Yoon</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Choi%2C+D">Donghee Choi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gim%2C+M">Mogan Gim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kang%2C+J">Jaewoo Kang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2407.20248v2-abstract-short" style="display: inline;">
        Crime situations are race against time. An <span class="search-hit mathjax">AI</span>-assisted criminal investigation system, providing prompt but precise&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.20248v2-abstract-full').style.display = 'inline'; document.getElementById('2407.20248v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2407.20248v2-abstract-full" style="display: none;">
        Crime situations are race against time. An <span class="search-hit mathjax">AI</span>-assisted criminal investigation system, providing prompt but precise <span class="search-hit mathjax">legal</span> counsel is in need for police officers. We introduce LAPIS (Language Model Augmented Police Investigation System), an automated system that assists police officers to perform rational and <span class="search-hit mathjax">legal</span> investigative actions. We constructed a finetuning dataset and retrieval knowledgebase specialized in crime investigation <span class="search-hit mathjax">legal</span> reasoning task. We extended the dataset&#39;s quality by incorporating manual curation efforts done by a group of domain experts. We then finetuned the pretrained weights of a smaller Korean language model to the newly constructed dataset and integrated it with the crime investigation knowledgebase retrieval approach. Experimental results show LAPIS&#39; potential in providing reliable <span class="search-hit mathjax">legal</span> guidance for police officers, even better than the proprietary GPT-4 model. Qualitative <span class="search-hit mathjax">analysis</span> on the rationales generated by LAPIS demonstrate the model&#39;s reasoning ability to leverage the premises and derive <span class="search-hit mathjax">legally</span> correct conclusions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.20248v2-abstract-full').style.display = 'none'; document.getElementById('2407.20248v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 July, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 19 July, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2407.17481">arXiv:2407.17481</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2407.17481">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Human Oversight of Artificial Intelligence and Technical Standardisation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ho-Dac%2C+M">Marion Ho-Dac</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Martinez%2C+B">Baptiste Martinez</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2407.17481v1-abstract-short" style="display: inline;">
        The adoption of human oversight measures makes it possible to regulate, to varying degrees and in different ways, the decision-making process of Artificial Intelligence (<span class="search-hit mathjax">AI</span>) systems, for example by placing a human being in charge of supervising the system and, upstream, by developing the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.17481v1-abstract-full').style.display = 'inline'; document.getElementById('2407.17481v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2407.17481v1-abstract-full" style="display: none;">
        The adoption of human oversight measures makes it possible to regulate, to varying degrees and in different ways, the decision-making process of Artificial Intelligence (<span class="search-hit mathjax">AI</span>) systems, for example by placing a human being in charge of supervising the system and, upstream, by developing the <span class="search-hit mathjax">AI</span> system to enable such supervision. Within the global governance of <span class="search-hit mathjax">AI</span>, the requirement for human oversight is embodied in several regulatory formats, within a diversity of normative sources. On the one hand, it reinforces the accountability of <span class="search-hit mathjax">AI</span> systems&#39; users (for example, by requiring them to carry out certain checks) and, on the other hand, it better protects the individuals affected by the <span class="search-hit mathjax">AI</span>-based decision (for example, by allowing them to request a review of the decision). In the European context, the <span class="search-hit mathjax">AI</span> Act imposes obligations on providers of high-risk <span class="search-hit mathjax">AI</span> systems (and to some extent also on professional users of these systems, known as deployers), including the introduction of human oversight tools throughout the life cycle of <span class="search-hit mathjax">AI</span> systems, including by design (and their implementation by deployers). The EU legislator is therefore going much further than in the past in &#34;spelling out&#34; the <span class="search-hit mathjax">legal</span> requirement for human oversight. But it does not intend to provide for all implementation details; it calls on standardisation to technically flesh out this requirement (and more broadly all the requirements of section 2 of chapter III) on the basis of article 40 of the <span class="search-hit mathjax">AI</span> Act. In this multi-level regulatory context, the question of the place of humans in the <span class="search-hit mathjax">AI</span> decision-making process should be given particular attention. Indeed, depending on whether it is the law or the technical standard that sets the contours of human oversight, the &#34;regulatory governance&#34; of <span class="search-hit mathjax">AI</span> is not the same: its nature, content and scope are different. This <span class="search-hit mathjax">analysis</span> is at the heart of the contribution made (or to be made) by <span class="search-hit mathjax">legal</span> experts to the central reflection on the most appropriate regulatory governance -- in terms of both its institutional format and its substance -- to ensure the effectiveness of human oversight and <span class="search-hit mathjax">AI</span> trustworthiness.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.17481v1-abstract-full').style.display = 'none'; document.getElementById('2407.17481v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 July, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">in French language</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2407.13621">arXiv:2407.13621</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2407.13621">pdf</a>, <a href="https://arxiv.org/format/2407.13621">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Differential Privacy Mechanisms in Neural Tangent Kernel Regression
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gu%2C+J">Jiuxiang Gu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liang%2C+Y">Yingyu Liang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sha%2C+Z">Zhizhou Sha</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shi%2C+Z">Zhenmei Shi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Song%2C+Z">Zhao Song</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2407.13621v2-abstract-short" style="display: inline;">
        Training data privacy is a fundamental problem in modern Artificial Intelligence (<span class="search-hit mathjax">AI</span>) applications, such as face recognition, recommendation systems, language generation, and many others, as it may contain sensitive user information related to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.13621v2-abstract-full').style.display = 'inline'; document.getElementById('2407.13621v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2407.13621v2-abstract-full" style="display: none;">
        Training data privacy is a fundamental problem in modern Artificial Intelligence (<span class="search-hit mathjax">AI</span>) applications, such as face recognition, recommendation systems, language generation, and many others, as it may contain sensitive user information related to <span class="search-hit mathjax">legal</span> issues. To fundamentally understand how privacy mechanisms work in <span class="search-hit mathjax">AI</span> applications, we study differential privacy (DP) in the Neural Tangent Kernel (NTK) regression setting, where DP is one of the most powerful tools for measuring privacy under statistical learning, and NTK is one of the most popular <span class="search-hit mathjax">analysis</span> frameworks for studying the learning mechanisms of deep neural networks. In our work, we can show provable guarantees for both differential privacy and test accuracy of our NTK regression. Furthermore, we conduct experiments on the basic image classification dataset CIFAR10 to demonstrate that NTK regression can preserve good accuracy under a modest privacy budget, supporting the validity of our <span class="search-hit mathjax">analysis</span>. To our knowledge, this is the first work to provide a DP guarantee for NTK regression.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.13621v2-abstract-full').style.display = 'none'; document.getElementById('2407.13621v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 November, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 18 July, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">WACV 2025</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2407.09322">arXiv:2407.09322</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2407.09322">pdf</a>, <a href="https://arxiv.org/format/2407.09322">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Good Intentions, Risky Inventions: A Method for Assessing the Risks and Benefits of <span class="search-hit mathjax">AI</span> in Mobile and Wearable Uses
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Constantinides%2C+M">Marios Constantinides</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bogucka%2C+E">Edyta Bogucka</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Scepanovic%2C+S">Sanja Scepanovic</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Quercia%2C+D">Daniele Quercia</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2407.09322v3-abstract-short" style="display: inline;">
        Integrating Artificial Intelligence (<span class="search-hit mathjax">AI</span>) into mobile and wearables offers numerous benefits at individual, societal, and environmental levels. Yet, it also spotlights concerns over emerging risks. Traditional assessments of risks and benefits have been sporadic, and often require costly expert&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.09322v3-abstract-full').style.display = 'inline'; document.getElementById('2407.09322v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2407.09322v3-abstract-full" style="display: none;">
        Integrating Artificial Intelligence (<span class="search-hit mathjax">AI</span>) into mobile and wearables offers numerous benefits at individual, societal, and environmental levels. Yet, it also spotlights concerns over emerging risks. Traditional assessments of risks and benefits have been sporadic, and often require costly expert <span class="search-hit mathjax">analysis</span>. We developed a semi-automatic method that leverages Large Language Models (LLMs) to identify <span class="search-hit mathjax">AI</span> uses in mobile and wearables, classify their risks based on the EU <span class="search-hit mathjax">AI</span> Act, and determine their benefits that align with globally recognized long-term sustainable development goals; a manual validation of our method by two experts in mobile and wearable technologies, a <span class="search-hit mathjax">legal</span> and compliance expert, and a cohort of nine individuals with <span class="search-hit mathjax">legal</span> backgrounds who were recruited from Prolific, confirmed its accuracy to be over 85\%. We uncovered that specific applications of mobile computing hold significant potential in improving well-being, safety, and social equality. However, these promising uses are linked to risks involving sensitive data, vulnerable groups, and automated decision-making. To avoid rejecting these risky yet impactful mobile and wearable uses, we propose a risk assessment checklist for the Mobile HCI community.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.09322v3-abstract-full').style.display = 'none'; document.getElementById('2407.09322v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 July, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 12 July, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">28 pages, 4 figures, 2 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2407.08105">arXiv:2407.08105</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2407.08105">pdf</a>, <a href="https://arxiv.org/ps/2407.08105">ps</a>, <a href="https://arxiv.org/format/2407.08105">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Federated Learning and <span class="search-hit mathjax">AI</span> Regulation in the European Union: Who is Responsible? -- An Interdisciplinary <span class="search-hit mathjax">Analysis</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Woisetschl%C3%A4ger%2C+H">Herbert Woisetschläger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mertel%2C+S">Simon Mertel</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kr%C3%B6nke%2C+C">Christoph Krönke</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mayer%2C+R">Ruben Mayer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jacobsen%2C+H">Hans-Arno Jacobsen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2407.08105v2-abstract-short" style="display: inline;">
        &hellip;to avoid substantial fines, prioritizing private and secure data processing with data remaining at its origin. Federated Learning (FL) enables the training of generative <span class="search-hit mathjax">AI</span> Models across data siloes, sharing only model parameters while improving data security. Since FL is a cooperative learning paradigm, clients and servers naturally share&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.08105v2-abstract-full').style.display = 'inline'; document.getElementById('2407.08105v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2407.08105v2-abstract-full" style="display: none;">
        The European Union Artificial Intelligence Act mandates clear stakeholder responsibilities in developing and deploying machine learning applications to avoid substantial fines, prioritizing private and secure data processing with data remaining at its origin. Federated Learning (FL) enables the training of generative <span class="search-hit mathjax">AI</span> Models across data siloes, sharing only model parameters while improving data security. Since FL is a cooperative learning paradigm, clients and servers naturally share <span class="search-hit mathjax">legal</span> responsibility in the FL pipeline. Our work contributes to clarifying the roles of both parties, explains strategies for shifting responsibilities to the server operator, and points out open technical challenges that we must solve to improve FL&#39;s practical applicability under the EU <span class="search-hit mathjax">AI</span> Act.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.08105v2-abstract-full').style.display = 'none'; document.getElementById('2407.08105v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 July, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 10 July, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at the GenLaw&#39;24 workshop in conjunction with ICML&#39;24</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          K.5; I.2.11; C.2.4; D.2.1
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2407.06798">arXiv:2407.06798</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2407.06798">pdf</a>, <a href="https://arxiv.org/format/2407.06798">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        It Cannot Be Right If It Was Written by <span class="search-hit mathjax">AI</span>: On Lawyers&#39; Preferences of Documents Perceived as Authored by an LLM vs a Human
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Harasta%2C+J">Jakub Harasta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Novotn%C3%A1%2C+T">Tereza Novotná</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Savelka%2C+J">Jaromir Savelka</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2407.06798v2-abstract-short" style="display: inline;">
        Large Language Models (LLMs) enable a future in which certain types of <span class="search-hit mathjax">legal</span> documents may be generated automatically. This has a great potential to streamline&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.06798v2-abstract-full').style.display = 'inline'; document.getElementById('2407.06798v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2407.06798v2-abstract-full" style="display: none;">
        Large Language Models (LLMs) enable a future in which certain types of <span class="search-hit mathjax">legal</span> documents may be generated automatically. This has a great potential to streamline <span class="search-hit mathjax">legal</span> processes, lower the cost of <span class="search-hit mathjax">legal</span> services, and dramatically increase access to justice. While many researchers focus on proposing and evaluating LLM-based applications supporting tasks in the <span class="search-hit mathjax">legal</span> domain, there is a notable lack of investigations into how <span class="search-hit mathjax">legal</span> professionals perceive content if they believe an LLM has generated it. Yet, this is a critical point as over-reliance or unfounded scepticism may influence whether such documents bring about appropriate <span class="search-hit mathjax">legal</span> consequences. This study is the necessary <span class="search-hit mathjax">analysis</span> of the ongoing transition towards mature generative <span class="search-hit mathjax">AI</span> systems. Specifically, we examined whether the perception of <span class="search-hit mathjax">legal</span> documents&#39; by lawyers and law students (n=75) varies based on their assumed origin (human-crafted vs <span class="search-hit mathjax">AI</span>-generated). The participants evaluated the documents, focusing on their correctness and language quality. Our <span class="search-hit mathjax">analysis</span> revealed a clear preference for documents perceived as crafted by a human over those believed to be generated by <span class="search-hit mathjax">AI</span>. At the same time, most participants expect the future in which documents will be generated automatically. These findings could be leveraged by <span class="search-hit mathjax">legal</span> practitioners, policymakers, and legislators to implement and adopt <span class="search-hit mathjax">legal</span> document generation technology responsibly and to fuel the necessary discussions on how <span class="search-hit mathjax">legal</span> processes should be updated to reflect recent technological developments.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.06798v2-abstract-full').style.display = 'none'; document.getElementById('2407.06798v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 October, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 9 July, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">40 pages, 12 figures. Accepted for publication with Artificial Intelligence and Law (Springer Nature)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2407.05786">arXiv:2407.05786</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2407.05786">pdf</a>, <a href="https://arxiv.org/ps/2407.05786">ps</a>, <a href="https://arxiv.org/format/2407.05786">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Large Language Models for Judicial Entity Extraction: A Comparative Study
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hussain%2C+A+S">Atin Sakkeer Hussain</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Thomas%2C+A">Anu Thomas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2407.05786v1-abstract-short" style="display: inline;">
        Domain-specific Entity Recognition holds significant importance in <span class="search-hit mathjax">legal</span> contexts, serving as a fundamental task that supports various applications such as question-answering systems, text summarization, machine translation, sentiment&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.05786v1-abstract-full').style.display = 'inline'; document.getElementById('2407.05786v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2407.05786v1-abstract-full" style="display: none;">
        Domain-specific Entity Recognition holds significant importance in <span class="search-hit mathjax">legal</span> contexts, serving as a fundamental task that supports various applications such as question-answering systems, text summarization, machine translation, sentiment <span class="search-hit mathjax">analysis</span>, and information retrieval specifically within case law documents. Recent advancements have highlighted the efficacy of Large Language Models in natural language processing tasks, demonstrating their capability to accurately detect and classify domain-specific facts (entities) from specialized texts like clinical and financial documents. This research investigates the application of Large Language Models in identifying domain-specific entities (e.g., courts, petitioner, judge, lawyer, respondents, FIR nos.) within case law documents, with a specific focus on their aptitude for handling domain-specific language complexity and contextual variations. The study evaluates the performance of state-of-the-art Large Language Model architectures, including Large Language Model Meta <span class="search-hit mathjax">AI</span> 3, Mistral, and Gemma, in the context of extracting judicial facts tailored to Indian judicial texts. Mistral and Gemma emerged as the top-performing models, showcasing balanced precision and recall crucial for accurate entity identification. These findings confirm the value of Large Language Models in judicial documents and demonstrate how they can facilitate and quicken scientific research by producing precise, organised data outputs that are appropriate for in-depth examination.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.05786v1-abstract-full').style.display = 'none'; document.getElementById('2407.05786v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 July, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2024.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.1
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2407.05336">arXiv:2407.05336</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2407.05336">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1177/08944393241235175">10.1177/08944393241235175 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Artificial intelligence, rationalization, and the limits of control in the public sector: the case of tax policy optimization
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mokander%2C+J">Jakob Mokander</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schroeder%2C+R">Ralph Schroeder</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2407.05336v1-abstract-short" style="display: inline;">
        The use of artificial intelligence (<span class="search-hit mathjax">AI</span>) in the public sector is best understood as a continuation and intensification of long standing rationalization and bureaucratization processes. Drawing on Weber, we take the core of these processes to be the replacement of traditions with instrumental rationality, i.e., the most calculable and efficient way of achievin&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.05336v1-abstract-full').style.display = 'inline'; document.getElementById('2407.05336v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2407.05336v1-abstract-full" style="display: none;">
        The use of artificial intelligence (<span class="search-hit mathjax">AI</span>) in the public sector is best understood as a continuation and intensification of long standing rationalization and bureaucratization processes. Drawing on Weber, we take the core of these processes to be the replacement of traditions with instrumental rationality, i.e., the most calculable and efficient way of achieving any given policy objective. In this article, we demonstrate how much of the criticisms, both among the public and in scholarship, directed towards <span class="search-hit mathjax">AI</span> systems spring from well known tensions at the heart of Weberian rationalization. To illustrate this point, we introduce a thought experiment whereby <span class="search-hit mathjax">AI</span> systems are used to optimize tax policy to advance a specific normative end, reducing economic inequality. Our <span class="search-hit mathjax">analysis</span> shows that building a machine-like tax system that promotes social and economic equality is possible. However, it also highlights that <span class="search-hit mathjax">AI</span> driven policy optimization (i) comes at the exclusion of other competing political values, (ii) overrides citizens sense of their noninstrumental obligations to each other, and (iii) undermines the notion of humans as self-determining beings. Contemporary scholarship and advocacy directed towards ensuring that <span class="search-hit mathjax">AI</span> systems are <span class="search-hit mathjax">legal</span>, ethical, and safe build on and reinforce central assumptions that underpin the process of rationalization, including the modern idea that science can sweep away oppressive systems and replace them with a rule of reason that would rescue humans from moral injustices. That is overly optimistic. Science can only provide the means, they cannot dictate the ends. Nonetheless, the use of <span class="search-hit mathjax">AI</span> in the public sector can also benefit the institutions and processes of liberal democracies. Most importantly, <span class="search-hit mathjax">AI</span> driven policy optimization demands that normative ends are made explicit and formalized, thereby subjecting them to public scrutiny and debate.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.05336v1-abstract-full').style.display = 'none'; document.getElementById('2407.05336v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 July, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2406.18211">arXiv:2406.18211</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2406.18211">pdf</a>, <a href="https://arxiv.org/format/2406.18211">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">AI</span> Cards: Towards an Applied Framework for Machine-Readable <span class="search-hit mathjax">AI</span> and Risk Documentation Inspired by the EU <span class="search-hit mathjax">AI</span> Act
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Golpayegani%2C+D">Delaram Golpayegani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hupont%2C+I">Isabelle Hupont</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Panigutti%2C+C">Cecilia Panigutti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pandit%2C+H+J">Harshvardhan J. Pandit</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schade%2C+S">Sven Schade</a>, 
      
      <a href="/search/?searchtype=author&amp;query=O%27Sullivan%2C+D">Declan O&#39;Sullivan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lewis%2C+D">Dave Lewis</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2406.18211v1-abstract-short" style="display: inline;">
        With the upcoming enforcement of the EU <span class="search-hit mathjax">AI</span> Act, documentation of high-risk&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.18211v1-abstract-full').style.display = 'inline'; document.getElementById('2406.18211v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2406.18211v1-abstract-full" style="display: none;">
        With the upcoming enforcement of the EU <span class="search-hit mathjax">AI</span> Act, documentation of high-risk <span class="search-hit mathjax">AI</span> systems and their risk management information will become a <span class="search-hit mathjax">legal</span> requirement playing a pivotal role in demonstration of compliance. Despite its importance, there is a lack of standards and guidelines to assist with drawing up <span class="search-hit mathjax">AI</span> and risk documentation aligned with the <span class="search-hit mathjax">AI</span> Act. This paper aims to address this gap by providing an in-depth <span class="search-hit mathjax">analysis</span> of the <span class="search-hit mathjax">AI</span> Act&#39;s provisions regarding technical documentation, wherein we particularly focus on <span class="search-hit mathjax">AI</span> risk management. On the basis of this <span class="search-hit mathjax">analysis</span>, we propose <span class="search-hit mathjax">AI</span> Cards as a novel holistic framework for representing a given intended use of an <span class="search-hit mathjax">AI</span> system by encompassing information regarding technical specifications, context of use, and risk management, both in human- and machine-readable formats. While the human-readable representation of <span class="search-hit mathjax">AI</span> Cards provides <span class="search-hit mathjax">AI</span> stakeholders with a transparent and comprehensible overview of the <span class="search-hit mathjax">AI</span> use case, its machine-readable specification leverages on state of the art Semantic Web technologies to embody the interoperability needed for exchanging documentation within the <span class="search-hit mathjax">AI</span> value chain. This brings the flexibility required for reflecting changes applied to the <span class="search-hit mathjax">AI</span> system and its context, provides the scalability needed to accommodate potential amendments to <span class="search-hit mathjax">legal</span> requirements, and enables development of automated tools to assist with <span class="search-hit mathjax">legal</span> compliance and conformity assessment tasks. To solidify the benefits, we provide an exemplar <span class="search-hit mathjax">AI</span> Card for an <span class="search-hit mathjax">AI</span>-based student proctoring system and further discuss its potential applications within and beyond the context of the <span class="search-hit mathjax">AI</span> Act.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.18211v1-abstract-full').style.display = 'none'; document.getElementById('2406.18211v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 June, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2406.16592">arXiv:2406.16592</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2406.16592">pdf</a>, <a href="https://arxiv.org/format/2406.16592">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Toward Fairer Face Recognition Datasets
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Fournier-Montgieux%2C+A">Alexandre Fournier-Montgieux</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soumm%2C+M">Michael Soumm</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Popescu%2C+A">Adrian Popescu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Luvison%2C+B">Bertrand Luvison</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Borgne%2C+H+L">Hervé Le Borgne</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2406.16592v3-abstract-short" style="display: inline;">
        Face recognition and verification are two computer vision tasks whose performance has progressed with the introduction of deep representations. However, ethical, <span class="search-hit mathjax">legal</span>, and technical challenges due to the sensitive character of face data and biases in real training datasets hinder their development. Generative&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.16592v3-abstract-full').style.display = 'inline'; document.getElementById('2406.16592v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2406.16592v3-abstract-full" style="display: none;">
        Face recognition and verification are two computer vision tasks whose performance has progressed with the introduction of deep representations. However, ethical, <span class="search-hit mathjax">legal</span>, and technical challenges due to the sensitive character of face data and biases in real training datasets hinder their development. Generative <span class="search-hit mathjax">AI</span> addresses privacy by creating fictitious identities, but fairness problems persist. We promote fairness by introducing a demographic attributes balancing mechanism in generated training datasets. We experiment with an existing real dataset, three generated training datasets, and the balanced versions of a diffusion-based dataset. We propose a comprehensive evaluation that considers accuracy and fairness equally and includes a rigorous regression-based statistical <span class="search-hit mathjax">analysis</span> of attributes. The <span class="search-hit mathjax">analysis</span> shows that balancing reduces demographic unfairness. Also, a performance gap persists despite generation becoming more accurate with time. The proposed balancing method and comprehensive verification evaluation promote fairer and transparent face recognition and verification.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.16592v3-abstract-full').style.display = 'none'; document.getElementById('2406.16592v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 October, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 24 June, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2406.10632">arXiv:2406.10632</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2406.10632">pdf</a>, <a href="https://arxiv.org/ps/2406.10632">ps</a>, <a href="https://arxiv.org/format/2406.10632">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.36227/techrxiv.171527587.75649430/v1">10.36227/techrxiv.171527587.75649430/v1 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Applications of Generative <span class="search-hit mathjax">AI</span> in Healthcare: algorithmic, ethical, <span class="search-hit mathjax">legal</span> and societal considerations
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Okonji%2C+O+R">Onyekachukwu R. Okonji</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yunusov%2C+K">Kamol Yunusov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gordon%2C+B">Bonnie Gordon</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2406.10632v1-abstract-short" style="display: inline;">
        Generative <span class="search-hit mathjax">AI</span> is rapidly transforming medical imaging and text&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.10632v1-abstract-full').style.display = 'inline'; document.getElementById('2406.10632v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2406.10632v1-abstract-full" style="display: none;">
        Generative <span class="search-hit mathjax">AI</span> is rapidly transforming medical imaging and text <span class="search-hit mathjax">analysis</span>, offering immense potential for enhanced diagnosis and personalized care. However, this transformative technology raises crucial ethical, societal, and <span class="search-hit mathjax">legal</span> questions. This paper delves into these complexities, examining issues of accuracy, informed consent, data privacy, and algorithmic limitations in the context of generative <span class="search-hit mathjax">AI&#39;s</span> application to medical imaging and text. We explore the <span class="search-hit mathjax">legal</span> landscape surrounding liability and accountability, emphasizing the need for robust regulatory frameworks. Furthermore, we dissect the algorithmic challenges, including data biases, model limitations, and workflow integration. By critically analyzing these challenges and proposing responsible solutions, we aim to foster a roadmap for ethical and responsible implementation of generative <span class="search-hit mathjax">AI</span> in healthcare, ensuring its transformative potential serves humanity with utmost care and precision.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.10632v1-abstract-full').style.display = 'none'; document.getElementById('2406.10632v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 June, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2406.08695">arXiv:2406.08695</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2406.08695">pdf</a>, <a href="https://arxiv.org/format/2406.08695">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Global <span class="search-hit mathjax">AI</span> Governance in Healthcare: A Cross-Jurisdictional Regulatory <span class="search-hit mathjax">Analysis</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chakraborty%2C+A">Attrayee Chakraborty</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Karhade%2C+M">Mandar Karhade</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2406.08695v1-abstract-short" style="display: inline;">
        Artificial Intelligence (<span class="search-hit mathjax">AI</span>) is being adopted across the world and promises a new revolution in healthcare. While&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.08695v1-abstract-full').style.display = 'inline'; document.getElementById('2406.08695v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2406.08695v1-abstract-full" style="display: none;">
        Artificial Intelligence (<span class="search-hit mathjax">AI</span>) is being adopted across the world and promises a new revolution in healthcare. While <span class="search-hit mathjax">AI</span>-enabled medical devices in North America dominate 42.3% of the global market, the use of <span class="search-hit mathjax">AI</span>-enabled medical devices in other countries is still a story waiting to be unfolded. We aim to delve deeper into global regulatory approaches towards <span class="search-hit mathjax">AI</span> use in healthcare, with a focus on how common themes are emerging globally. We compare these themes to the World Health Organization&#39;s (WHO) regulatory considerations and principles on ethical use of <span class="search-hit mathjax">AI</span> for healthcare applications. Our work seeks to take a global perspective on <span class="search-hit mathjax">AI</span> policy by analyzing 14 <span class="search-hit mathjax">legal</span> jurisdictions including countries representative of various regions in the world (North America, South America, South East Asia, Middle East, Africa, Australia, and the Asia-Pacific). Our eventual goal is to foster a global conversation on the ethical use of <span class="search-hit mathjax">AI</span> in healthcare and the regulations that will guide it. We propose solutions to promote international harmonization of <span class="search-hit mathjax">AI</span> regulations and examine the requirements for regulating generative <span class="search-hit mathjax">AI</span>, using China and Singapore as examples of countries with well-developed policies in this area.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.08695v1-abstract-full').style.display = 'none'; document.getElementById('2406.08695v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 June, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">32 pages, 8 figures, 5 tables</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          K.4.1; K.6; K.5.2; J.3
        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2406.04136">arXiv:2406.04136</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2406.04136">pdf</a>, <a href="https://arxiv.org/format/2406.04136">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Legal</span> Judgment Reimagined: PredEx and the Rise of Intelligent <span class="search-hit mathjax">AI</span> Interpretation in Indian Courts
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Nigam%2C+S+K">Shubham Kumar Nigam</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sharma%2C+A">Anurag Sharma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Khanna%2C+D">Danush Khanna</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shallum%2C+N">Noel Shallum</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ghosh%2C+K">Kripabandhu Ghosh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bhattacharya%2C+A">Arnab Bhattacharya</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2406.04136v1-abstract-short" style="display: inline;">
        In the era of Large Language Models (LLMs), predicting judicial outcomes poses significant challenges due to the complexity of <span class="search-hit mathjax">legal</span> proceedings and the scarcity of expert-annotated datasets. Addressing this, we introduce \textbf{Pred}iction with \textbf{Ex}planation (\texttt{PredEx}), the largest expert-annotated dataset for&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.04136v1-abstract-full').style.display = 'inline'; document.getElementById('2406.04136v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2406.04136v1-abstract-full" style="display: none;">
        In the era of Large Language Models (LLMs), predicting judicial outcomes poses significant challenges due to the complexity of <span class="search-hit mathjax">legal</span> proceedings and the scarcity of expert-annotated datasets. Addressing this, we introduce \textbf{Pred}iction with \textbf{Ex}planation (\texttt{PredEx}), the largest expert-annotated dataset for <span class="search-hit mathjax">legal</span> judgment prediction and explanation in the Indian context, featuring over 15,000 annotations. This groundbreaking corpus significantly enhances the training and evaluation of <span class="search-hit mathjax">AI</span> models in <span class="search-hit mathjax">legal</span> <span class="search-hit mathjax">analysis</span>, with innovations including the application of instruction tuning to LLMs. This method has markedly improved the predictive accuracy and explanatory depth of these models for <span class="search-hit mathjax">legal</span> judgments. We employed various transformer-based models, tailored for both general and Indian <span class="search-hit mathjax">legal</span> contexts. Through rigorous lexical, semantic, and expert assessments, our models effectively leverage \texttt{PredEx} to provide precise predictions and meaningful explanations, establishing it as a valuable benchmark for both the <span class="search-hit mathjax">legal</span> profession and the NLP community.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.04136v1-abstract-full').style.display = 'none'; document.getElementById('2406.04136v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 June, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2406.02650">arXiv:2406.02650</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2406.02650">pdf</a>, <a href="https://arxiv.org/format/2406.02650">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        By Fair Means or Foul: Quantifying Collusion in a Market Simulation with Deep Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Schlechtinger%2C+M">Michael Schlechtinger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kosack%2C+D">Damaris Kosack</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Krause%2C+F">Franz Krause</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Paulheim%2C+H">Heiko Paulheim</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2406.02650v1-abstract-short" style="display: inline;">
        In the rapidly evolving landscape of eCommerce, Artificial Intelligence (<span class="search-hit mathjax">AI</span>) based pricing algorithms, particularly those utilizing Reinforcement Learning (RL), are becoming increasingly prevalent. This rise has led to an inextricable pricing situation with the potential for market collusion. Our research employs an experimental oligopoly model of repeated p&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.02650v1-abstract-full').style.display = 'inline'; document.getElementById('2406.02650v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2406.02650v1-abstract-full" style="display: none;">
        In the rapidly evolving landscape of eCommerce, Artificial Intelligence (<span class="search-hit mathjax">AI</span>) based pricing algorithms, particularly those utilizing Reinforcement Learning (RL), are becoming increasingly prevalent. This rise has led to an inextricable pricing situation with the potential for market collusion. Our research employs an experimental oligopoly model of repeated price competition, systematically varying the environment to cover scenarios from basic economic theory to subjective consumer demand preferences. We also introduce a novel demand framework that enables the implementation of various demand models, allowing for a weighted blending of different models. In contrast to existing research in this domain, we aim to investigate the strategies and emerging pricing patterns developed by the agents, which may lead to a collusive outcome. Furthermore, we investigate a scenario where agents cannot observe their competitors&#39; prices. Finally, we provide a comprehensive <span class="search-hit mathjax">legal</span> <span class="search-hit mathjax">analysis</span> across all scenarios. Our findings indicate that RL-based <span class="search-hit mathjax">AI</span> agents converge to a collusive state characterized by the charging of supracompetitive prices, without necessarily requiring inter-agent communication. Implementing alternative RL algorithms, altering the number of agents or simulation settings, and restricting the scope of the agents&#39; observation space does not significantly impact the collusive market outcome behavior.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.02650v1-abstract-full').style.display = 'none'; document.getElementById('2406.02650v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 June, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Preprint for IJCAI 2024</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2405.18492">arXiv:2405.18492</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2405.18492">pdf</a>, <a href="https://arxiv.org/format/2405.18492">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        LLMs and Memorization: On Quality and Specificity of Copyright Compliance
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mueller%2C+F+B">Felix B Mueller</a>, 
      
      <a href="/search/?searchtype=author&amp;query=G%C3%B6rge%2C+R">Rebekka Görge</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bernzen%2C+A+K">Anna K Bernzen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pirk%2C+J+C">Janna C Pirk</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Poretschkin%2C+M">Maximilian Poretschkin</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2405.18492v3-abstract-short" style="display: inline;">
        &hellip;reproduce parts of their training data, including copyrighted work. This is an important problem to solve, as it may violate existing copyright laws as well as the European <span class="search-hit mathjax">AI</span> Act. In this work, we propose a systematic&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2405.18492v3-abstract-full').style.display = 'inline'; document.getElementById('2405.18492v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2405.18492v3-abstract-full" style="display: none;">
        Memorization in large language models (LLMs) is a growing concern. LLMs have been shown to easily reproduce parts of their training data, including copyrighted work. This is an important problem to solve, as it may violate existing copyright laws as well as the European <span class="search-hit mathjax">AI</span> Act. In this work, we propose a systematic <span class="search-hit mathjax">analysis</span> to quantify the extent of potential copyright infringements in LLMs using European law as an example. Unlike previous work, we evaluate instruction-finetuned models in a realistic end-user scenario. Our <span class="search-hit mathjax">analysis</span> builds on a proposed threshold of 160 characters, which we borrow from the German Copyright Service Provider Act and a fuzzy text matching algorithm to identify potentially copyright-infringing textual reproductions. The specificity of countermeasures against copyright infringement is analyzed by comparing model behavior on copyrighted and public domain data. We investigate what behaviors models show instead of producing protected text (such as refusal or hallucination) and provide a first <span class="search-hit mathjax">legal</span> assessment of these behaviors. We find that there are huge differences in copyright compliance, specificity, and appropriate refusal among popular LLMs. Alpaca, GPT 4, GPT 3.5, and Luminous perform best in our comparison, with OpenGPT-X, Alpaca, and Luminous producing a particularly low absolute number of potential copyright violations. Code can be found at https://github.com/felixbmuller/llms-memorization-copyright.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2405.18492v3-abstract-full').style.display = 'none'; document.getElementById('2405.18492v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 November, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 28 May, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages, 3 figures, AIES 2024 conference</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.7
        
      </p>
    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Proceedings of the AAAI/ACM Conference on <span class="search-hit mathjax">AI</span>, Ethics, and Society, 7(1), 984-996, 2024
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2405.12910">arXiv:2405.12910</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2405.12910">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/s10506-025-09434-0">10.1007/s10506-025-09434-0 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Topic Classification of Case Law Using a Large Language Model and a New Taxonomy for UK Law: <span class="search-hit mathjax">AI</span> Insights into Summary Judgment
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sargeant%2C+H">Holli Sargeant</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Izzidien%2C+A">Ahmed Izzidien</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Steffek%2C+F">Felix Steffek</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2405.12910v3-abstract-short" style="display: inline;">
        This paper addresses a critical gap in <span class="search-hit mathjax">legal</span> analytics by developing and applying a novel taxonomy for topic classification of summary judgment cases in the United Kingdom. Using a curated dataset of summary judgment cases, we use the Large Language Model Claude 3 Opus to explore functional topics and trends. We find that Claude 3 Opus correctly classified t&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2405.12910v3-abstract-full').style.display = 'inline'; document.getElementById('2405.12910v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2405.12910v3-abstract-full" style="display: none;">
        This paper addresses a critical gap in <span class="search-hit mathjax">legal</span> analytics by developing and applying a novel taxonomy for topic classification of summary judgment cases in the United Kingdom. Using a curated dataset of summary judgment cases, we use the Large Language Model Claude 3 Opus to explore functional topics and trends. We find that Claude 3 Opus correctly classified the topic with an accuracy of 87.13% and an F1 score of 0.87. The <span class="search-hit mathjax">analysis</span> reveals distinct patterns in the application of summary judgments across various <span class="search-hit mathjax">legal</span> domains. As case law in the United Kingdom is not originally labelled with keywords or a topic filtering option, the findings not only refine our understanding of the thematic underpinnings of summary judgments but also illustrate the potential of combining traditional and <span class="search-hit mathjax">AI</span>-driven approaches in <span class="search-hit mathjax">legal</span> classification. Therefore, this paper provides a new and general taxonomy for UK law. The implications of this work serve as a foundation for further research and policy discussions in the field of judicial administration and computational <span class="search-hit mathjax">legal</span> research methodologies.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2405.12910v3-abstract-full').style.display = 'none'; document.getElementById('2405.12910v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 February, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 May, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2024.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Artificial Intelligence and Law (2025)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2405.12193">arXiv:2405.12193</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2405.12193">pdf</a>, <a href="https://arxiv.org/format/2405.12193">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Narrow Depth and Breadth of Corporate Responsible <span class="search-hit mathjax">AI</span> Research
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ahmed%2C+N">Nur Ahmed</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Das%2C+A">Amit Das</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Martin%2C+K">Kirsten Martin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Banerjee%2C+K">Kawshik Banerjee</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2405.12193v1-abstract-short" style="display: inline;">
        The transformative potential of <span class="search-hit mathjax">AI</span> presents remarkable opportunities, but also significant risks, underscoring the importance of responsible&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2405.12193v1-abstract-full').style.display = 'inline'; document.getElementById('2405.12193v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2405.12193v1-abstract-full" style="display: none;">
        The transformative potential of <span class="search-hit mathjax">AI</span> presents remarkable opportunities, but also significant risks, underscoring the importance of responsible <span class="search-hit mathjax">AI</span> development and deployment. Despite a growing emphasis on this area, there is limited understanding of industry&#39;s engagement in responsible <span class="search-hit mathjax">AI</span> research, i.e., the critical examination of <span class="search-hit mathjax">AI&#39;s</span> ethical, social, and <span class="search-hit mathjax">legal</span> dimensions. To address this gap, we analyzed over 6 million peer-reviewed articles and 32 million patent citations using multiple methods across five distinct datasets to quantify industry&#39;s engagement. Our findings reveal that the majority of <span class="search-hit mathjax">AI</span> firms show limited or no engagement in this critical subfield of <span class="search-hit mathjax">AI</span>. We show a stark disparity between industry&#39;s dominant presence in conventional <span class="search-hit mathjax">AI</span> research and its limited engagement in responsible <span class="search-hit mathjax">AI</span>. Leading <span class="search-hit mathjax">AI</span> firms exhibit significantly lower output in responsible <span class="search-hit mathjax">AI</span> research compared to their conventional <span class="search-hit mathjax">AI</span> research and the contributions of leading academic institutions. Our linguistic <span class="search-hit mathjax">analysis</span> documents a narrower scope of responsible <span class="search-hit mathjax">AI</span> research within industry, with a lack of diversity in key topics addressed. Our large-scale patent citation <span class="search-hit mathjax">analysis</span> uncovers a pronounced disconnect between responsible <span class="search-hit mathjax">AI</span> research and the commercialization of <span class="search-hit mathjax">AI</span> technologies, suggesting that industry patents rarely build upon insights generated by the responsible <span class="search-hit mathjax">AI</span> literature. This gap highlights the potential for <span class="search-hit mathjax">AI</span> development to diverge from a socially optimal path, risking unintended consequences due to insufficient consideration of ethical and societal implications. Our results highlight the urgent need for industry to publicly engage in responsible <span class="search-hit mathjax">AI</span> research to absorb academic knowledge, cultivate public trust, and proactively mitigate <span class="search-hit mathjax">AI</span>-induced societal harms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2405.12193v1-abstract-full').style.display = 'none'; document.getElementById('2405.12193v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 May, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2405.10248">arXiv:2405.10248</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2405.10248">pdf</a>, <a href="https://arxiv.org/format/2405.10248">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Co-Matching: Towards Human-Machine Collaborative <span class="search-hit mathjax">Legal</span> Case Matching
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+C">Chen Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+X">Xinwei Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Deng%2C+Y">Yang Deng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lei%2C+W">Wenqiang Lei</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lv%2C+J">JianCheng Lv</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chua%2C+T">Tat-Seng Chua</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2405.10248v1-abstract-short" style="display: inline;">
        Recent efforts have aimed to improve <span class="search-hit mathjax">AI</span> machines in&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2405.10248v1-abstract-full').style.display = 'inline'; document.getElementById('2405.10248v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2405.10248v1-abstract-full" style="display: none;">
        Recent efforts have aimed to improve <span class="search-hit mathjax">AI</span> machines in <span class="search-hit mathjax">legal</span> case matching by integrating <span class="search-hit mathjax">legal</span> domain knowledge. However, successful <span class="search-hit mathjax">legal</span> case matching requires the tacit knowledge of <span class="search-hit mathjax">legal</span> practitioners, which is difficult to verbalize and encode into machines. This emphasizes the crucial role of involving <span class="search-hit mathjax">legal</span> practitioners in high-stakes <span class="search-hit mathjax">legal</span> case matching. To address this, we propose a collaborative matching framework called Co-Matching, which encourages both the machine and the <span class="search-hit mathjax">legal</span> practitioner to participate in the matching process, integrating tacit knowledge. Unlike existing methods that rely solely on the machine, Co-Matching allows both the <span class="search-hit mathjax">legal</span> practitioner and the machine to determine key sentences and then combine them probabilistically. Co-Matching introduces a method called ProtoEM to estimate human decision uncertainty, facilitating the probabilistic combination. Experimental results demonstrate that Co-Matching consistently outperforms existing <span class="search-hit mathjax">legal</span> case matching methods, delivering significant performance improvements over human- and machine-based matching in isolation (on average, +5.51% and +8.71%, respectively). Further <span class="search-hit mathjax">analysis</span> shows that Co-Matching also ensures better human-machine collaboration effectiveness. Our study represents a pioneering effort in human-machine collaboration for the matching task, marking a milestone for future collaborative matching studies.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2405.10248v1-abstract-full').style.display = 'none'; document.getElementById('2405.10248v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 May, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Draft V1: 23 pages, 7 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2404.18308">arXiv:2404.18308</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2404.18308">pdf</a>, <a href="https://arxiv.org/format/2404.18308">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Near-Term Enforcement of <span class="search-hit mathjax">AI</span> Chip Export Controls Using A Firmware-Based Design for Offline Licensing
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Petrie%2C+J">James Petrie</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2404.18308v2-abstract-short" style="display: inline;">
        Offline Licensing is a mechanism for compute governance that could be used to prevent unregulated training of potentially dangerous frontier <span class="search-hit mathjax">AI</span> models. The mechanism works by disabling&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.18308v2-abstract-full').style.display = 'inline'; document.getElementById('2404.18308v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2404.18308v2-abstract-full" style="display: none;">
        Offline Licensing is a mechanism for compute governance that could be used to prevent unregulated training of potentially dangerous frontier <span class="search-hit mathjax">AI</span> models. The mechanism works by disabling <span class="search-hit mathjax">AI</span> chips unless they have an unused license from a regulator. In this report, we present a design for a minimal version of Offline Licensing that could be delivered via a firmware update. Existing <span class="search-hit mathjax">AI</span> chips could potentially support Offline Licensing within a year if they have the following (relatively common) hardware security features: firmware verification, firmware rollback protection, and secure non-volatile memory. Public documentation suggests that NVIDIA&#39;s H100 <span class="search-hit mathjax">AI</span> chip already has these security features. Without additional hardware modifications, the system is susceptible to physical hardware attacks. However, these attacks might require expensive equipment and could be difficult to reliably apply to thousands of <span class="search-hit mathjax">AI</span> chips. A firmware-based Offline Licensing design shares the same <span class="search-hit mathjax">legal</span> requirements and license approval mechanism as a hardware-based solution. Implementing a firmware-based solution now could accelerate the eventual deployment of a more secure hardware-based solution in the future. For <span class="search-hit mathjax">AI</span> chip manufacturers, implementing this security mechanism might allow chips to be sold to customers that would otherwise be prohibited by export restrictions. For governments, it may be important to be able to prevent unsafe or malicious actors from training frontier <span class="search-hit mathjax">AI</span> models in the next few years. Based on this initial <span class="search-hit mathjax">analysis</span>, firmware-based Offline Licensing could partially solve urgent security and trade problems and is technically feasible for <span class="search-hit mathjax">AI</span> chips that have common hardware security features.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.18308v2-abstract-full').style.display = 'none'; document.getElementById('2404.18308v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 May, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 28 April, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2404.10032">arXiv:2404.10032</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2404.10032">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Detecting <span class="search-hit mathjax">AI</span> Generated Text Based on NLP and Machine Learning Approaches
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Prova%2C+N">Nuzhat Prova</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2404.10032v1-abstract-short" style="display: inline;">
        Recent advances in natural language processing (NLP) may enable artificial intelligence (<span class="search-hit mathjax">AI</span>) models to generate writing that is identical to human written form in the future. This might have profound ethical,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.10032v1-abstract-full').style.display = 'inline'; document.getElementById('2404.10032v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2404.10032v1-abstract-full" style="display: none;">
        Recent advances in natural language processing (NLP) may enable artificial intelligence (<span class="search-hit mathjax">AI</span>) models to generate writing that is identical to human written form in the future. This might have profound ethical, <span class="search-hit mathjax">legal</span>, and social repercussions. This study aims to address this problem by offering an accurate <span class="search-hit mathjax">AI</span> detector model that can differentiate between electronically produced text and human-written text. Our approach includes machine learning methods such as XGB Classifier, SVM, BERT architecture deep learning models. Furthermore, our results show that the BERT performs better than previous models in identifying information generated by <span class="search-hit mathjax">AI</span> from information provided by humans. Provide a comprehensive <span class="search-hit mathjax">analysis</span> of the current state of <span class="search-hit mathjax">AI</span>-generated text identification in our assessment of pertinent studies. Our testing yielded positive findings, showing that our strategy is successful, with the BERT emerging as the most probable answer. We analyze the research&#39;s societal implications, highlighting the possible advantages for various industries while addressing sustainability issues pertaining to morality and the environment. The XGB classifier and SVM give 0.84 and 0.81 accuracy in this article, respectively. The greatest accuracy in this research is provided by the BERT model, which provides 0.93% accuracy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.10032v1-abstract-full').style.display = 'none'; document.getElementById('2404.10032v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 April, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2404.02990">arXiv:2404.02990</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2404.02990">pdf</a>, <a href="https://arxiv.org/format/2404.02990">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        ASAP: Interpretable <span class="search-hit mathjax">Analysis</span> and Summarization of <span class="search-hit mathjax">AI</span>-generated Image Patterns at Scale
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+J">Jinbin Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+C">Chen Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mishra%2C+A">Aditi Mishra</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kwon%2C+B+C">Bum Chul Kwon</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Z">Zhicheng Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bryan%2C+C">Chris Bryan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2404.02990v1-abstract-short" style="display: inline;">
        &hellip;to produce realistic images. Despite potential benefits, concerns grow about its misuse, particularly in generating deceptive images that could raise significant ethical, <span class="search-hit mathjax">legal</span>, and societal issues. Consequently, there is growing demand to empower users to effectively discern and comprehend patterns of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.02990v1-abstract-full').style.display = 'inline'; document.getElementById('2404.02990v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2404.02990v1-abstract-full" style="display: none;">
        Generative image models have emerged as a promising technology to produce realistic images. Despite potential benefits, concerns grow about its misuse, particularly in generating deceptive images that could raise significant ethical, <span class="search-hit mathjax">legal</span>, and societal issues. Consequently, there is growing demand to empower users to effectively discern and comprehend patterns of <span class="search-hit mathjax">AI</span>-generated images. To this end, we developed ASAP, an interactive visualization system that automatically extracts distinct patterns of <span class="search-hit mathjax">AI</span>-generated images and allows users to interactively explore them via various views. To uncover fake patterns, ASAP introduces a novel image encoder, adapted from CLIP, which transforms images into compact &#34;distilled&#34; representations, enriched with information for differentiating authentic and fake images. These representations generate gradients that propagate back to the attention maps of CLIP&#39;s transformer block. This process quantifies the relative importance of each pixel to image authenticity or fakeness, exposing key deceptive patterns. ASAP enables the at scale interactive <span class="search-hit mathjax">analysis</span> of these patterns through multiple, coordinated visualizations. This includes a representation overview with innovative cell glyphs to aid in the exploration and qualitative evaluation of fake patterns across a vast array of images, as well as a pattern view that displays authenticity-indicating patterns in images and quantifies their impact. ASAP supports the <span class="search-hit mathjax">analysis</span> of cutting-edge generative models with the latest architectures, including GAN-based models like proGAN and diffusion models like the latent diffusion model. We demonstrate ASAP&#39;s usefulness through two usage scenarios using multiple fake image detection benchmark datasets, revealing its ability to identify and understand hidden patterns in <span class="search-hit mathjax">AI</span>-generated images, especially in detecting fake human faces produced by diffusion-based techniques.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.02990v1-abstract-full').style.display = 'none'; document.getElementById('2404.02990v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 April, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, 6 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2404.01403">arXiv:2404.01403</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2404.01403">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards a potential paradigm shift in health data collection and <span class="search-hit mathjax">analysis</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Herzog%2C+D+J">David Josef Herzog</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Herzog%2C+N+J">Nitsa Judith Herzog</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2404.01403v1-abstract-short" style="display: inline;">
        &hellip;The modern cyber-physical space underlines the role of the person in the expanding context of computerization and big data processing. In healthcare, where data collection and <span class="search-hit mathjax">analysis</span> particularly depend on human efforts, the disruptive nature of these developments is evident. Adaptation to this process requires deep scrutiny of the trends and recognition o&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.01403v1-abstract-full').style.display = 'inline'; document.getElementById('2404.01403v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2404.01403v1-abstract-full" style="display: none;">
        Industrial Revolution 4.0 transforms healthcare systems. The first three technological revolutions changed the relationship between human and machine interaction due to the exponential growth of machine numbers. The fourth revolution put humans into a situation where heterogeneous data is produced with unmatched quantity and quality not only by traditional methods, enforced by digitization, but also by ubiquitous computing, machine-to-machine interactions and smart environment. The modern cyber-physical space underlines the role of the person in the expanding context of computerization and big data processing. In healthcare, where data collection and <span class="search-hit mathjax">analysis</span> particularly depend on human efforts, the disruptive nature of these developments is evident. Adaptation to this process requires deep scrutiny of the trends and recognition of future medical data technologies` evolution. Significant difficulties arise from discrepancies in requirements by healthcare, administrative and technology stakeholders. Black box and grey box decisions made in medical imaging and diagnostic Decision Support Software are often not transparent enough for the professional, social and medico-<span class="search-hit mathjax">legal</span> requirements. While Explainable <span class="search-hit mathjax">AI</span> proposes a partial solution for <span class="search-hit mathjax">AI</span> applications in medicine, the approach has to be wider and multiplex. LLM potential and limitations are also discussed. This paper lists the most significant issues in these topics and describes possible solutions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.01403v1-abstract-full').style.display = 'none'; document.getElementById('2404.01403v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 April, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">14 pages, 6 figurers, 3 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2404.00990">arXiv:2404.00990</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2404.00990">pdf</a>, <a href="https://arxiv.org/ps/2404.00990">ps</a>, <a href="https://arxiv.org/format/2404.00990">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Exploring the Nexus of Large Language Models and <span class="search-hit mathjax">Legal</span> Systems: A Short Survey
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Qin%2C+W">Weicong Qin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+Z">Zhongxiang Sun</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2404.00990v1-abstract-short" style="display: inline;">
        With the advancement of Artificial Intelligence (<span class="search-hit mathjax">AI</span>) and Large Language Models (LLMs), there is a profound transformation occurring in the realm of natural language processing tasks within the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.00990v1-abstract-full').style.display = 'inline'; document.getElementById('2404.00990v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2404.00990v1-abstract-full" style="display: none;">
        With the advancement of Artificial Intelligence (<span class="search-hit mathjax">AI</span>) and Large Language Models (LLMs), there is a profound transformation occurring in the realm of natural language processing tasks within the <span class="search-hit mathjax">legal</span> domain. The capabilities of LLMs are increasingly demonstrating unique roles in the <span class="search-hit mathjax">legal</span> sector, bringing both distinctive benefits and various challenges. This survey delves into the synergy between LLMs and the <span class="search-hit mathjax">legal</span> system, such as their applications in tasks like <span class="search-hit mathjax">legal</span> text comprehension, case retrieval, and <span class="search-hit mathjax">analysis</span>. Furthermore, this survey highlights key challenges faced by LLMs in the <span class="search-hit mathjax">legal</span> domain, including bias, interpretability, and ethical considerations, as well as how researchers are addressing these issues. The survey showcases the latest advancements in fine-tuned <span class="search-hit mathjax">legal</span> LLMs tailored for various <span class="search-hit mathjax">legal</span> systems, along with <span class="search-hit mathjax">legal</span> datasets available for fine-tuning LLMs in various languages. Additionally, it proposes directions for future research and development.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.00990v1-abstract-full').style.display = 'none'; document.getElementById('2404.00990v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 April, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2403.15779">arXiv:2403.15779</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2403.15779">pdf</a>, <a href="https://arxiv.org/format/2403.15779">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Frontier of Data Erasure: Machine Unlearning for Large Language Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Qu%2C+Y">Youyang Qu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+M">Ming Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+N">Nan Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Thilakarathna%2C+K">Kanchana Thilakarathna</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+T">Tianqing Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Niyato%2C+D">Dusit Niyato</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2403.15779v1-abstract-short" style="display: inline;">
        Large Language Models (LLMs) are foundational to <span class="search-hit mathjax">AI</span> advancements, facilitating applications like predictive text generation. Nonetheless, they pose risks by potentially memorizing and disseminating sensitive, biased, or copyrighted information from their vast datasets. Machine unlearning emerges as a cutting-edge solution to mitigate these concerns, offering&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2403.15779v1-abstract-full').style.display = 'inline'; document.getElementById('2403.15779v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2403.15779v1-abstract-full" style="display: none;">
        Large Language Models (LLMs) are foundational to <span class="search-hit mathjax">AI</span> advancements, facilitating applications like predictive text generation. Nonetheless, they pose risks by potentially memorizing and disseminating sensitive, biased, or copyrighted information from their vast datasets. Machine unlearning emerges as a cutting-edge solution to mitigate these concerns, offering techniques for LLMs to selectively discard certain data. This paper reviews the latest in machine unlearning for LLMs, introducing methods for the targeted forgetting of information to address privacy, ethical, and <span class="search-hit mathjax">legal</span> challenges without necessitating full model retraining. It divides existing research into unlearning from unstructured/textual data and structured/classification data, showcasing the effectiveness of these approaches in removing specific data while maintaining model efficacy. Highlighting the practicality of machine unlearning, this <span class="search-hit mathjax">analysis</span> also points out the hurdles in preserving model integrity, avoiding excessive or insufficient data removal, and ensuring consistent outputs, underlining the role of machine unlearning in advancing responsible, ethical <span class="search-hit mathjax">AI</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2403.15779v1-abstract-full').style.display = 'none'; document.getElementById('2403.15779v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 March, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2402.05968">arXiv:2402.05968</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2402.05968">pdf</a>, <a href="https://arxiv.org/format/2402.05968">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Federated Learning Priorities Under the European Union Artificial Intelligence Act
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Woisetschl%C3%A4ger%2C+H">Herbert Woisetschläger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Erben%2C+A">Alexander Erben</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marino%2C+B">Bill Marino</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+S">Shiqiang Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lane%2C+N+D">Nicholas D. Lane</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mayer%2C+R">Ruben Mayer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jacobsen%2C+H">Hans-Arno Jacobsen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2402.05968v1-abstract-short" style="display: inline;">
        The age of <span class="search-hit mathjax">AI</span> regulation is upon us, with the European Union Artificial Intelligence Act (&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2402.05968v1-abstract-full').style.display = 'inline'; document.getElementById('2402.05968v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2402.05968v1-abstract-full" style="display: none;">
        The age of <span class="search-hit mathjax">AI</span> regulation is upon us, with the European Union Artificial Intelligence Act (<span class="search-hit mathjax">AI</span> Act) leading the way. Our key inquiry is how this will affect Federated Learning (FL), whose starting point of prioritizing data privacy while performing ML fundamentally differs from that of centralized learning. We believe the <span class="search-hit mathjax">AI</span> Act and future regulations could be the missing catalyst that pushes FL toward mainstream adoption. However, this can only occur if the FL community reprioritizes its research focus. In our position paper, we perform a first-of-its-kind interdisciplinary <span class="search-hit mathjax">analysis</span> (<span class="search-hit mathjax">legal</span> and ML) of the impact the <span class="search-hit mathjax">AI</span> Act may have on FL and make a series of observations supporting our primary position through quantitative and qualitative <span class="search-hit mathjax">analysis</span>. We explore data governance issues and the concern for privacy. We establish new challenges regarding performance and energy efficiency within lifecycle monitoring. Taken together, our <span class="search-hit mathjax">analysis</span> suggests there is a sizable opportunity for FL to become a crucial component of <span class="search-hit mathjax">AI</span> Act-compliant ML systems and for the new regulation to drive the adoption of FL techniques in general. Most noteworthy are the opportunities to defend against data bias and enhance private and secure computation
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2402.05968v1-abstract-full').style.display = 'none'; document.getElementById('2402.05968v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 February, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2024.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2; I.2.11; K.5
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2402.04140">arXiv:2402.04140</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2402.04140">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Advancing <span class="search-hit mathjax">Legal</span> Reasoning: The Integration of <span class="search-hit mathjax">AI</span> to Navigate Complexities and Biases in Global Jurisprudence with Semi-Automated Arbitration Processes (SAAPs)
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=De%27Shazer%2C+M">Michael De&#39;Shazer</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2402.04140v3-abstract-short" style="display: inline;">
        This study consists of a novel approach toward the <span class="search-hit mathjax">analysis</span> of court judgments spanning five countries, including the United States, the United Kingdom, Rwanda, Sweden and Hong Kong. This study also explores the intersection of the latest advancements in artificial intelligence (&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2402.04140v3-abstract-full').style.display = 'inline'; document.getElementById('2402.04140v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2402.04140v3-abstract-full" style="display: none;">
        This study consists of a novel approach toward the <span class="search-hit mathjax">analysis</span> of court judgments spanning five countries, including the United States, the United Kingdom, Rwanda, Sweden and Hong Kong. This study also explores the intersection of the latest advancements in artificial intelligence (<span class="search-hit mathjax">AI</span>) and <span class="search-hit mathjax">legal</span> <span class="search-hit mathjax">analysis</span>, emphasizing the role of <span class="search-hit mathjax">AI</span> (specifically generative <span class="search-hit mathjax">AI</span>) in identifying human biases and facilitating automated, valid, and coherent multisided argumentation of court judgments with the goal of ensuring consistent application of laws in and across various jurisdictions. By incorporating Advanced Language Models (ALMs) and a newly introduced human-<span class="search-hit mathjax">AI</span> collaborative framework, this paper seeks to analyze Grounded Theory-based research design with Advanced Language Models (ALMs) in the practice of law. SHIRLEY is the name of the <span class="search-hit mathjax">AI</span>-based application (built on top of OpenAI&#39;s GPT technology), focusing on detecting logical inconsistencies and biases across various <span class="search-hit mathjax">legal</span> decisions. SHIRLEY <span class="search-hit mathjax">analysis</span> is aggregated and is accompanied by a comparison-oriented <span class="search-hit mathjax">AI</span>-based application called SAM (also an ALM) to identify relative deviations in SHIRLEY bias detections. Further, a CRITIC is generated within semi-autonomous arbitration process via the ALM, SARA. A novel approach is introduced in the utilization of an <span class="search-hit mathjax">AI</span> arbitrator to critically evaluate biases and qualitative-in-nature nuances identified by the aforementioned <span class="search-hit mathjax">AI</span> applications (SAM in concert with SHIRLEY), based on the Hague Rules on Business and Human Rights Arbitration. This Semi-Automated Arbitration Process (SAAP) aims to uphold the integrity and fairness of <span class="search-hit mathjax">legal</span> judgments by ensuring a nuanced debate-resultant &#34;understanding&#34; through a hybrid system of <span class="search-hit mathjax">AI</span> and human-based collaborative <span class="search-hit mathjax">analysis</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2402.04140v3-abstract-full').style.display = 'none'; document.getElementById('2402.04140v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 February, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 6 February, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2402.03043">arXiv:2402.03043</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2402.03043">pdf</a>, <a href="https://arxiv.org/format/2402.03043">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        SIDU-TXT: An XAI Algorithm for NLP with a Holistic Assessment Approach
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Jahromi%2C+M+N+S">Mohammad N. S. Jahromi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Muddamsetty%2C+S+M">Satya. M. Muddamsetty</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jarlner%2C+A+S+S">Asta Sofie Stage Jarlner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=H%C3%B8genhaug%2C+A+M">Anna Murphy Høgenhaug</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gammeltoft-Hansen%2C+T">Thomas Gammeltoft-Hansen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moeslund%2C+T+B">Thomas B. Moeslund</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2402.03043v1-abstract-short" style="display: inline;">
        Explainable <span class="search-hit mathjax">AI</span> (XAI) aids in deciphering &#39;black-box&#39; models. While several methods have been proposed and evaluated primarily in the image domain, the exploration of explainability in the text domain remains a growing research area. In this paper, we delve into the applicability of XAI methods for the text domain. In this context, the &#39;Similarity&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2402.03043v1-abstract-full').style.display = 'inline'; document.getElementById('2402.03043v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2402.03043v1-abstract-full" style="display: none;">
        Explainable <span class="search-hit mathjax">AI</span> (XAI) aids in deciphering &#39;black-box&#39; models. While several methods have been proposed and evaluated primarily in the image domain, the exploration of explainability in the text domain remains a growing research area. In this paper, we delve into the applicability of XAI methods for the text domain. In this context, the &#39;Similarity Difference and Uniqueness&#39; (SIDU) XAI method, recognized for its superior capability in localizing entire salient regions in image-based classification is extended to textual data. The extended method, SIDU-TXT, utilizes feature activation maps from &#39;black-box&#39; models to generate heatmaps at a granular, word-based level, thereby providing explanations that highlight contextually significant textual elements crucial for model predictions. Given the absence of a unified standard for assessing XAI methods, this study applies a holistic three-tiered comprehensive evaluation framework: Functionally-Grounded, Human-Grounded and Application-Grounded, to assess the effectiveness of the proposed SIDU-TXT across various experiments. We find that, in sentiment <span class="search-hit mathjax">analysis</span> task of a movie review dataset, SIDU-TXT excels in both functionally and human-grounded evaluations, demonstrating superior performance through quantitative and qualitative analyses compared to benchmarks like Grad-CAM and LIME. In the application-grounded evaluation within the sensitive and complex <span class="search-hit mathjax">legal</span> domain of asylum decision-making, SIDU-TXT and Grad-CAM demonstrate comparable performances, each with its own set of strengths and weaknesses. However, both methods fall short of entirely fulfilling the sophisticated criteria of expert expectations, highlighting the imperative need for additional research in XAI methods suitable for such domains.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2402.03043v1-abstract-full').style.display = 'none'; document.getElementById('2402.03043v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 February, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Preprint submitted to Elsevier on Jan 5th, 2024</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2401.16212">arXiv:2401.16212</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2401.16212">pdf</a>, <a href="https://arxiv.org/format/2401.16212">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Better Call GPT, Comparing Large Language Models Against Lawyers
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Martin%2C+L">Lauren Martin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Whitehouse%2C+N">Nick Whitehouse</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yiu%2C+S">Stephanie Yiu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Catterson%2C+L">Lizzie Catterson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Perera%2C+R">Rivindu Perera</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2401.16212v1-abstract-short" style="display: inline;">
        This paper presents a groundbreaking comparison between Large Language Models and traditional <span class="search-hit mathjax">legal</span> contract reviewers, Junior Lawyers and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2401.16212v1-abstract-full').style.display = 'inline'; document.getElementById('2401.16212v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2401.16212v1-abstract-full" style="display: none;">
        This paper presents a groundbreaking comparison between Large Language Models and traditional <span class="search-hit mathjax">legal</span> contract reviewers, Junior Lawyers and <span class="search-hit mathjax">Legal</span> Process Outsourcers. We dissect whether LLMs can outperform humans in accuracy, speed, and cost efficiency during contract review. Our empirical <span class="search-hit mathjax">analysis</span> benchmarks LLMs against a ground truth set by Senior Lawyers, uncovering that advanced models match or exceed human accuracy in determining <span class="search-hit mathjax">legal</span> issues. In speed, LLMs complete reviews in mere seconds, eclipsing the hours required by their human counterparts. Cost wise, LLMs operate at a fraction of the price, offering a staggering 99.97 percent reduction in cost over traditional methods. These results are not just statistics, they signal a seismic shift in <span class="search-hit mathjax">legal</span> practice. LLMs stand poised to disrupt the <span class="search-hit mathjax">legal</span> industry, enhancing accessibility and efficiency of <span class="search-hit mathjax">legal</span> services. Our research asserts that the era of LLM dominance in <span class="search-hit mathjax">legal</span> contract review is upon us, challenging the status quo and calling for a reimagined future of <span class="search-hit mathjax">legal</span> workflows.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2401.16212v1-abstract-full').style.display = 'none'; document.getElementById('2401.16212v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 January, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">16 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2401.12324">arXiv:2401.12324</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2401.12324">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1016/j.neucom.2021.10.085">10.1016/j.neucom.2021.10.085 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Streamlining Advanced Taxi Assignment Strategies based on <span class="search-hit mathjax">Legal</span> <span class="search-hit mathjax">Analysis</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Billhardt%2C+H">Holger Billhardt</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Santos%2C+J">José-Antonio Santos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fern%C3%A1ndez%2C+A">Alberto Fernández</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moreno%2C+M">Mar Moreno</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ossowski%2C+S">Sascha Ossowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rodr%C3%ADguez%2C+J+A">José A. Rodríguez</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2401.12324v1-abstract-short" style="display: inline;">
        &hellip;in the domain of urban transportation, many researchers have put forward novel ideas, which are then implemented and evaluated through prototypes that usually draw upon <span class="search-hit mathjax">AI</span> methods and tools. However, such proposals also bring up multiple non-technical issues that need to be identified and addressed adequately if such systems are ever meant to be applied to t&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2401.12324v1-abstract-full').style.display = 'inline'; document.getElementById('2401.12324v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2401.12324v1-abstract-full" style="display: none;">
        In recent years many novel applications have appeared that promote the provision of services and activities in a collaborative manner. The key idea behind such systems is to take advantage of idle or underused capacities of existing resources, in order to provide improved services that assist people in their daily tasks, with additional functionality, enhanced efficiency, and/or reduced cost. Particularly in the domain of urban transportation, many researchers have put forward novel ideas, which are then implemented and evaluated through prototypes that usually draw upon <span class="search-hit mathjax">AI</span> methods and tools. However, such proposals also bring up multiple non-technical issues that need to be identified and addressed adequately if such systems are ever meant to be applied to the real world. While, in practice, <span class="search-hit mathjax">legal</span> and ethical aspects related to such <span class="search-hit mathjax">AI</span>-based systems are seldomly considered in the beginning of the research and development process, we argue that they not only restrict design decisions, but can also help guiding them. In this manuscript, we set out from a prototype of a taxi coordination service that mediates between individual (and autonomous) taxis and potential customers. After representing key aspects of its operation in a semi-structured manner, we analyse its viability from the viewpoint of current <span class="search-hit mathjax">legal</span> restrictions and constraints, so as to identify additional non-functional requirements as well as options to address them. Then, we go one step ahead, and actually modify the existing prototype to incorporate the previously identified recommendations. Performing experiments with this improved system helps us identify the most adequate option among several <span class="search-hit mathjax">legally</span> admissible alternatives.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2401.12324v1-abstract-full').style.display = 'none'; document.getElementById('2401.12324v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 January, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2024.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.1
        
      </p>
    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Neurocomputing, Volume 438 (2022)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2401.09459">arXiv:2401.09459</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2401.09459">pdf</a>, <a href="https://arxiv.org/format/2401.09459">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        What&#39;s my role? Modelling responsibility for <span class="search-hit mathjax">AI</span>-based safety-critical systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ryan%2C+P">Philippa Ryan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Porter%2C+Z">Zoe Porter</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Al-Qaddoumi%2C+J">Joanna Al-Qaddoumi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=McDermid%2C+J">John McDermid</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Habli%2C+I">Ibrahim Habli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2401.09459v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">AI</span>-Based Safety-Critical Systems (&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2401.09459v1-abstract-full').style.display = 'inline'; document.getElementById('2401.09459v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2401.09459v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">AI</span>-Based Safety-Critical Systems (<span class="search-hit mathjax">AI</span>-SCS) are being increasingly deployed in the real world. These can pose a risk of harm to people and the environment. Reducing that risk is an overarching priority during development and operation. As more <span class="search-hit mathjax">AI</span>-SCS become autonomous, a layer of risk management via human intervention has been removed. Following an accident it will be important to identify causal contributions and the different responsible actors behind those to learn from mistakes and prevent similar future events. Many authors have commented on the &#34;responsibility gap&#34; where it is difficult for developers and manufacturers to be held responsible for harmful behaviour of an <span class="search-hit mathjax">AI</span>-SCS. This is due to the complex development cycle for <span class="search-hit mathjax">AI</span>, uncertainty in <span class="search-hit mathjax">AI</span> performance, and dynamic operating environment. A human operator can become a &#34;liability sink&#34; absorbing blame for the consequences of <span class="search-hit mathjax">AI</span>-SCS outputs they weren&#39;t responsible for creating, and may not have understanding of.
  This cross-disciplinary paper considers different senses of responsibility (role, moral, <span class="search-hit mathjax">legal</span> and causal), and how they apply in the context of <span class="search-hit mathjax">AI</span>-SCS safety. We use a core concept (Actor(A) is responsible for Occurrence(O)) to create role responsibility models, producing a practical method to capture responsibility relationships and provide clarity on the previously identified responsibility issues. Our paper demonstrates the approach with two examples: a retrospective <span class="search-hit mathjax">analysis</span> of the Tempe Arizona fatal collision involving an autonomous vehicle, and a safety focused predictive role-responsibility <span class="search-hit mathjax">analysis</span> for an <span class="search-hit mathjax">AI</span>-based diabetes co-morbidity predictor. In both examples our primary focus is on safety, aiming to reduce unfair or disproportionate blame being placed on operators or developers. We present a discussion and avenues for future research.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2401.09459v1-abstract-full').style.display = 'none'; document.getElementById('2401.09459v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 December, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">22 pages, 7 figures, 2 tables</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.0; K.4.0
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2401.05273">arXiv:2401.05273</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2401.05273">pdf</a>, <a href="https://arxiv.org/format/2401.05273">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Pereira%2C+J">Jayr Pereira</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Assumpcao%2C+A">Andre Assumpcao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Trecenti%2C+J">Julio Trecenti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Airosa%2C+L">Luiz Airosa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lente%2C+C">Caio Lente</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cl%C3%A9to%2C+J">Jhonatan Cléto</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dobins%2C+G">Guilherme Dobins</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nogueira%2C+R">Rodrigo Nogueira</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mitchell%2C+L">Luis Mitchell</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lotufo%2C+R">Roberto Lotufo</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2401.05273v3-abstract-short" style="display: inline;">
        &hellip;designed to integrate Large Language Models (LLMs) into the operational framework of Brazilian Federal Court of Accounts (TCU). The system automates various stages of case <span class="search-hit mathjax">analysis</span>, including basic information extraction, admissibility examination, Periculum in mora and Fumus boni iuris analyses, and recommendations generation. Through a series of experiment&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2401.05273v3-abstract-full').style.display = 'inline'; document.getElementById('2401.05273v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2401.05273v3-abstract-full" style="display: none;">
        This paper introduces INACIA (Instrução Assistida com Inteligência Artificial), a groundbreaking system designed to integrate Large Language Models (LLMs) into the operational framework of Brazilian Federal Court of Accounts (TCU). The system automates various stages of case <span class="search-hit mathjax">analysis</span>, including basic information extraction, admissibility examination, Periculum in mora and Fumus boni iuris analyses, and recommendations generation. Through a series of experiments, we demonstrate INACIA&#39;s potential in extracting relevant information from case documents, evaluating its <span class="search-hit mathjax">legal</span> plausibility, and formulating propositions for judicial decision-making. Utilizing a validation dataset alongside LLMs, our evaluation methodology presents a novel approach to assessing system performance, correlating highly with human judgment. These results underscore INACIA&#39;s potential in complex <span class="search-hit mathjax">legal</span> task handling while also acknowledging the current limitations. This study discusses possible improvements and the broader implications of applying <span class="search-hit mathjax">AI</span> in <span class="search-hit mathjax">legal</span> contexts, suggesting that INACIA represents a significant step towards integrating <span class="search-hit mathjax">AI</span> in <span class="search-hit mathjax">legal</span> systems globally, albeit with cautious optimism grounded in the empirical findings.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2401.05273v3-abstract-full').style.display = 'none'; document.getElementById('2401.05273v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 February, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 10 January, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2401.04126">arXiv:2401.04126</a>
        <span>&nbsp;&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Concept of the Tactile Signature System for Individuals with Visual Impairments
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kremenchutskiy%2C+A">Anatoliy Kremenchutskiy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gabdreshov%2C+G">Galymzhan Gabdreshov</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2401.04126v2-abstract-short" style="display: inline;">
        &hellip;Through tactile interaction and voice algorithmic guidance, individuals create signatures reflecting their preferences and natural writing style. Real-time feedback: <span class="search-hit mathjax">AI</span>-powered voice prompts and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2401.04126v2-abstract-full').style.display = 'inline'; document.getElementById('2401.04126v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2401.04126v2-abstract-full" style="display: none;">
        The lack of an accessible and effective system for blind individuals to create handwritten signatures presents a significant barrier to their independence and full participation in various aspects of life. This research introduces the Tactile Signature System, a groundbreaking approach that empowers individuals with visual impairments to form their unique handwritten signatures. Key features of the system include: Personalized customization: Through tactile interaction and voice algorithmic guidance, individuals create signatures reflecting their preferences and natural writing style. Real-time feedback: <span class="search-hit mathjax">AI</span>-powered voice prompts and <span class="search-hit mathjax">analysis</span> ensure accuracy and consistency in signature formation. Accessibility: Installation in local service centers provides a secure and supervised environment for signature creation. The system&#39;s impact reaches beyond the individual level: Promotes inclusivity and independence: Blind individuals can engage in <span class="search-hit mathjax">legal</span> and financial transactions without relying on others. Empowers and fosters equal opportunities: Participation in education, employment, and civic engagement becomes more accessible. Aligns with international conventions: Upholds the right of persons with disabilities to participate fully in society. The Tactile Signature System represents a significant step towards an inclusive and accessible future for individuals with visual impairments.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2401.04126v2-abstract-full').style.display = 'none'; document.getElementById('2401.04126v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 January, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 5 January, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">The principles of connection between the interaction of a blind individual with the tactile field, when he uses touch, drawing various figures and forms, and the resulting prompts to the user to create a valid signature, have not been disclosed</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2401.02986">arXiv:2401.02986</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2401.02986">pdf</a>, <a href="https://arxiv.org/format/2401.02986">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Identification of Regulatory Requirements Relevant to Business Processes: A Comparative Study on Generative <span class="search-hit mathjax">AI</span>, Embedding-based Ranking, Crowd and Expert-driven Methods
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sai%2C+C">Catherine Sai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sadiq%2C+S">Shazia Sadiq</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Han%2C+L">Lei Han</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Demartini%2C+G">Gianluca Demartini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rinderle-Ma%2C+S">Stefanie Rinderle-Ma</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2401.02986v1-abstract-short" style="display: inline;">
        &hellip;Considering these contextual factors, as a first step, relevant documents (e.g., laws, regulations, directives, policies) are identified, followed by a more detailed <span class="search-hit mathjax">analysis</span> of which parts of the identified documents are relevant for which step of a given business process. Nowadays the identification of regulatory requirements relevant to business processe&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2401.02986v1-abstract-full').style.display = 'inline'; document.getElementById('2401.02986v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2401.02986v1-abstract-full" style="display: none;">
        Organizations face the challenge of ensuring compliance with an increasing amount of requirements from various regulatory documents. Which requirements are relevant depends on aspects such as the geographic location of the organization, its domain, size, and business processes. Considering these contextual factors, as a first step, relevant documents (e.g., laws, regulations, directives, policies) are identified, followed by a more detailed <span class="search-hit mathjax">analysis</span> of which parts of the identified documents are relevant for which step of a given business process. Nowadays the identification of regulatory requirements relevant to business processes is mostly done manually by domain and <span class="search-hit mathjax">legal</span> experts, posing a tremendous effort on them, especially for a large number of regulatory documents which might frequently change. Hence, this work examines how <span class="search-hit mathjax">legal</span> and domain experts can be assisted in the assessment of relevant requirements. For this, we compare an embedding-based NLP ranking method, a generative <span class="search-hit mathjax">AI</span> method using GPT-4, and a crowdsourced method with the purely manual method of creating relevancy labels by experts. The proposed methods are evaluated based on two case studies: an Australian insurance case created with domain experts and a global banking use case, adapted from SAP Signavio&#39;s workflow example of an international guideline. A gold standard is created for both BPMN2.0 processes and matched to real-world textual requirements from multiple regulatory documents. The evaluation and discussion provide insights into strengths and weaknesses of each method regarding applicability, automation, transparency, and reproducibility and provide guidelines on which method combinations will maximize benefits for given characteristics such as process usage, impact, and dynamics of an application scenario.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2401.02986v1-abstract-full').style.display = 'none'; document.getElementById('2401.02986v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 January, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2312.14628">arXiv:2312.14628</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2312.14628">pdf</a>, <a href="https://arxiv.org/format/2312.14628">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Holistic <span class="search-hit mathjax">analysis</span> on the sustainability of Federated Learning across <span class="search-hit mathjax">AI</span> product lifecycle
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cao%2C+H">Hongliu Cao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2312.14628v2-abstract-short" style="display: inline;">
        In light of emerging <span class="search-hit mathjax">legal</span> requirements and policies focused on privacy protection, there is a growing trend of companies across various industries adopting Federated Learning (FL). This decentralized approach involves multiple clients or silos, collaboratively training a global model under the coordination of a central server while utilizing their private l&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2312.14628v2-abstract-full').style.display = 'inline'; document.getElementById('2312.14628v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2312.14628v2-abstract-full" style="display: none;">
        In light of emerging <span class="search-hit mathjax">legal</span> requirements and policies focused on privacy protection, there is a growing trend of companies across various industries adopting Federated Learning (FL). This decentralized approach involves multiple clients or silos, collaboratively training a global model under the coordination of a central server while utilizing their private local data. Unlike traditional methods that necessitate data sharing and transmission, Cross-Silo FL allows clients to share model updates rather than raw data, thereby enhancing privacy. Despite its growing adoption, the carbon impact associated with Cross-Silo FL remains poorly understood due to the limited research in this area. This study seeks to bridge this gap by evaluating the sustainability of Cross-Silo FL throughout the entire <span class="search-hit mathjax">AI</span> product lifecycle, extending the <span class="search-hit mathjax">analysis</span> beyond the model training phase alone. We systematically compare this decentralized method with traditional centralized approaches and present a robust quantitative framework for assessing the costs and CO2 emissions in real-world Cross-Silo FL environments. Our findings indicate that the energy consumption and costs of model training are comparable between Cross-Silo Federated Learning and Centralized Learning. However, the additional data transfer and storage requirements inherent in Centralized Learning can result in significant, often overlooked CO2 emissions. Moreover, we introduce an innovative data and application management system that integrates Cross-Silo FL and analytics, aiming at improving the sustainability and economic efficiency of IT enterprises.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2312.14628v2-abstract-full').style.display = 'none'; document.getElementById('2312.14628v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 April, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 22 December, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Presented in Sophia Summit 2023</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2312.11711">arXiv:2312.11711</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2312.11711">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="General Economics">econ.GN</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Energy-saving technologies and energy efficiency in the post-pandemic world
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Strielkowski%2C+W">Wadim Strielkowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gorina%2C+L">Larisa Gorina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Korneeva%2C+E">Elena Korneeva</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kovaleva%2C+O">Olga Kovaleva</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2312.11711v2-abstract-short" style="display: inline;">
        &hellip;the importance of employing digital tools and technologies in energy networks and smart grids (e.g. Internet of Energy (IoE), peer-to-peer (P2P) prosumer networks, or the <span class="search-hit mathjax">AI</span>-powered autonomous power systems (APS)). In addition, the pandemic added novel&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2312.11711v2-abstract-full').style.display = 'inline'; document.getElementById('2312.11711v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2312.11711v2-abstract-full" style="display: none;">
        This paper explores the role of energy-saving technologies and energy efficiency in the post-COVID era. The pandemic meant major rethinking of the entrenched patterns in energy saving and efficiency. It also provided opportunities for reevaluating energy consumption for households and industries. In addition, it highlighted the importance of employing digital tools and technologies in energy networks and smart grids (e.g. Internet of Energy (IoE), peer-to-peer (P2P) prosumer networks, or the <span class="search-hit mathjax">AI</span>-powered autonomous power systems (APS)). In addition, the pandemic added novel <span class="search-hit mathjax">legal</span> aspects to the energy efficiency and energy saving and enhanced inter-national collaborations and partnerships. The paper highlights the importance of energy efficiency measures and examines various technologies that can contribute to a sustainable and resilient energy future. Using the bibliometric network <span class="search-hit mathjax">analysis</span> of 12960 publications indexed in Web of Science databases, it demonstrates the potential benefits and challenges associated with implementing energy-saving technologies and autonomic power systems in a post-COVID world. Our findings emphasize the need for robust policies, technological advancements, and public engagement to foster energy efficiency and mitigate the environmental impacts of energy consumption.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2312.11711v2-abstract-full').style.display = 'none'; document.getElementById('2312.11711v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 December, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 18 December, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">19 pages, 5 figures, 1 table</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2312.10077">arXiv:2312.10077</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2312.10077">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Digital Libraries">cs.DL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Artificial intelligence in social science: A study based on bibliometrics <span class="search-hit mathjax">analysis</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Prieto-Gutierrez%2C+J">Juan-Jose Prieto-Gutierrez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Segado-Boj%2C+F">Francisco Segado-Boj</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fran%C3%A7a%2C+F+D+S">Fabiana Da Silva França</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2312.10077v1-abstract-short" style="display: inline;">
        Artificial intelligence (<span class="search-hit mathjax">AI</span>) is gradually changing the planet. Data digitisation, computing infrastructure and machine learning are helping&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2312.10077v1-abstract-full').style.display = 'inline'; document.getElementById('2312.10077v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2312.10077v1-abstract-full" style="display: none;">
        Artificial intelligence (<span class="search-hit mathjax">AI</span>) is gradually changing the planet. Data digitisation, computing infrastructure and machine learning are helping <span class="search-hit mathjax">AI</span> tools to spread across all sectors of society. This article presents the results of a bibliometric <span class="search-hit mathjax">analysis</span> of <span class="search-hit mathjax">AI</span>-related publications in the social sciences over the last ten years (2013-2022). Most of the historical publications are taken into consideration with the aim of identifying research relevance and trends in this field. The results indicate that more than 19,408 articles have been published, 85% from 2008 to 2022, showing that research in this field is increasing significantly year on year. Clear domains or disciplines of research related to <span class="search-hit mathjax">AI</span> within the social sciences can be grouped into sub-areas such as law and <span class="search-hit mathjax">legal</span> reasoning, education, economics, and ethics. The United States is the country that publishes the most (20%), followed by China (13%). The influence of <span class="search-hit mathjax">AI</span> on society is inevitable and the advances can generate great opportunities for innovation and new jobs, but in the medium term it is necessary to adequately face this transition, setting regulations and reviewing the challenges of ethics and responsibility.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2312.10077v1-abstract-full').style.display = 'none'; document.getElementById('2312.10077v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 December, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2312.09699">arXiv:2312.09699</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2312.09699">pdf</a>, <a href="https://arxiv.org/format/2312.09699">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1609/aaai.v38i20.30245">10.1609/aaai.v38i20.30245 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Social, <span class="search-hit mathjax">Legal</span>, Ethical, Empathetic, and Cultural Rules: Compilation and Reasoning (Extended Version)
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Troquard%2C+N">Nicolas Troquard</a>, 
      
      <a href="/search/?searchtype=author&amp;query=De+Sanctis%2C+M">Martina De Sanctis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Inverardi%2C+P">Paola Inverardi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pelliccione%2C+P">Patrizio Pelliccione</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Scoccia%2C+G+L">Gian Luca Scoccia</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2312.09699v3-abstract-short" style="display: inline;">
        The rise of <span class="search-hit mathjax">AI</span>-based and autonomous systems is raising concerns and apprehension due to potential negative repercussions stemming from their behavior or decisions. These systems must be designed to comply with the human contexts in which they will operate. To this extent, Townsend et al. (2022) introduce the concept of SLEEC (social,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2312.09699v3-abstract-full').style.display = 'inline'; document.getElementById('2312.09699v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2312.09699v3-abstract-full" style="display: none;">
        The rise of <span class="search-hit mathjax">AI</span>-based and autonomous systems is raising concerns and apprehension due to potential negative repercussions stemming from their behavior or decisions. These systems must be designed to comply with the human contexts in which they will operate. To this extent, Townsend et al. (2022) introduce the concept of SLEEC (social, <span class="search-hit mathjax">legal</span>, ethical, empathetic, or cultural) rules that aim to facilitate the formulation, verification, and enforcement of the rules <span class="search-hit mathjax">AI</span>-based and autonomous systems should obey. They lay out a methodology to elicit them and to let philosophers, lawyers, domain experts, and others to formulate them in natural language. To enable their effective use in <span class="search-hit mathjax">AI</span> systems, it is necessary to translate these rules systematically into a formal language that supports automated reasoning. In this study, we first conduct a linguistic <span class="search-hit mathjax">analysis</span> of the SLEEC rules pattern, which justifies the translation of SLEEC rules into classical logic. Then we investigate the computational complexity of reasoning about SLEEC rules and show how logical programming frameworks can be employed to implement SLEEC rules in practical scenarios. The result is a readily applicable strategy for implementing <span class="search-hit mathjax">AI</span> systems that conform to norms expressed as SLEEC rules.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2312.09699v3-abstract-full').style.display = 'none'; document.getElementById('2312.09699v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 September, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 15 December, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">In proceedings of the 38th Annual AAAI Conference on Artificial Intelligence</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2311.14966">arXiv:2311.14966</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2311.14966">pdf</a>, <a href="https://arxiv.org/format/2311.14966">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Walking a Tightrope -- Evaluating Large Language Models in High-Risk Domains
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hung%2C+C">Chia-Chien Hung</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rim%2C+W+B">Wiem Ben Rim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Frost%2C+L">Lindsay Frost</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bruckner%2C+L">Lars Bruckner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lawrence%2C+C">Carolin Lawrence</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2311.14966v1-abstract-short" style="display: inline;">
        &hellip;the great success of large language models (LLMs), such as ChatGPT and its variants, their performance in high-risk domains remains unclear. Our study delves into an in-depth <span class="search-hit mathjax">analysis</span> of the performance of instruction-tuned LLMs, focusing on factual accuracy and safety adherence. To comprehensively assess the capabilities of LLMs, we conduct experiments on s&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.14966v1-abstract-full').style.display = 'inline'; document.getElementById('2311.14966v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2311.14966v1-abstract-full" style="display: none;">
        High-risk domains pose unique challenges that require language models to provide accurate and safe responses. Despite the great success of large language models (LLMs), such as ChatGPT and its variants, their performance in high-risk domains remains unclear. Our study delves into an in-depth <span class="search-hit mathjax">analysis</span> of the performance of instruction-tuned LLMs, focusing on factual accuracy and safety adherence. To comprehensively assess the capabilities of LLMs, we conduct experiments on six NLP datasets including question answering and summarization tasks within two high-risk domains: <span class="search-hit mathjax">legal</span> and medical. Further qualitative <span class="search-hit mathjax">analysis</span> highlights the existing limitations inherent in current LLMs when evaluating in high-risk domains. This underscores the essential nature of not only improving LLM capabilities but also prioritizing the refinement of domain-specific metrics, and embracing a more human-centric approach to enhance safety and factual reliability. Our findings advance the field toward the concerns of properly evaluating LLMs in high-risk domains, aiming to steer the adaptability of LLMs in fulfilling societal obligations and aligning with forthcoming regulations, such as the EU <span class="search-hit mathjax">AI</span> Act.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.14966v1-abstract-full').style.display = 'none'; document.getElementById('2311.14966v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 November, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">EMNLP 2023 Workshop on Benchmarking Generalisation in NLP (GenBench)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2311.13871">arXiv:2311.13871</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2311.13871">pdf</a>, <a href="https://arxiv.org/format/2311.13871">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Legal</span> Requirements <span class="search-hit mathjax">Analysis</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Abualhaija%2C+S">Sallam Abualhaija</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ceci%2C+M">Marcello Ceci</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briand%2C+L">Lionel Briand</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2311.13871v3-abstract-short" style="display: inline;">
        &hellip;software has been an integral part of everyday activities in many disciplines and application contexts. Introducing intelligent automation by leveraging artificial intelligence (<span class="search-hit mathjax">AI</span>) led to break-throughs in many fields. The effectiveness of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.13871v3-abstract-full').style.display = 'inline'; document.getElementById('2311.13871v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2311.13871v3-abstract-full" style="display: none;">
        Modern software has been an integral part of everyday activities in many disciplines and application contexts. Introducing intelligent automation by leveraging artificial intelligence (<span class="search-hit mathjax">AI</span>) led to break-throughs in many fields. The effectiveness of <span class="search-hit mathjax">AI</span> can be attributed to several factors, among which is the increasing availability of data. Regulations such as the general data protection regulation (GDPR) in the European Union (EU) are introduced to ensure the protection of personal data. Software systems that collect, process, or share personal data are subject to compliance with such regulations. Developing compliant software depends heavily on addressing <span class="search-hit mathjax">legal</span> requirements stipulated in applicable regulations, a central activity in the requirements engineering (RE) phase of the software development process. RE is concerned with specifying and maintaining requirements of a system-to-be, including <span class="search-hit mathjax">legal</span> requirements. <span class="search-hit mathjax">Legal</span> agreements which describe the policies organizations implement for processing personal data can provide an additional source to regulations for eliciting <span class="search-hit mathjax">legal</span> requirements. In this chapter, we explore a variety of methods for analyzing <span class="search-hit mathjax">legal</span> requirements and exemplify them on GDPR. Specifically, we describe possible alternatives for creating machine-analyzable representations from regulations, survey the existing automated means for enabling compliance verification against regulations, and further reflect on the current challenges of <span class="search-hit mathjax">legal</span> requirements <span class="search-hit mathjax">analysis</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.13871v3-abstract-full').style.display = 'none'; document.getElementById('2311.13871v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 February, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 23 November, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2311.09226">arXiv:2311.09226</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2311.09226">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Emerging Technologies">cs.ET</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The value creation potential of digital humans
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zirar%2C+A">Araz Zirar</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2311.09226v1-abstract-short" style="display: inline;">
        &#39;Digital humans&#39; are digital reproductions of humans powered by artificial intelligence (<span class="search-hit mathjax">AI</span>) and capable of communicating and forming emotional bonds. The value creation potential of digital humans is overlooked due to the limitations of digital human technologies. This article explores the value creation potential and the value realisation limitatio&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.09226v1-abstract-full').style.display = 'inline'; document.getElementById('2311.09226v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2311.09226v1-abstract-full" style="display: none;">
        &#39;Digital humans&#39; are digital reproductions of humans powered by artificial intelligence (<span class="search-hit mathjax">AI</span>) and capable of communicating and forming emotional bonds. The value creation potential of digital humans is overlooked due to the limitations of digital human technologies. This article explores the value creation potential and the value realisation limitations of digital humans. The <span class="search-hit mathjax">analysis</span> is based on a review of 62 articles retrieved from the Web of Science database. The <span class="search-hit mathjax">analysis</span> suggests that digital humans have the potential to alleviate labour and skill shortages, reduce the natural human element in high-risk tasks, avoid design errors, improve the ergonomics of products and workplaces, and provide guidance and emotional support, all of which will benefit natural humans in the workplace. However, technical limits, evolving understanding of digital humans, the social significance and acceptance of digital humans, ethical considerations, and the adjustment of <span class="search-hit mathjax">legal</span> tradition limit the value realisation. This review suggests that digital humans&#39; perceived usefulness and ease of development determine organisations&#39; willingness to utilise this technology. Overcoming the limitations, which still involve engineering challenges and a change in how they are perceived, will positively affect realising the value potential of digital humans in organisations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.09226v1-abstract-full').style.display = 'none'; document.getElementById('2311.09226v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 September, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">36 pages, 1 figure</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2310.20101">arXiv:2310.20101</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2310.20101">pdf</a>, <a href="https://arxiv.org/format/2310.20101">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Image and Video Processing">eess.IV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Medical Image Denosing via Explainable <span class="search-hit mathjax">AI</span> Feature Preserving Loss
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Dong%2C+G">Guanfang Dong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Basu%2C+A">Anup Basu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2310.20101v2-abstract-short" style="display: inline;">
        Denoising algorithms play a crucial role in medical image processing and <span class="search-hit mathjax">analysis</span>. However, classical denoising algorithms often ignore explanatory and critical medical features preservation, which may lead to misdiagnosis and <span class="search-hit mathjax">legal</span> liabilities. In this work, we propose a new denoising method for medical images that no&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2310.20101v2-abstract-full').style.display = 'inline'; document.getElementById('2310.20101v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2310.20101v2-abstract-full" style="display: none;">
        Denoising algorithms play a crucial role in medical image processing and <span class="search-hit mathjax">analysis</span>. However, classical denoising algorithms often ignore explanatory and critical medical features preservation, which may lead to misdiagnosis and <span class="search-hit mathjax">legal</span> liabilities. In this work, we propose a new denoising method for medical images that not only efficiently removes various types of noise, but also preserves key medical features throughout the process. To achieve this goal, we utilize a gradient-based eXplainable Artificial Intelligence (XAI) approach to design a feature preserving loss function. Our feature preserving loss function is motivated by the characteristic that gradient-based XAI is sensitive to noise. Through backpropagation, medical image features before and after denoising can be kept consistent. We conducted extensive experiments on three available medical image datasets, including synthesized 13 different types of noise and artifacts. The experimental results demonstrate the superiority of our method in terms of denoising performance, model explainability, and generalization.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2310.20101v2-abstract-full').style.display = 'none'; document.getElementById('2310.20101v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 November, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 30 October, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2310.16787">arXiv:2310.16787</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2310.16787">pdf</a>, <a href="https://arxiv.org/format/2310.16787">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Data Provenance Initiative: A Large Scale Audit of Dataset Licensing &amp; Attribution in <span class="search-hit mathjax">AI</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Longpre%2C+S">Shayne Longpre</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mahari%2C+R">Robert Mahari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+A">Anthony Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Obeng-Marnu%2C+N">Naana Obeng-Marnu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sileo%2C+D">Damien Sileo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Brannon%2C+W">William Brannon</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Muennighoff%2C+N">Niklas Muennighoff</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Khazam%2C+N">Nathan Khazam</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kabbara%2C+J">Jad Kabbara</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Perisetla%2C+K">Kartik Perisetla</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+X">Xinyi Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shippole%2C+E">Enrico Shippole</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bollacker%2C+K">Kurt Bollacker</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+T">Tongshuang Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Villa%2C+L">Luis Villa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pentland%2C+S">Sandy Pentland</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hooker%2C+S">Sara Hooker</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2310.16787v3-abstract-short" style="display: inline;">
        The race to train language models on vast, diverse, and inconsistently documented datasets has raised pressing concerns about the <span class="search-hit mathjax">legal</span> and ethical risks for practitioners. To remedy these practices threatening data transparency and understanding, we convene a multi-disciplinary effort between&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2310.16787v3-abstract-full').style.display = 'inline'; document.getElementById('2310.16787v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2310.16787v3-abstract-full" style="display: none;">
        The race to train language models on vast, diverse, and inconsistently documented datasets has raised pressing concerns about the <span class="search-hit mathjax">legal</span> and ethical risks for practitioners. To remedy these practices threatening data transparency and understanding, we convene a multi-disciplinary effort between <span class="search-hit mathjax">legal</span> and machine learning experts to systematically audit and trace 1800+ text datasets. We develop tools and standards to trace the lineage of these datasets, from their source, creators, series of license conditions, properties, and subsequent use. Our landscape <span class="search-hit mathjax">analysis</span> highlights the sharp divides in composition and focus of commercially open vs closed datasets, with closed datasets monopolizing important categories: lower resource languages, more creative tasks, richer topic variety, newer and more synthetic training data. This points to a deepening divide in the types of data that are made available under different license conditions, and heightened implications for jurisdictional <span class="search-hit mathjax">legal</span> interpretations of copyright and fair use. We also observe frequent miscategorization of licenses on widely used dataset hosting sites, with license omission of 70%+ and error rates of 50%+. This points to a crisis in misattribution and informed use of the most popular datasets driving many recent breakthroughs. As a contribution to ongoing improvements in dataset transparency and responsible use, we release our entire audit, with an interactive UI, the Data Provenance Explorer, which allows practitioners to trace and filter on data provenance for the most popular open source finetuning data collections: www.dataprovenance.org.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2310.16787v3-abstract-full').style.display = 'none'; document.getElementById('2310.16787v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 November, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 25 October, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">30 pages (18 main), 6 figures, 5 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2310.13192">arXiv:2310.13192</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2310.13192">pdf</a>, <a href="https://arxiv.org/format/2310.13192">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Opaque Law of Artificial Intelligence
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Calderonio%2C+V">Vincenzo Calderonio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2310.13192v3-abstract-short" style="display: inline;">
        &hellip;approach by which, applying the proposed conversational methodology of the Turing Test, we expect to evaluate the performance of one of the best existing NLP model of generative <span class="search-hit mathjax">AI</span> (Chat-GPT) to see how far it can go right now and how the shape of a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2310.13192v3-abstract-full').style.display = 'inline'; document.getElementById('2310.13192v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2310.13192v3-abstract-full" style="display: none;">
        The purpose of this paper is to analyse the opacity of algorithms, contextualized in the open debate on responsibility for artificial intelligence causation; with an experimental approach by which, applying the proposed conversational methodology of the Turing Test, we expect to evaluate the performance of one of the best existing NLP model of generative <span class="search-hit mathjax">AI</span> (Chat-GPT) to see how far it can go right now and how the shape of a <span class="search-hit mathjax">legal</span> regulation of it could be. The <span class="search-hit mathjax">analysis</span> of the problem will be supported by a comment of Italian classical law categories such as causality, intent and fault to understand the problem of the usage of <span class="search-hit mathjax">AI</span>, focusing in particular on the human-machine interaction. On the computer science side, for a technical point of view of the logic used to craft these algorithms, in the second chapter will be proposed a practical interrogation of Chat-GPT aimed at finding some critical points of the functioning of <span class="search-hit mathjax">AI</span>. The end of the paper will concentrate on some existing <span class="search-hit mathjax">legal</span> solutions which can be applied to the problem, plus a brief description of the approach proposed by EU Artificial Intelligence act.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2310.13192v3-abstract-full').style.display = 'none'; document.getElementById('2310.13192v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 January, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 19 October, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">17 pages, 7 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          F.0; I.2; J.4; K.4; K.5
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2310.04735">arXiv:2310.04735</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2310.04735">pdf</a>, <a href="https://arxiv.org/format/2310.04735">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Investigating the Influence of <span class="search-hit mathjax">Legal</span> Case Retrieval Systems on Users&#39; Decision Process
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+B">Beining Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+R">Ruizhe Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+Y">Yueyue Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ai%2C+Q">Qingyao Ai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+M">Min Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yiqun Liu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2310.04735v1-abstract-short" style="display: inline;">
        Given a specific query case, <span class="search-hit mathjax">legal</span> case retrieval systems aim to retrieve a set of case documents relevant to the case at hand. Previous studies on user behavior&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2310.04735v1-abstract-full').style.display = 'inline'; document.getElementById('2310.04735v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2310.04735v1-abstract-full" style="display: none;">
        Given a specific query case, <span class="search-hit mathjax">legal</span> case retrieval systems aim to retrieve a set of case documents relevant to the case at hand. Previous studies on user behavior <span class="search-hit mathjax">analysis</span> have shown that information retrieval (IR) systems can significantly influence users&#39; decisions by presenting results in varying orders and formats. However, whether such influence exists in <span class="search-hit mathjax">legal</span> case retrieval remains largely unknown. This study presents the first investigation into the influence of <span class="search-hit mathjax">legal</span> case retrieval systems on the decision-making process of <span class="search-hit mathjax">legal</span> users. We conducted an online user study involving more than ninety participants, and our findings suggest that the result distribution of <span class="search-hit mathjax">legal</span> case retrieval systems indeed affect users&#39; judgements on the sentences in cases. Notably, when users are presented with biased results that involve harsher sentences, they tend to impose harsher sentences on the current case as well. This research highlights the importance of optimizing the unbiasedness of <span class="search-hit mathjax">legal</span> case retrieval systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2310.04735v1-abstract-full').style.display = 'none'; document.getElementById('2310.04735v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 October, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2309.14213">arXiv:2309.14213</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2309.14213">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Autonomous Vehicles an overview on system, cyber security, risks, issues, and a way forward
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Islam%2C+M+A">Md Aminul Islam</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alqahtani%2C+S">Sarah Alqahtani</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2309.14213v1-abstract-short" style="display: inline;">
        &hellip;The initial phase of the discussion is elucidating the internal mechanics of these automobiles, encompassing the crucial involvement of sensors, artificial intelligence (<span class="search-hit mathjax">AI</span>) identification systems, control mechanisms, and their integration with cloud-based servers within the framework of the Internet of Things (IoT). It delves into practical implementations&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2309.14213v1-abstract-full').style.display = 'inline'; document.getElementById('2309.14213v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2309.14213v1-abstract-full" style="display: none;">
        This chapter explores the complex realm of autonomous cars, analyzing their fundamental components and operational characteristics. The initial phase of the discussion is elucidating the internal mechanics of these automobiles, encompassing the crucial involvement of sensors, artificial intelligence (<span class="search-hit mathjax">AI</span>) identification systems, control mechanisms, and their integration with cloud-based servers within the framework of the Internet of Things (IoT). It delves into practical implementations of autonomous cars, emphasizing their utilization in forecasting traffic patterns and transforming the dynamics of transportation. The text also explores the topic of Robotic Process Automation (RPA), illustrating the impact of autonomous cars on different businesses through the automation of tasks. The primary focus of this investigation lies in the realm of cybersecurity, specifically in the context of autonomous vehicles. A comprehensive <span class="search-hit mathjax">analysis</span> will be conducted to explore various risk management solutions aimed at protecting these vehicles from potential threats including ethical, environmental, <span class="search-hit mathjax">legal</span>, professional, and social dimensions, offering a comprehensive perspective on their societal implications. A strategic plan for addressing the challenges and proposing strategies for effectively traversing the complex terrain of autonomous car systems, cybersecurity, hazards, and other concerns are some resources for acquiring an understanding of the intricate realm of autonomous cars and their ramifications in contemporary society, supported by a comprehensive compilation of resources for additional investigation.
  Keywords: RPA, Cyber Security, AV, Risk, Smart Cars
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2309.14213v1-abstract-full').style.display = 'none'; document.getElementById('2309.14213v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 September, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2308.15906">arXiv:2308.15906</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2308.15906">pdf</a>, <a href="https://arxiv.org/format/2308.15906">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Is the U.S. <span class="search-hit mathjax">Legal</span> System Ready for <span class="search-hit mathjax">AI&#39;s</span> Challenges to Human Values?
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cheong%2C+I">Inyoung Cheong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Caliskan%2C+A">Aylin Caliskan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kohno%2C+T">Tadayoshi Kohno</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2308.15906v3-abstract-short" style="display: inline;">
        Our interdisciplinary study investigates how effectively U.S. laws confront the challenges posed by Generative <span class="search-hit mathjax">AI</span> to human values. Through an&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2308.15906v3-abstract-full').style.display = 'inline'; document.getElementById('2308.15906v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2308.15906v3-abstract-full" style="display: none;">
        Our interdisciplinary study investigates how effectively U.S. laws confront the challenges posed by Generative <span class="search-hit mathjax">AI</span> to human values. Through an <span class="search-hit mathjax">analysis</span> of diverse hypothetical scenarios crafted during an expert workshop, we have identified notable gaps and uncertainties within the existing <span class="search-hit mathjax">legal</span> framework regarding the protection of fundamental values, such as privacy, autonomy, dignity, diversity, equity, and physical/mental well-being. Constitutional and civil rights, it appears, may not provide sufficient protection against <span class="search-hit mathjax">AI</span>-generated discriminatory outputs. Furthermore, even if we exclude the liability shield provided by Section 230, proving causation for defamation and product liability claims is a challenging endeavor due to the intricate and opaque nature of <span class="search-hit mathjax">AI</span> systems. To address the unique and unforeseeable threats posed by Generative <span class="search-hit mathjax">AI</span>, we advocate for <span class="search-hit mathjax">legal</span> frameworks that evolve to recognize new threats and provide proactive, auditable guidelines to industry stakeholders. Addressing these issues requires deep interdisciplinary collaborations to identify harms, values, and mitigation strategies.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2308.15906v3-abstract-full').style.display = 'none'; document.getElementById('2308.15906v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 September, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 30 August, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">25 pages, 7 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2308.13228">arXiv:2308.13228</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2308.13228">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Meaningful XAI Based on User-Centric Design Methodology
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Maxwell%2C+W">Winston Maxwell</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dumas%2C+B">Bruno Dumas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2308.13228v1-abstract-short" style="display: inline;">
        This report first takes stock of XAI-related requirements appearing in various EU directives, regulations, guidelines, and CJEU case law. This <span class="search-hit mathjax">analysis</span> of existing requirements will permit us to have a clearer vision of the purposes, the ``why&#39;&#39;, of XAI, which we separate into five categories: contestability, empowerment/redressing information asymme&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2308.13228v1-abstract-full').style.display = 'inline'; document.getElementById('2308.13228v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2308.13228v1-abstract-full" style="display: none;">
        This report first takes stock of XAI-related requirements appearing in various EU directives, regulations, guidelines, and CJEU case law. This <span class="search-hit mathjax">analysis</span> of existing requirements will permit us to have a clearer vision of the purposes, the ``why&#39;&#39;, of XAI, which we separate into five categories: contestability, empowerment/redressing information asymmetries, control over system performance, evaluation of algorithmic decisions, and public administration transparency. The <span class="search-hit mathjax">analysis</span> of <span class="search-hit mathjax">legal</span> requirements also permits us to create four categories of recipients for explainability: data science teams; human operators of the system; persons affected by algorithmic decisions, and regulators/judges/auditors. Lastly, we identify four main operational contexts for explainability: XAI for the upstream design and testing phase; XAI for human-on-the-loop control; XAI for human-in-the-loop control; and XAI for ex-post challenges and investigations.Second, we will present user-centered design methodology, which takes the purposes, the recipients and the operational context into account in order to develop optimal XAI solutions.Third, we will suggest a methodology to permit suppliers and users of high-risk <span class="search-hit mathjax">AI</span> applications to propose local XAI solutions that are effective in the sense of being ``meaningful&#39;&#39;, for example, useful in light of the operational, safety and fundamental rights contexts. The process used to develop these ``meaningful&#39;&#39; XAI solutions will be based on user-centric design principles examined in the second part.Fourth, we will suggest that the European Commission issue guidelines to provide a harmonised approach to defining ``meaningful&#39;&#39; explanations based on the purposes, audiences and operational contexts of <span class="search-hit mathjax">AI</span> systems. These guidelines would apply to the <span class="search-hit mathjax">AI</span> Act, but also to the other EU texts requiring explanations for algorithmic systems and results.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2308.13228v1-abstract-full').style.display = 'none'; document.getElementById('2308.13228v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 August, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2307.13298">arXiv:2307.13298</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2307.13298">pdf</a>, <a href="https://arxiv.org/format/2307.13298">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An Intent Taxonomy of <span class="search-hit mathjax">Legal</span> Case Retrieval
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Shao%2C+Y">Yunqiu Shao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+H">Haitao Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+Y">Yueyue Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yiqun Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ai%2C+Q">Qingyao Ai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mao%2C+J">Jiaxin Mao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+Y">Yixiao Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+S">Shaoping Ma</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2307.13298v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Legal</span> case retrieval is a special Information Retrieval~(IR) task focusing on&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2307.13298v1-abstract-full').style.display = 'inline'; document.getElementById('2307.13298v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2307.13298v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Legal</span> case retrieval is a special Information Retrieval~(IR) task focusing on <span class="search-hit mathjax">legal</span> case documents. Depending on the downstream tasks of the retrieved case documents, users&#39; information needs in <span class="search-hit mathjax">legal</span> case retrieval could be significantly different from those in Web search and traditional ad-hoc retrieval tasks. While there are several studies that retrieve <span class="search-hit mathjax">legal</span> cases based on text similarity, the underlying search intents of <span class="search-hit mathjax">legal</span> retrieval users, as shown in this paper, are more complicated than that yet mostly unexplored. To this end, we present a novel hierarchical intent taxonomy of <span class="search-hit mathjax">legal</span> case retrieval. It consists of five intent types categorized by three criteria, i.e., search for Particular Case(s), Characterization, Penalty, Procedure, and Interest. The taxonomy was constructed transparently and evaluated extensively through interviews, editorial user studies, and query log <span class="search-hit mathjax">analysis</span>. Through a laboratory user study, we reveal significant differences in user behavior and satisfaction under different search intents in <span class="search-hit mathjax">legal</span> case retrieval. Furthermore, we apply the proposed taxonomy to various downstream <span class="search-hit mathjax">legal</span> retrieval tasks, e.g., result ranking and satisfaction prediction, and demonstrate its effectiveness. Our work provides important insights into the understanding of user intents in <span class="search-hit mathjax">legal</span> case retrieval and potentially leads to better retrieval techniques in the <span class="search-hit mathjax">legal</span> domain, such as intent-aware ranking strategies and evaluation methodologies.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2307.13298v1-abstract-full').style.display = 'none'; document.getElementById('2307.13298v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 July, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">28 pages, work in process</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2307.12218">arXiv:2307.12218</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2307.12218">pdf</a>, <a href="https://arxiv.org/format/2307.12218">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Comprehensive Review and Systematic <span class="search-hit mathjax">Analysis</span> of Artificial Intelligence Regulation Policies
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+W">Weiyue Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+S">Shaoshan Liu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2307.12218v1-abstract-short" style="display: inline;">
        Due to the cultural and governance differences of countries around the world, there currently exists a wide spectrum of <span class="search-hit mathjax">AI</span> regulation policy proposals that have created a chaos in the global&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2307.12218v1-abstract-full').style.display = 'inline'; document.getElementById('2307.12218v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2307.12218v1-abstract-full" style="display: none;">
        Due to the cultural and governance differences of countries around the world, there currently exists a wide spectrum of <span class="search-hit mathjax">AI</span> regulation policy proposals that have created a chaos in the global <span class="search-hit mathjax">AI</span> regulatory space. Properly regulating <span class="search-hit mathjax">AI</span> technologies is extremely challenging, as it requires a delicate balance between <span class="search-hit mathjax">legal</span> restrictions and technological developments. In this article, we first present a comprehensive review of <span class="search-hit mathjax">AI</span> regulation proposals from different geographical locations and cultural backgrounds. Then, drawing from historical lessons, we develop a framework to facilitate a thorough <span class="search-hit mathjax">analysis</span> of <span class="search-hit mathjax">AI</span> regulation proposals. Finally, we perform a systematic <span class="search-hit mathjax">analysis</span> of these <span class="search-hit mathjax">AI</span> regulation proposals to understand how each proposal may fail. This study, containing historical lessons and <span class="search-hit mathjax">analysis</span> methods, aims to help governing bodies untangling the <span class="search-hit mathjax">AI</span> regulatory chaos through a divide-and-conquer manner.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2307.12218v1-abstract-full').style.display = 'none'; document.getElementById('2307.12218v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 July, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2307.10200">arXiv:2307.10200</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2307.10200">pdf</a>, <a href="https://arxiv.org/format/2307.10200">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Disentangling Societal Inequality from Model Biases: Gender Inequality in Divorce Court Proceedings
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Dutta%2C+S">Sujan Dutta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Srivastava%2C+P">Parth Srivastava</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Solunke%2C+V">Vaishnavi Solunke</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nath%2C+S">Swaprava Nath</a>, 
      
      <a href="/search/?searchtype=author&amp;query=KhudaBukhsh%2C+A+R">Ashiqur R. KhudaBukhsh</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2307.10200v1-abstract-short" style="display: inline;">
        Divorce is the <span class="search-hit mathjax">legal</span> dissolution of a marriage by a court. Since this is usually an unpleasant outcome of a marital union, each party may have reasons to call the decision to quit which is generally documented in detail in the court proceedings. Via a substantial corpus of 17,306 court proceedings, this paper investigates gender inequality through the lens o&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2307.10200v1-abstract-full').style.display = 'inline'; document.getElementById('2307.10200v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2307.10200v1-abstract-full" style="display: none;">
        Divorce is the <span class="search-hit mathjax">legal</span> dissolution of a marriage by a court. Since this is usually an unpleasant outcome of a marital union, each party may have reasons to call the decision to quit which is generally documented in detail in the court proceedings. Via a substantial corpus of 17,306 court proceedings, this paper investigates gender inequality through the lens of divorce court proceedings. While emerging data sources (e.g., public court records) on sensitive societal issues hold promise in aiding social science research, biases present in cutting-edge natural language processing (NLP) methods may interfere with or affect such studies. We thus require a thorough <span class="search-hit mathjax">analysis</span> of potential gaps and limitations present in extant NLP resources. In this paper, on the methodological side, we demonstrate that existing NLP resources required several non-trivial modifications to quantify societal inequalities. On the substantive side, we find that while a large number of court cases perhaps suggest changing norms in India where women are increasingly challenging patriarchy, <span class="search-hit mathjax">AI</span>-powered analyses of these court proceedings indicate striking gender inequality with women often subjected to domestic violence.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2307.10200v1-abstract-full').style.display = 'none'; document.getElementById('2307.10200v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 July, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This paper is accepted at IJCAI 2023 (<span class="search-hit mathjax">AI</span> for good track)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2307.04028">arXiv:2307.04028</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2307.04028">pdf</a>, <a href="https://arxiv.org/format/2307.04028">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Measuring the Success of Diffusion Models at Imitating Human Artists
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Casper%2C+S">Stephen Casper</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guo%2C+Z">Zifan Guo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mogulothu%2C+S">Shreya Mogulothu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marinov%2C+Z">Zachary Marinov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Deshpande%2C+C">Chinmay Deshpande</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yew%2C+R">Rui-Jie Yew</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dai%2C+Z">Zheng Dai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hadfield-Menell%2C+D">Dylan Hadfield-Menell</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2307.04028v1-abstract-short" style="display: inline;">
        Modern diffusion models have set the state-of-the-art in <span class="search-hit mathjax">AI</span> image generation. Their success is due, in part, to training on Internet-scale data which often includes copyrighted work. This prompts questions about the extent to which these models learn from, imitate, or copy the work of human artists. This work suggests that tying copyright liability to the ca&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2307.04028v1-abstract-full').style.display = 'inline'; document.getElementById('2307.04028v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2307.04028v1-abstract-full" style="display: none;">
        Modern diffusion models have set the state-of-the-art in <span class="search-hit mathjax">AI</span> image generation. Their success is due, in part, to training on Internet-scale data which often includes copyrighted work. This prompts questions about the extent to which these models learn from, imitate, or copy the work of human artists. This work suggests that tying copyright liability to the capabilities of the model may be useful given the evolving ecosystem of generative models. Specifically, much of the <span class="search-hit mathjax">legal</span> <span class="search-hit mathjax">analysis</span> of copyright and generative systems focuses on the use of protected data for training. As a result, the connections between data, training, and the system are often obscured. In our approach, we consider simple image classification techniques to measure a model&#39;s ability to imitate specific artists. Specifically, we use Contrastive Language-Image Pretrained (CLIP) encoders to classify images in a zero-shot fashion. Our process first prompts a model to imitate a specific artist. Then, we test whether CLIP can be used to reclassify the artist (or the artist&#39;s work) from the imitation. If these tests match the imitation back to the original artist, this suggests the model can imitate that artist&#39;s expression. Our approach is simple and quantitative. Furthermore, it uses standard techniques and does not require additional training. We demonstrate our approach with an audit of Stable Diffusion&#39;s capacity to imitate 70 professional digital artists with copyrighted work online. When Stable Diffusion is prompted to imitate an artist from this set, we find that the artist can be identified from the imitation with an average accuracy of 81.0%. Finally, we also show that a sample of the artist&#39;s work can be matched to these imitation images with a high degree of statistical reliability. Overall, these results suggest that Stable Diffusion is broadly successful at imitating individual human artists.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2307.04028v1-abstract-full').style.display = 'none'; document.getElementById('2307.04028v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 July, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to the 1 st Workshop on Generative <span class="search-hit mathjax">AI</span> and Law</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2306.14062">arXiv:2306.14062</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2306.14062">pdf</a>, <a href="https://arxiv.org/format/2306.14062">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On the Uses of Large Language Models to Interpret Ambiguous Cyberattack Descriptions
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Fayyazi%2C+R">Reza Fayyazi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+S+J">Shanchieh Jay Yang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2306.14062v2-abstract-short" style="display: inline;">
        The volume, variety, and velocity of change in vulnerabilities and exploits have made incident threat <span class="search-hit mathjax">analysis</span> challenging with human expertise and experience along. Tactics, Techniques, and Procedures (TTPs) are to describe how and why attackers exploit vulnerabilities. However, a TTP description written by one security professional can be interpreted very&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.14062v2-abstract-full').style.display = 'inline'; document.getElementById('2306.14062v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2306.14062v2-abstract-full" style="display: none;">
        The volume, variety, and velocity of change in vulnerabilities and exploits have made incident threat <span class="search-hit mathjax">analysis</span> challenging with human expertise and experience along. Tactics, Techniques, and Procedures (TTPs) are to describe how and why attackers exploit vulnerabilities. However, a TTP description written by one security professional can be interpreted very differently by another, leading to confusion in cybersecurity operations or even business, policy, and <span class="search-hit mathjax">legal</span> decisions. Meanwhile, advancements in <span class="search-hit mathjax">AI</span> have led to the increasing use of Natural Language Processing (NLP) algorithms to assist the various tasks in cyber operations. With the rise of Large Language Models (LLMs), NLP tasks have significantly improved because of the LLM&#39;s semantic understanding and scalability. This leads us to question how well LLMs can interpret TTPs or general cyberattack descriptions to inform analysts of the intended purposes of cyberattacks. We propose to analyze and compare the direct use of LLMs (e.g., GPT-3.5) versus supervised fine-tuning (SFT) of small-scale-LLMs (e.g., BERT) to study their capabilities in predicting ATT&amp;CK tactics. Our results reveal that the small-scale-LLMs with SFT provide a more focused and clearer differentiation between the ATT&amp;CK tactics (if such differentiation exists). On the other hand, direct use of LLMs offer a broader interpretation of cyberattack techniques. When treating more general cases, despite the power of LLMs, inherent ambiguity exists and limits their predictive power. We then summarize the challenges and recommend research directions on LLMs to treat the inherent ambiguity of TTP descriptions used in various cyber operations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.14062v2-abstract-full').style.display = 'none'; document.getElementById('2306.14062v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 August, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 24 June, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2306.10069">arXiv:2306.10069</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2306.10069">pdf</a>, <a href="https://arxiv.org/format/2306.10069">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The pop song generator: designing an online course to teach collaborative, creative <span class="search-hit mathjax">AI</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yee-king%2C+M">Matthew Yee-king</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fiorucci%2C+A">Andrea Fiorucci</a>, 
      
      <a href="/search/?searchtype=author&amp;query=d%27Inverno%2C+M">Mark d&#39;Inverno</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2306.10069v1-abstract-short" style="display: inline;">
        This article describes and evaluates a new online <span class="search-hit mathjax">AI</span>-creativity course. The course is based around three near-state-of-the-art&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.10069v1-abstract-full').style.display = 'inline'; document.getElementById('2306.10069v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2306.10069v1-abstract-full" style="display: none;">
        This article describes and evaluates a new online <span class="search-hit mathjax">AI</span>-creativity course. The course is based around three near-state-of-the-art <span class="search-hit mathjax">AI</span> models combined into a pop song generating system. A fine-tuned GPT-2 model writes lyrics, Music-VAE composes musical scores and instrumentation and Diffsinger synthesises a singing voice. We explain the decisions made in designing the course which is based on Piagetian, constructivist &#39;learning-by-doing&#39;. We present details of the five-week course design with learning objectives, technical concepts, and creative and technical activities. We explain how we overcame technical challenges to build a complete pop song generator system, consisting of Python scripts, pre-trained models, and Javascript code that runs in a dockerised Linux container via a web-based IDE. A quantitative <span class="search-hit mathjax">analysis</span> of student activity provides evidence on engagement and a benchmark for future improvements. A qualitative <span class="search-hit mathjax">analysis</span> of a workshop with experts validated the overall course design, it suggested the need for a stronger creative brief and ethical and <span class="search-hit mathjax">legal</span> content.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.10069v1-abstract-full').style.display = 'none'; document.getElementById('2306.10069v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 June, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2023.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68T01
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          K.3; J.5; I.2
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2306.08394">arXiv:2306.08394</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2306.08394">pdf</a>, <a href="https://arxiv.org/format/2306.08394">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Compatibility of Fairness Metrics with EU Non-Discrimination Laws: Demographic Parity &amp; Conditional Demographic Disparity
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Koumeri%2C+L+K">Lisa Koutsoviti Koumeri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Legast%2C+M">Magali Legast</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yousefi%2C+Y">Yasaman Yousefi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vanhoof%2C+K">Koen Vanhoof</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Legay%2C+A">Axel Legay</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schommer%2C+C">Christoph Schommer</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2306.08394v1-abstract-short" style="display: inline;">
        Empirical evidence suggests that algorithmic decisions driven by Machine Learning (ML) techniques threaten to discriminate against <span class="search-hit mathjax">legally</span> protected groups or create new sources of unfairness. This work supports the contextual approach to fairness in EU non-discrimination&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.08394v1-abstract-full').style.display = 'inline'; document.getElementById('2306.08394v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2306.08394v1-abstract-full" style="display: none;">
        Empirical evidence suggests that algorithmic decisions driven by Machine Learning (ML) techniques threaten to discriminate against <span class="search-hit mathjax">legally</span> protected groups or create new sources of unfairness. This work supports the contextual approach to fairness in EU non-discrimination <span class="search-hit mathjax">legal</span> framework and aims at assessing up to what point we can assure <span class="search-hit mathjax">legal</span> fairness through fairness metrics and under fairness constraints. For that, we analyze the <span class="search-hit mathjax">legal</span> notion of non-discrimination and differential treatment with the fairness definition Demographic Parity (DP) through Conditional Demographic Disparity (CDD). We train and compare different classifiers with fairness constraints to assess whether it is possible to reduce bias in the prediction while enabling the contextual approach to judicial interpretation practiced under EU non-discrimination laws. Our experimental results on three scenarios show that the in-processing bias mitigation algorithm leads to different performances in each of them. Our experiments and <span class="search-hit mathjax">analysis</span> suggest that <span class="search-hit mathjax">AI</span>-assisted decision-making can be fair from a <span class="search-hit mathjax">legal</span> perspective depending on the case at hand and the <span class="search-hit mathjax">legal</span> justification. These preliminary results encourage future work which will involve further case studies, metrics, and fairness notions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.08394v1-abstract-full').style.display = 'none'; document.getElementById('2306.08394v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 June, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted at the 19th International Conference on Artificial Intelligence and Law - ICAIL 2023. Expected decision date is July 18, 2023</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2306.07075">arXiv:2306.07075</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2306.07075">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Large Language Models as Tax Attorneys: A Case Study in <span class="search-hit mathjax">Legal</span> Capabilities Emergence
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Nay%2C+J+J">John J. Nay</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Karamardian%2C+D">David Karamardian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lawsky%2C+S+B">Sarah B. Lawsky</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tao%2C+W">Wenting Tao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bhat%2C+M">Meghana Bhat</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jain%2C+R">Raghav Jain</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lee%2C+A+T">Aaron Travis Lee</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Choi%2C+J+H">Jonathan H. Choi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kasai%2C+J">Jungo Kasai</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2306.07075v1-abstract-short" style="display: inline;">
        Better understanding of Large Language Models&#39; (LLMs) <span class="search-hit mathjax">legal</span>&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.07075v1-abstract-full').style.display = 'inline'; document.getElementById('2306.07075v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2306.07075v1-abstract-full" style="display: none;">
        Better understanding of Large Language Models&#39; (LLMs) <span class="search-hit mathjax">legal</span> <span class="search-hit mathjax">analysis</span> abilities can contribute to improving the efficiency of <span class="search-hit mathjax">legal</span> services, governing artificial intelligence, and leveraging LLMs to identify inconsistencies in law. This paper explores LLM capabilities in applying tax law. We choose this area of law because it has a structure that allows us to set up automated validation pipelines across thousands of examples, requires logical reasoning and maths skills, and enables us to test LLM capabilities in a manner relevant to real-world economic lives of citizens and companies. Our experiments demonstrate emerging <span class="search-hit mathjax">legal</span> understanding capabilities, with improved performance in each subsequent OpenAI model release. We experiment with retrieving and utilising the relevant <span class="search-hit mathjax">legal</span> authority to assess the impact of providing additional <span class="search-hit mathjax">legal</span> context to LLMs. Few-shot prompting, presenting examples of question-answer pairs, is also found to significantly enhance the performance of the most advanced model, GPT-4. The findings indicate that LLMs, particularly when combined with prompting enhancements and the correct <span class="search-hit mathjax">legal</span> texts, can perform at high levels of accuracy but not yet at expert tax lawyer levels. As LLMs continue to advance, their ability to reason about law autonomously could have significant implications for the <span class="search-hit mathjax">legal</span> profession and <span class="search-hit mathjax">AI</span> governance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.07075v1-abstract-full').style.display = 'none'; document.getElementById('2306.07075v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 June, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2306.06699">arXiv:2306.06699</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2306.06699">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Other Quantitative Biology">q-bio.OT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Adapting to the Impact of <span class="search-hit mathjax">AI</span> in Scientific Writing: Balancing Benefits and Drawbacks while Developing Policies and Regulations
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=BaHammam%2C+A+S">Ahmed S. BaHammam</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Trabelsi%2C+K">Khaled Trabelsi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pandi-Perumal%2C+S+R">Seithikurippu R. Pandi-Perumal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jahrami%2C+H">Hiatham Jahrami</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2306.06699v1-abstract-short" style="display: inline;">
        This article examines the advantages and disadvantages of Large Language Models (LLMs) and Artificial Intelligence (<span class="search-hit mathjax">AI</span>) in research and education and proposes the urgent need for an international statement to guide their responsible use. LLMs and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.06699v1-abstract-full').style.display = 'inline'; document.getElementById('2306.06699v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2306.06699v1-abstract-full" style="display: none;">
        This article examines the advantages and disadvantages of Large Language Models (LLMs) and Artificial Intelligence (<span class="search-hit mathjax">AI</span>) in research and education and proposes the urgent need for an international statement to guide their responsible use. LLMs and <span class="search-hit mathjax">AI</span> demonstrate remarkable natural language processing, data <span class="search-hit mathjax">analysis</span>, and decision-making capabilities, offering potential benefits such as improved efficiency and transformative solutions. However, concerns regarding ethical considerations, bias, fake publications, and malicious use also arise. The objectives of this paper are to critically evaluate the utility of LLMs and <span class="search-hit mathjax">AI</span> in research and education, call for discussions between stakeholders, and discuss the need for an international statement. We identify advantages such as data processing, task automation, and personalized experiences, alongside disadvantages like bias reinforcement, interpretability challenges, inaccurate reporting, and plagiarism. Stakeholders from academia, industry, government, and civil society must engage in open discussions to address the ethical, <span class="search-hit mathjax">legal</span>, and societal implications. The proposed international statement should emphasize transparency, accountability, ongoing research, and risk mitigation. Monitoring, evaluation, user education, and awareness are essential components. By fostering discussions and establishing guidelines, we can ensure the responsible and ethical development and use of LLMs and <span class="search-hit mathjax">AI</span>, maximizing benefits while minimizing risks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.06699v1-abstract-full').style.display = 'none'; document.getElementById('2306.06699v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 June, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">2 Figure, (in press)</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Journal of Nature and Science of Medicine 2023, Volume 6, Issue 3
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2306.00007">arXiv:2306.00007</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2306.00007">pdf</a>, <a href="https://arxiv.org/format/2306.00007">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Datasets for Portuguese <span class="search-hit mathjax">Legal</span> Semantic Textual Similarity: Comparing weak supervision and an annotation process approaches
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Junior%2C+D+d+S">Daniel da Silva Junior</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Corval%2C+P+R+d+S">Paulo Roberto dos S. Corval</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Paes%2C+A">Aline Paes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=de+Oliveira%2C+D">Daniel de Oliveira</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2306.00007v1-abstract-short" style="display: inline;">
        The Brazilian judiciary has a large workload, resulting in a long time to finish <span class="search-hit mathjax">legal</span> proceedings. Brazilian National Council of Justice has established in Resolution 469/2022 formal guidance for document and process digitalization opening up the possibility of using automatic techniques to help with everyday tasks in the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.00007v1-abstract-full').style.display = 'inline'; document.getElementById('2306.00007v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2306.00007v1-abstract-full" style="display: none;">
        The Brazilian judiciary has a large workload, resulting in a long time to finish <span class="search-hit mathjax">legal</span> proceedings. Brazilian National Council of Justice has established in Resolution 469/2022 formal guidance for document and process digitalization opening up the possibility of using automatic techniques to help with everyday tasks in the <span class="search-hit mathjax">legal</span> field, particularly in a large number of texts yielded on the routine of law procedures. Notably, Artificial Intelligence (<span class="search-hit mathjax">AI</span>) techniques allow for processing and extracting useful information from textual data, potentially speeding up the process. However, datasets from the <span class="search-hit mathjax">legal</span> domain required by several <span class="search-hit mathjax">AI</span> techniques are scarce and difficult to obtain as they need labels from experts. To address this challenge, this article contributes with four datasets from the <span class="search-hit mathjax">legal</span> domain, two with documents and metadata but unlabeled, and another two labeled with a heuristic aiming at its use in textual semantic similarity tasks. Also, to evaluate the effectiveness of the proposed heuristic label process, this article presents a small ground truth dataset generated from domain expert annotations. The <span class="search-hit mathjax">analysis</span> of ground truth labels highlights that semantic <span class="search-hit mathjax">analysis</span> of domain text can be challenging even for domain experts. Also, the comparison between ground truth and heuristic labels shows that heuristic labels are useful.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.00007v1-abstract-full').style.display = 'none'; document.getElementById('2306.00007v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 May, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2305.18615">arXiv:2305.18615</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2305.18615">pdf</a>, <a href="https://arxiv.org/format/2305.18615">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3593013.3594002">10.1145/3593013.3594002 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Stronger Together: on the Articulation of Ethical Charters, <span class="search-hit mathjax">Legal</span> Tools, and Technical Documentation in ML
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Pistilli%2C+G">Giada Pistilli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ferrandis%2C+C+M">Carlos Munoz Ferrandis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jernite%2C+Y">Yacine Jernite</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mitchell%2C+M">Margaret Mitchell</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2305.18615v1-abstract-short" style="display: inline;">
        The growing need for accountability of the people behind <span class="search-hit mathjax">AI</span> systems can be addressed by leveraging processes in three fields of study: ethics, law, and computer science. While these fields are often considered in isolation, they rely on complementary notions in their interpretation and implementation. In this work, we detail this interdependence and motivate&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2305.18615v1-abstract-full').style.display = 'inline'; document.getElementById('2305.18615v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2305.18615v1-abstract-full" style="display: none;">
        The growing need for accountability of the people behind <span class="search-hit mathjax">AI</span> systems can be addressed by leveraging processes in three fields of study: ethics, law, and computer science. While these fields are often considered in isolation, they rely on complementary notions in their interpretation and implementation. In this work, we detail this interdependence and motivate the necessary role of collaborative governance tools in shaping a positive evolution of <span class="search-hit mathjax">AI</span>. We first contrast notions of compliance in the ethical, <span class="search-hit mathjax">legal</span>, and technical fields; we outline both their differences and where they complement each other, with a particular focus on the roles of ethical charters, licenses, and technical documentation in these interactions. We then focus on the role of values in articulating the synergies between the fields and outline specific mechanisms of interaction between them in practice. We identify how these mechanisms have played out in several open governance fora: an open collaborative workshop, a responsible licensing initiative, and a proposed regulatory framework. By leveraging complementary notions of compliance in these three domains, we can create a more comprehensive framework for governing <span class="search-hit mathjax">AI</span> systems that jointly takes into account their technical capabilities, their impact on society, and how technical specifications can inform relevant regulations. Our <span class="search-hit mathjax">analysis</span> thus underlines the necessity of joint consideration of the ethical, <span class="search-hit mathjax">legal</span>, and technical in <span class="search-hit mathjax">AI</span> ethics frameworks to be used on a larger scale to govern <span class="search-hit mathjax">AI</span> systems and how the thinking in each of these areas can inform the others.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2305.18615v1-abstract-full').style.display = 'none'; document.getElementById('2305.18615v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 May, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2305.12747">arXiv:2305.12747</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2305.12747">pdf</a>, <a href="https://arxiv.org/format/2305.12747">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The &#34;code&#39;&#39; of Ethics:A Holistic Audit of <span class="search-hit mathjax">AI</span> Code Generators
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+W">Wanlun Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Song%2C+Y">Yiliao Song</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xue%2C+M">Minhui Xue</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wen%2C+S">Sheng Wen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiang%2C+Y">Yang Xiang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2305.12747v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">AI</span>-powered programming language generation (PLG) models have gained increasing attention due to their ability to generate source code of programs in a few seconds with a plain program description. Despite their remarkable performance, many concerns are raised over the potential risks of their development and deployment, such as&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2305.12747v1-abstract-full').style.display = 'inline'; document.getElementById('2305.12747v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2305.12747v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">AI</span>-powered programming language generation (PLG) models have gained increasing attention due to their ability to generate source code of programs in a few seconds with a plain program description. Despite their remarkable performance, many concerns are raised over the potential risks of their development and deployment, such as <span class="search-hit mathjax">legal</span> issues of copyright infringement induced by training usage of licensed code, and malicious consequences due to the unregulated use of these models. In this paper, we present the first-of-its-kind study to systematically investigate the accountability of PLG models from the perspectives of both model development and deployment. In particular, we develop a holistic framework not only to audit the training data usage of PLG models, but also to identify neural code generated by PLG models as well as determine its attribution to a source model. To this end, we propose using membership inference to audit whether a code snippet used is in the PLG model&#39;s training data. In addition, we propose a learning-based method to distinguish between human-written code and neural code. In neural code attribution, through both empirical and theoretical <span class="search-hit mathjax">analysis</span>, we show that it is impossible to reliably attribute the generation of one code snippet to one model. We then propose two feasible alternative methods: one is to attribute one neural code snippet to one of the candidate PLG models, and the other is to verify whether a set of neural code snippets can be attributed to a given PLG model. The proposed framework thoroughly examines the accountability of PLG models which are verified by extensive experiments. The implementations of our proposed framework are also encapsulated into a new artifact, named CodeForensic, to foster further research.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2305.12747v1-abstract-full').style.display = 'none'; document.getElementById('2305.12747v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 May, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2304.13680">arXiv:2304.13680</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2304.13680">pdf</a>, <a href="https://arxiv.org/format/2304.13680">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Measuring Bias in <span class="search-hit mathjax">AI</span> Models: An Statistical Approach Introducing N-Sigma
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=DeAlcala%2C+D">Daniel DeAlcala</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Serna%2C+I">Ignacio Serna</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Morales%2C+A">Aythami Morales</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fierrez%2C+J">Julian Fierrez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ortega-Garcia%2C+J">Javier Ortega-Garcia</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2304.13680v2-abstract-short" style="display: inline;">
        The new regulatory framework proposal on Artificial Intelligence (<span class="search-hit mathjax">AI</span>) published by the European Commission establishes a new risk-based&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2304.13680v2-abstract-full').style.display = 'inline'; document.getElementById('2304.13680v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2304.13680v2-abstract-full" style="display: none;">
        The new regulatory framework proposal on Artificial Intelligence (<span class="search-hit mathjax">AI</span>) published by the European Commission establishes a new risk-based <span class="search-hit mathjax">legal</span> approach. The proposal highlights the need to develop adequate risk assessments for the different uses of <span class="search-hit mathjax">AI</span>. This risk assessment should address, among others, the detection and mitigation of bias in <span class="search-hit mathjax">AI</span>. In this work we analyze statistical approaches to measure biases in automatic decision-making systems. We focus our experiments in face recognition technologies. We propose a novel way to measure the biases in machine learning models using a statistical approach based on the N-Sigma method. N-Sigma is a popular statistical approach used to validate hypotheses in general science such as physics and social areas and its application to machine learning is yet unexplored. In this work we study how to apply this methodology to develop new risk assessment frameworks based on bias <span class="search-hit mathjax">analysis</span> and we discuss the main advantages and drawbacks with respect to other popular statistical tests.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2304.13680v2-abstract-full').style.display = 'none'; document.getElementById('2304.13680v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 May, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 26 April, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">6 pages Paper accepted in IEEE Conf. on Computers, Software, and Applications (COMPSAC), 2023</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2303.08721">arXiv:2303.08721</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2303.08721">pdf</a>, <a href="https://arxiv.org/format/2303.08721">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Artificial Influence: An <span class="search-hit mathjax">Analysis</span> Of <span class="search-hit mathjax">AI</span>-Driven Persuasion
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Burtell%2C+M">Matthew Burtell</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Woodside%2C+T">Thomas Woodside</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2303.08721v1-abstract-short" style="display: inline;">
        Persuasion is a key aspect of what it means to be human, and is central to business, politics, and other endeavors. Advancements in artificial intelligence (<span class="search-hit mathjax">AI</span>) have produced&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2303.08721v1-abstract-full').style.display = 'inline'; document.getElementById('2303.08721v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2303.08721v1-abstract-full" style="display: none;">
        Persuasion is a key aspect of what it means to be human, and is central to business, politics, and other endeavors. Advancements in artificial intelligence (<span class="search-hit mathjax">AI</span>) have produced <span class="search-hit mathjax">AI</span> systems that are capable of persuading humans to buy products, watch videos, click on search results, and more. Even systems that are not explicitly designed to persuade may do so in practice. In the future, increasingly anthropomorphic <span class="search-hit mathjax">AI</span> systems may form ongoing relationships with users, increasing their persuasive power. This paper investigates the uncertain future of persuasive <span class="search-hit mathjax">AI</span> systems. We examine ways that <span class="search-hit mathjax">AI</span> could qualitatively alter our relationship to and views regarding persuasion by shifting the balance of persuasive power, allowing personalized persuasion to be deployed at scale, powering misinformation campaigns, and changing the way humans can shape their own discourse. We consider ways <span class="search-hit mathjax">AI</span>-driven persuasion could differ from human-driven persuasion. We warn that ubiquitous highlypersuasive <span class="search-hit mathjax">AI</span> systems could alter our information environment so significantly so as to contribute to a loss of human control of our own future. In response, we examine several potential responses to <span class="search-hit mathjax">AI</span>-driven persuasion: prohibition, identification of <span class="search-hit mathjax">AI</span> agents, truthful <span class="search-hit mathjax">AI</span>, and <span class="search-hit mathjax">legal</span> remedies. We conclude that none of these solutions will be airtight, and that individuals and governments will need to take active steps to guard against the most pernicious effects of persuasive <span class="search-hit mathjax">AI</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2303.08721v1-abstract-full').style.display = 'none'; document.getElementById('2303.08721v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 March, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2303.06219">arXiv:2303.06219</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2303.06219">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Carbon Emissions of Writing and Illustrating Are Lower for <span class="search-hit mathjax">AI</span> than for Humans
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Tomlinson%2C+B">Bill Tomlinson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Black%2C+R+W">Rebecca W. Black</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Patterson%2C+D+J">Donald J. Patterson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Torrance%2C+A+W">Andrew W. Torrance</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2303.06219v1-abstract-short" style="display: inline;">
        As <span class="search-hit mathjax">AI</span> systems proliferate, their greenhouse gas emissions are an increasingly important concern for human societies. We analyze the emissions of several&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2303.06219v1-abstract-full').style.display = 'inline'; document.getElementById('2303.06219v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2303.06219v1-abstract-full" style="display: none;">
        As <span class="search-hit mathjax">AI</span> systems proliferate, their greenhouse gas emissions are an increasingly important concern for human societies. We analyze the emissions of several <span class="search-hit mathjax">AI</span> systems (ChatGPT, BLOOM, DALL-E2, Midjourney) relative to those of humans completing the same tasks. We find that an <span class="search-hit mathjax">AI</span> writing a page of text emits 130 to 1500 times less CO2e than a human doing so. Similarly, an <span class="search-hit mathjax">AI</span> creating an image emits 310 to 2900 times less. Emissions <span class="search-hit mathjax">analysis</span> do not account for social impacts such as professional displacement, <span class="search-hit mathjax">legality</span>, and rebound effects. In addition, <span class="search-hit mathjax">AI</span> is not a substitute for all human tasks. Nevertheless, at present, the use of <span class="search-hit mathjax">AI</span> holds the potential to carry out several major activities at much lower emission levels than can humans.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2303.06219v1-abstract-full').style.display = 'none'; document.getElementById('2303.06219v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 March, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">21 pages, 2 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          K.4; I.2
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2301.06009">arXiv:2301.06009</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2301.06009">pdf</a>, <a href="https://arxiv.org/format/2301.06009">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1016/j.artint.2022.103828">10.1016/j.artint.2022.103828 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Rationalizing Predictions by Adversarial Information Calibration
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sha%2C+L">Lei Sha</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Camburu%2C+O">Oana-Maria Camburu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lukasiewicz%2C+T">Thomas Lukasiewicz</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2301.06009v1-abstract-short" style="display: inline;">
        Explaining the predictions of <span class="search-hit mathjax">AI</span> models is paramount in safety-critical applications, such as in&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2301.06009v1-abstract-full').style.display = 'inline'; document.getElementById('2301.06009v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2301.06009v1-abstract-full" style="display: none;">
        Explaining the predictions of <span class="search-hit mathjax">AI</span> models is paramount in safety-critical applications, such as in <span class="search-hit mathjax">legal</span> or medical domains. One form of explanation for a prediction is an extractive rationale, i.e., a subset of features of an instance that lead the model to give its prediction on that instance. For example, the subphrase ``he stole the mobile phone&#39;&#39; can be an extractive rationale for the prediction of ``Theft&#39;&#39;. Previous works on generating extractive rationales usually employ a two-phase model: a selector that selects the most important features (i.e., the rationale) followed by a predictor that makes the prediction based exclusively on the selected features. One disadvantage of these works is that the main signal for learning to select features comes from the comparison of the answers given by the predictor to the ground-truth answers. In this work, we propose to squeeze more information from the predictor via an information calibration method. More precisely, we train two models jointly: one is a typical neural model that solves the task at hand in an accurate but black-box manner, and the other is a selector-predictor model that additionally produces a rationale for its prediction. The first model is used as a guide for the second model. We use an adversarial technique to calibrate the information extracted by the two models such that the difference between them is an indicator of the missed or over-selected features. In addition, for natural language tasks, we propose a language-model-based regularizer to encourage the extraction of fluent rationales. Experimental results on a sentiment <span class="search-hit mathjax">analysis</span> task, a hate speech recognition task as well as on three tasks from the <span class="search-hit mathjax">legal</span> domain show the effectiveness of our approach to rationale extraction.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2301.06009v1-abstract-full').style.display = 'none'; document.getElementById('2301.06009v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 January, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">arXiv admin note: substantial text overlap with arXiv:2012.08884</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Artificial Intelligence, Volume 315, February 2023
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2212.00469">arXiv:2212.00469</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2212.00469">pdf</a>, <a href="https://arxiv.org/format/2212.00469">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Beyond Incompatibility: Trade-offs between Mutually Exclusive Fairness Criteria in Machine Learning and Law
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zehlike%2C+M">Meike Zehlike</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Loosley%2C+A">Alex Loosley</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jonsson%2C+H">Håkan Jonsson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wiedemann%2C+E">Emil Wiedemann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hacker%2C+P">Philipp Hacker</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2212.00469v6-abstract-short" style="display: inline;">
        Fair and trustworthy <span class="search-hit mathjax">AI</span> is becoming ever more important in both machine learning and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2212.00469v6-abstract-full').style.display = 'inline'; document.getElementById('2212.00469v6-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2212.00469v6-abstract-full" style="display: none;">
        Fair and trustworthy <span class="search-hit mathjax">AI</span> is becoming ever more important in both machine learning and <span class="search-hit mathjax">legal</span> domains. One important consequence is that decision makers must seek to guarantee a &#39;fair&#39;, i.e., non-discriminatory, algorithmic decision procedure. However, there are several competing notions of algorithmic fairness that have been shown to be mutually incompatible under realistic factual assumptions. This concerns, for example, the widely used fairness measures of &#39;calibration within groups&#39; and &#39;balance for the positive/negative class&#39;. In this paper, we present a novel algorithm (FAir Interpolation Method: FAIM) for continuously interpolating between these three fairness criteria. Thus, an initially unfair prediction can be remedied to, at least partially, meet a desired, weighted combination of the respective fairness conditions. We demonstrate the effectiveness of our algorithm when applied to synthetic data, the COMPAS data set, and a new, real-world data set from the e-commerce sector. Finally, we discuss to what extent FAIM can be harnessed to comply with conflicting <span class="search-hit mathjax">legal</span> obligations. The <span class="search-hit mathjax">analysis</span> suggests that it may operationalize duties in traditional <span class="search-hit mathjax">legal</span> fields, such as credit scoring and criminal justice proceedings, but also for the latest <span class="search-hit mathjax">AI</span> regulations put forth in the EU, like the Digital Markets Act and the recently enacted <span class="search-hit mathjax">AI</span> Act.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2212.00469v6-abstract-full').style.display = 'none'; document.getElementById('2212.00469v6-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 December, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 1 December, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2022.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.m; K.4.2; K.5.m
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2210.15289">arXiv:2210.15289</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2210.15289">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On the Efficiency of Ethics as a Governing Tool for Artificial Intelligence
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Corr%C3%AAa%2C+N+K">Nicholas Kluge Corrêa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=De+Oliveira%2C+N">Nythamar De Oliveira</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Massmann%2C+D">Diogo Massmann</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2210.15289v1-abstract-short" style="display: inline;">
        &hellip;organizations have published guidelines proposing ethical principles for regulating the use and development of autonomous intelligent systems. Meta-analyses of the <span class="search-hit mathjax">AI</span> Ethics research field point to convergence on certain principles that supposedly govern the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2210.15289v1-abstract-full').style.display = 'inline'; document.getElementById('2210.15289v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2210.15289v1-abstract-full" style="display: none;">
        The 4th Industrial Revolution is the culmination of the digital age. Nowadays, technologies such as robotics, nanotechnology, genetics, and artificial intelligence promise to transform our world and the way we live. Artificial Intelligence Ethics and Safety is an emerging research field that has been gaining popularity in recent years. Several private, public and non-governmental organizations have published guidelines proposing ethical principles for regulating the use and development of autonomous intelligent systems. Meta-analyses of the <span class="search-hit mathjax">AI</span> Ethics research field point to convergence on certain principles that supposedly govern the <span class="search-hit mathjax">AI</span> industry. However, little is known about the effectiveness of this form of Ethics. In this paper, we would like to conduct a critical <span class="search-hit mathjax">analysis</span> of the current state of <span class="search-hit mathjax">AI</span> Ethics and suggest that this form of governance based on principled ethical guidelines is not sufficient to norm the <span class="search-hit mathjax">AI</span> industry and its developers. We believe that drastic changes are necessary, both in the training processes of professionals in the fields related to the development of software and intelligent systems and in the increased regulation of these professionals and their industry. To this end, we suggest that law should benefit from recent contributions from bioethics, to make the contributions of <span class="search-hit mathjax">AI</span> ethics to governance explicit in <span class="search-hit mathjax">legal</span> terms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2210.15289v1-abstract-full').style.display = 'none'; document.getElementById('2210.15289v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 October, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2209.09666">arXiv:2209.09666</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2209.09666">pdf</a>, <a href="https://arxiv.org/format/2209.09666">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Documenting use cases in the affective computing domain using Unified Modeling Language
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hupont%2C+I">Isabelle Hupont</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gomez%2C+E">Emilia Gomez</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2209.09666v1-abstract-short" style="display: inline;">
        The study of the ethical impact of <span class="search-hit mathjax">AI</span> and the design of trustworthy systems needs the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2209.09666v1-abstract-full').style.display = 'inline'; document.getElementById('2209.09666v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2209.09666v1-abstract-full" style="display: none;">
        The study of the ethical impact of <span class="search-hit mathjax">AI</span> and the design of trustworthy systems needs the <span class="search-hit mathjax">analysis</span> of the scenarios where <span class="search-hit mathjax">AI</span> systems are used, which is related to the software engineering concept of &#34;use case&#34; and the &#34;intended purpose&#34; <span class="search-hit mathjax">legal</span> term. However, there is no standard methodology for use case documentation covering the context of use, scope, functional requirements and risks of an <span class="search-hit mathjax">AI</span> system. In this work, we propose a novel documentation methodology for <span class="search-hit mathjax">AI</span> use cases, with a special focus on the affective computing domain. Our approach builds upon an assessment of use case information needs documented in the research literature and the recently proposed European regulatory framework for <span class="search-hit mathjax">AI</span>. From this assessment, we adopt and adapt the Unified Modeling Language (UML), which has been used in the last two decades mostly by software engineers. Each use case is then represented by an UML diagram and a structured table, and we provide a set of examples illustrating its application to several affective computing scenarios.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2209.09666v1-abstract-full').style.display = 'none'; document.getElementById('2209.09666v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 September, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 5 figures, 2 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2209.05440">arXiv:2209.05440</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2209.05440">pdf</a>, <a href="https://arxiv.org/format/2209.05440">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Bias Impact <span class="search-hit mathjax">Analysis</span> of <span class="search-hit mathjax">AI</span> in Consumer Mobile Health Technologies: <span class="search-hit mathjax">Legal</span>, Technical, and Policy
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gloria%2C+K">Kristine Gloria</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rastogi%2C+N">Nidhi Rastogi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=DeGroff%2C+S">Stevie DeGroff</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2209.05440v1-abstract-short" style="display: inline;">
        &hellip;patient journeys. We also include mental and behavioral health (mental and physiological) as part of our study. Furthermore, we explore to what extent current mechanisms - <span class="search-hit mathjax">legal</span>, technical, and or normative - help mitigate potential risks associated with unwanted bias in intelligent systems that make up the mHealth domain. We provide additional guidance on t&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2209.05440v1-abstract-full').style.display = 'inline'; document.getElementById('2209.05440v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2209.05440v1-abstract-full" style="display: none;">
        Today&#39;s large-scale algorithmic and automated deployment of decision-making systems threatens to exclude marginalized communities. Thus, the emergent danger comes from the effectiveness and the propensity of such systems to replicate, reinforce, or amplify harmful existing discriminatory acts. Algorithmic bias exposes a deeply entrenched encoding of a range of unwanted biases that can have profound real-world effects that manifest in domains from employment, to housing, to healthcare. The last decade of research and examples on these effects further underscores the need to examine any claim of a value-neutral technology. This work examines the intersection of algorithmic bias in consumer mobile health technologies (mHealth). We include mHealth, a term used to describe mobile technology and associated sensors to provide healthcare solutions through patient journeys. We also include mental and behavioral health (mental and physiological) as part of our study. Furthermore, we explore to what extent current mechanisms - <span class="search-hit mathjax">legal</span>, technical, and or normative - help mitigate potential risks associated with unwanted bias in intelligent systems that make up the mHealth domain. We provide additional guidance on the role and responsibilities technologists and policymakers have to ensure that such systems empower patients equitably.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2209.05440v1-abstract-full').style.display = 'none'; document.getElementById('2209.05440v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 August, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2207.04053">arXiv:2207.04053</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2207.04053">pdf</a>, <a href="https://arxiv.org/format/2207.04053">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On the Need and Applicability of Causality for Fairness: A Unified Framework for <span class="search-hit mathjax">AI</span> Auditing and <span class="search-hit mathjax">Legal</span> <span class="search-hit mathjax">Analysis</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Binkyte%2C+R">Ruta Binkyte</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Grozdanovski%2C+L">Ljupcho Grozdanovski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhioua%2C+S">Sami Zhioua</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2207.04053v4-abstract-short" style="display: inline;">
        As Artificial Intelligence (<span class="search-hit mathjax">AI</span>) increasingly influences decisions in critical societal sectors, understanding and establishing causality becomes essential for evaluating the fairness of automated systems. This article explores the significance of causal reasoning in addressing algorithmic discrimination, emphasizing both&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2207.04053v4-abstract-full').style.display = 'inline'; document.getElementById('2207.04053v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2207.04053v4-abstract-full" style="display: none;">
        As Artificial Intelligence (<span class="search-hit mathjax">AI</span>) increasingly influences decisions in critical societal sectors, understanding and establishing causality becomes essential for evaluating the fairness of automated systems. This article explores the significance of causal reasoning in addressing algorithmic discrimination, emphasizing both <span class="search-hit mathjax">legal</span> and societal perspectives. By reviewing landmark cases and regulatory frameworks, particularly within the European Union, we illustrate the challenges inherent in proving causal claims when confronted with opaque <span class="search-hit mathjax">AI</span> decision-making processes. The discussion outlines practical obstacles and methodological limitations in applying causal inference to real-world fairness scenarios, proposing actionable solutions to enhance transparency, accountability, and fairness in algorithm-driven decisions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2207.04053v4-abstract-full').style.display = 'none'; document.getElementById('2207.04053v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 March, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 8 July, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2207.01493">arXiv:2207.01493</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2207.01493">pdf</a>, <a href="https://arxiv.org/format/2207.01493">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">AI</span> Ethics: An Empirical Study on the Views of Practitioners and Lawmakers
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Khan%2C+A+A">Arif Ali Khan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Akbar%2C+M+A">Muhammad Azeem Akbar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fahmideh%2C+M">Mahdi Fahmideh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liang%2C+P">Peng Liang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Waseem%2C+M">Muhammad Waseem</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ahmad%2C+A">Aakash Ahmad</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Niazi%2C+M">Mahmood Niazi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Abrahamsson%2C+P">Pekka Abrahamsson</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2207.01493v2-abstract-short" style="display: inline;">
        Artificial Intelligence (<span class="search-hit mathjax">AI</span>) solutions and technologies are being increasingly adopted in smart systems context, however, such technologies are continuously concerned with ethical uncertainties. Various guidelines, principles, and regulatory frameworks are designed to ensure that&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2207.01493v2-abstract-full').style.display = 'inline'; document.getElementById('2207.01493v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2207.01493v2-abstract-full" style="display: none;">
        Artificial Intelligence (<span class="search-hit mathjax">AI</span>) solutions and technologies are being increasingly adopted in smart systems context, however, such technologies are continuously concerned with ethical uncertainties. Various guidelines, principles, and regulatory frameworks are designed to ensure that <span class="search-hit mathjax">AI</span> technologies bring ethical well-being. However, the implications of <span class="search-hit mathjax">AI</span> ethics principles and guidelines are still being debated. To further explore the significance of <span class="search-hit mathjax">AI</span> ethics principles and relevant challenges, we conducted a survey of 99 representative <span class="search-hit mathjax">AI</span> practitioners and lawmakers (e.g., <span class="search-hit mathjax">AI</span> engineers, lawyers) from twenty countries across five continents. To the best of our knowledge, this is the first empirical study that encapsulates the perceptions of two different types of population (<span class="search-hit mathjax">AI</span> practitioners and lawmakers) and the study findings confirm that transparency, accountability, and privacy are the most critical <span class="search-hit mathjax">AI</span> ethics principles. On the other hand, lack of ethical knowledge, no <span class="search-hit mathjax">legal</span> frameworks, and lacking monitoring bodies are found the most common <span class="search-hit mathjax">AI</span> ethics challenges. The impact <span class="search-hit mathjax">analysis</span> of the challenges across <span class="search-hit mathjax">AI</span> ethics principles reveals that conflict in practice is a highly severe challenge. Moreover, the perceptions of practitioners and lawmakers are statistically correlated with significant differences for particular principles (e.g. fairness, freedom) and challenges (e.g. lacking monitoring bodies, machine distortion). Our findings stimulate further research, especially empowering existing capability maturity models to support the development and quality assessment of ethics-aware <span class="search-hit mathjax">AI</span> systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2207.01493v2-abstract-full').style.display = 'none'; document.getElementById('2207.01493v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 November, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 30 June, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2206.06149">arXiv:2206.06149</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2206.06149">pdf</a>, <a href="https://arxiv.org/ps/2206.06149">ps</a>, <a href="https://arxiv.org/format/2206.06149">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3531146.3533169">10.1145/3531146.3533169 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Tackling Algorithmic Disability Discrimination in the Hiring Process: An Ethical, <span class="search-hit mathjax">Legal</span> and Technical <span class="search-hit mathjax">Analysis</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Buyl%2C+M">Maarten Buyl</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cociancig%2C+C">Christina Cociancig</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Frattone%2C+C">Cristina Frattone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Roekens%2C+N">Nele Roekens</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2206.06149v1-abstract-short" style="display: inline;">
        &hellip;persons with disabilities (PWDs) demands a distinctive approach that is fundamentally different to that applied to other protected characteristics, due to particular ethical, <span class="search-hit mathjax">legal</span>, and technical challenges. We address these challenges specifically in the context of artificial intelligence (&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2206.06149v1-abstract-full').style.display = 'inline'; document.getElementById('2206.06149v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2206.06149v1-abstract-full" style="display: none;">
        Tackling algorithmic discrimination against persons with disabilities (PWDs) demands a distinctive approach that is fundamentally different to that applied to other protected characteristics, due to particular ethical, <span class="search-hit mathjax">legal</span>, and technical challenges. We address these challenges specifically in the context of artificial intelligence (<span class="search-hit mathjax">AI</span>) systems used in hiring processes (or automated hiring systems, AHSs), in which automated assessment procedures are subject to unique ethical and <span class="search-hit mathjax">legal</span> considerations and have an undeniable adverse impact on PWDs. In this paper, we discuss concerns and opportunities raised by <span class="search-hit mathjax">AI</span>-driven hiring in relation to disability discrimination. Ultimately, we aim to encourage further research into this topic. Hence, we establish some starting points and design a roadmap for ethicists, lawmakers, advocates as well as <span class="search-hit mathjax">AI</span> practitioners alike.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2206.06149v1-abstract-full').style.display = 'none'; document.getElementById('2206.06149v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 June, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">FAccT 2022 proceedings</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2206.00485">arXiv:2206.00485</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2206.00485">pdf</a>, <a href="https://arxiv.org/format/2206.00485">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Co-creation and ownership for <span class="search-hit mathjax">AI</span> radio
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gordon%2C+S">Skylar Gordon</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mahari%2C+R">Robert Mahari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mishra%2C+M">Manaswi Mishra</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Epstein%2C+Z">Ziv Epstein</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2206.00485v1-abstract-short" style="display: inline;">
        Recent breakthroughs in <span class="search-hit mathjax">AI</span>-generated music open the door for new forms for co-creation and co-creativity. We present Artificial$.\!$fm, a proof-of-concept casual creator that blends&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2206.00485v1-abstract-full').style.display = 'inline'; document.getElementById('2206.00485v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2206.00485v1-abstract-full" style="display: none;">
        Recent breakthroughs in <span class="search-hit mathjax">AI</span>-generated music open the door for new forms for co-creation and co-creativity. We present Artificial$.\!$fm, a proof-of-concept casual creator that blends <span class="search-hit mathjax">AI</span>-music generation, subjective ratings, and personalized recommendation for the creation and curation of <span class="search-hit mathjax">AI</span>-generated music. Listeners can rate emergent songs to steer the evolution of future music. They can also personalize their preferences to better navigate the possibility space. As a &#34;slow creator&#34; with many human stakeholders, Artificial$.\!$fm is an example of how casual creators can leverage human curation at scale to collectively navigate a possibility space. It also provides a case study to reflect on how ownership should be considered in these contexts. We report on the design and development of Artificial$.\!$fm, and provide a <span class="search-hit mathjax">legal</span> <span class="search-hit mathjax">analysis</span> on the ownership of artifacts generated on the platform.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2206.00485v1-abstract-full').style.display = 'none'; document.getElementById('2206.00485v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 June, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2205.08264">arXiv:2205.08264</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2205.08264">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Working with Affective Computing: Exploring UK Public Perceptions of <span class="search-hit mathjax">AI</span> enabled Workplace Surveillance
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Urquhart%2C+L">Lachlan Urquhart</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Laffer%2C+A">Alex Laffer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Miranda%2C+D">Diana Miranda</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2205.08264v1-abstract-short" style="display: inline;">
        &hellip;introduction; section 2 provides an overview of the innovative design fiction methodology; section 3 explores wider shifts around IT in the workplace; section 4 provides some <span class="search-hit mathjax">legal</span> <span class="search-hit mathjax">analysis</span> exploring emergence of <span class="search-hit mathjax">AI</span> in the workplace; and section 5 presents themes from the study d&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2205.08264v1-abstract-full').style.display = 'inline'; document.getElementById('2205.08264v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2205.08264v1-abstract-full" style="display: none;">
        This paper explores public perceptions around the role of affective computing in the workplace. It uses a series of design fictions with 46 UK based participants, unpacking their perspectives on the advantages and disadvantages of tracking the emotional state of workers. The scenario focuses on mundane uses of biometric sensing in a sales environment, and how this could shape management approaches with workers. The paper structure is as follows: section 1 provides a brief introduction; section 2 provides an overview of the innovative design fiction methodology; section 3 explores wider shifts around IT in the workplace; section 4 provides some <span class="search-hit mathjax">legal</span> <span class="search-hit mathjax">analysis</span> exploring emergence of <span class="search-hit mathjax">AI</span> in the workplace; and section 5 presents themes from the study data. The latter section includes discussion on concerns around functionality and accuracy of affective computing systems, and their impacts on surveillance, human agency, and worker/management interactions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2205.08264v1-abstract-full').style.display = 'none'; document.getElementById('2205.08264v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 May, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2205.01772">arXiv:2205.01772</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2205.01772">pdf</a>, <a href="https://arxiv.org/format/2205.01772">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Brazilian Data at Risk in the Age of <span class="search-hit mathjax">AI</span>?
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Teixeira%2C+R+F+d+S">Raoni F. da S. Teixeira</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Januzi%2C+R+B">Rafael B. Januzi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Faria%2C+F+A">Fabio A. Faria</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2205.01772v3-abstract-short" style="display: inline;">
        Advances in image processing and <span class="search-hit mathjax">analysis</span> as well as machine learning techniques have contributed to the use of biometric recognition systems in daily people tasks. These tasks range from simple access to mobile devices to tagging friends in photos shared on social networks and complex financial operations on self-service devices for banking transactions. In&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2205.01772v3-abstract-full').style.display = 'inline'; document.getElementById('2205.01772v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2205.01772v3-abstract-full" style="display: none;">
        Advances in image processing and <span class="search-hit mathjax">analysis</span> as well as machine learning techniques have contributed to the use of biometric recognition systems in daily people tasks. These tasks range from simple access to mobile devices to tagging friends in photos shared on social networks and complex financial operations on self-service devices for banking transactions. In China, the use of these systems goes beyond personal use becoming a country&#39;s government policy with the objective of monitoring the behavior of its population. On July 05th 2021, the Brazilian government announced acquisition of a biometric recognition system to be used nationwide. In the opposite direction to China, Europe and some American cities have already started the discussion about the <span class="search-hit mathjax">legality</span> of using biometric systems in public places, even banning this practice in their territory. In order to open a deeper discussion about the risks and <span class="search-hit mathjax">legality</span> of using these systems, this work exposes the vulnerabilities of biometric recognition systems, focusing its efforts on the face modality. Furthermore, it shows how it is possible to fool a biometric system through a well-known presentation attack approach in the literature called morphing. Finally, a list of ten concerns was created to start the discussion about the security of citizen data and data privacy law in the Age of Artificial Intelligence (<span class="search-hit mathjax">AI</span>).
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2205.01772v3-abstract-full').style.display = 'none'; document.getElementById('2205.01772v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 3 May, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages in Portuguese and 5 figures, Top 3 among the best papers at the ENIAC 2022</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2205.00911">arXiv:2205.00911</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2205.00911">pdf</a>, <a href="https://arxiv.org/ps/2205.00911">ps</a>, <a href="https://arxiv.org/format/2205.00911">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">AI</span>-Driven Contextual Advertising: A Technology Report and Implication <span class="search-hit mathjax">Analysis</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=H%C3%A4glund%2C+E">Emil Häglund</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bj%C3%B6rklund%2C+J">Johanna Björklund</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2205.00911v1-abstract-short" style="display: inline;">
        &hellip;the surrounding media context. The growing interest in contextual advertising is in part a counterreaction to the current dependency on personal data, which is problematic from <span class="search-hit mathjax">legal</span> and ethical standpoints. The transition is further accelerated by developments in Artificial Intelligence (&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2205.00911v1-abstract-full').style.display = 'inline'; document.getElementById('2205.00911v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2205.00911v1-abstract-full" style="display: none;">
        Programmatic advertising consists in automated auctioning of digital ad space. Every time a user requests a web page, placeholders on the page are populated with ads from the highest-bidding advertisers. The bids are typically based on information about the user, and to an increasing extent, on information about the surrounding media context. The growing interest in contextual advertising is in part a counterreaction to the current dependency on personal data, which is problematic from <span class="search-hit mathjax">legal</span> and ethical standpoints. The transition is further accelerated by developments in Artificial Intelligence (<span class="search-hit mathjax">AI</span>), which allow for a deeper semantic understanding of context and, by extension, more effective ad placement. In this article, we begin by identifying context factors that have been shown in previous research to positively influence how ads are received. We then continue to discuss applications of <span class="search-hit mathjax">AI</span> in contextual advertising, where it adds value by, e.g., extracting high-level information about media context and optimising bidding strategies. However, left unchecked, these new practices can lead to unfair ad delivery and manipulative use of context. We summarize these and other concerns for consumers, publishers and advertisers in an implication <span class="search-hit mathjax">analysis</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2205.00911v1-abstract-full').style.display = 'none'; document.getElementById('2205.00911v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 May, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2203.06246">arXiv:2203.06246</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2203.06246">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3512898">10.1145/3512898 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An Uncommon Task: Participatory Design in <span class="search-hit mathjax">Legal</span> <span class="search-hit mathjax">AI</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Delgado%2C+F">Fernando Delgado</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Barocas%2C+S">Solon Barocas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Levy%2C+K">Karen Levy</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2203.06246v1-abstract-short" style="display: inline;">
        Despite growing calls for participation in <span class="search-hit mathjax">AI</span> design, there are to date few empirical studies of what these processes look like and how they can be structured for meaningful engagement with domain experts. In this paper, we examine a notable yet understudied&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.06246v1-abstract-full').style.display = 'inline'; document.getElementById('2203.06246v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2203.06246v1-abstract-full" style="display: none;">
        Despite growing calls for participation in <span class="search-hit mathjax">AI</span> design, there are to date few empirical studies of what these processes look like and how they can be structured for meaningful engagement with domain experts. In this paper, we examine a notable yet understudied <span class="search-hit mathjax">AI</span> design process in the <span class="search-hit mathjax">legal</span> domain that took place over a decade ago, the impact of which still informs <span class="search-hit mathjax">legal</span> automation efforts today. Specifically, we examine the design and evaluation activities that took place from 2006 to 2011 within the TeXT Retrieval Conference&#39;s (TREC) <span class="search-hit mathjax">Legal</span> Track, a computational research venue hosted by the National Institute of Standards and Technologies. The <span class="search-hit mathjax">Legal</span> Track of TREC is notable in the history of <span class="search-hit mathjax">AI</span> research and practice because it relied on a range of participatory approaches to facilitate the design and evaluation of new computational techniques--in this case, for automating attorney document review for civil litigation matters. Drawing on archival research and interviews with coordinators of the <span class="search-hit mathjax">Legal</span> Track of TREC, our <span class="search-hit mathjax">analysis</span> reveals how an interactive simulation methodology allowed computer scientists and lawyers to become co-designers and helped bridge the chasm between computational research and real-world, high-stakes litigation practice. In analyzing this case from the recent past, our aim is to empirically ground contemporary critiques of <span class="search-hit mathjax">AI</span> development and evaluation and the calls for greater participation as a means to address them.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.06246v1-abstract-full').style.display = 'none'; document.getElementById('2203.06246v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 March, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2022.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        In Proceedings of the ACM on Human-Computer Interaction, 6, CSCW1, Article 51 (April 2022), 23 pages
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2203.00469">arXiv:2203.00469</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2203.00469">pdf</a>, <a href="https://arxiv.org/ps/2203.00469">ps</a>, <a href="https://arxiv.org/format/2203.00469">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multimedia">cs.MM</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Compliance Challenges in Forensic Image <span class="search-hit mathjax">Analysis</span> Under the Artificial Intelligence Act
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lorch%2C+B">Benedikt Lorch</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Scheler%2C+N">Nicole Scheler</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Riess%2C+C">Christian Riess</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2203.00469v1-abstract-short" style="display: inline;">
        In many applications of forensic image <span class="search-hit mathjax">analysis</span>, state-of-the-art results are nowadays achieved with machine learning methods. However, concerns about their reliability and opaqueness raise the question whether such methods can be used in criminal investigations. So far, this question of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.00469v1-abstract-full').style.display = 'inline'; document.getElementById('2203.00469v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2203.00469v1-abstract-full" style="display: none;">
        In many applications of forensic image <span class="search-hit mathjax">analysis</span>, state-of-the-art results are nowadays achieved with machine learning methods. However, concerns about their reliability and opaqueness raise the question whether such methods can be used in criminal investigations. So far, this question of <span class="search-hit mathjax">legal</span> compliance has hardly been discussed, also because <span class="search-hit mathjax">legal</span> regulations for machine learning methods were not defined explicitly. To this end, the European Commission recently proposed the artificial intelligence (<span class="search-hit mathjax">AI</span>) act, a regulatory framework for the trustworthy use of <span class="search-hit mathjax">AI</span>. Under the draft <span class="search-hit mathjax">AI</span> act, high-risk <span class="search-hit mathjax">AI</span> systems for use in law enforcement are permitted but subject to compliance with mandatory requirements. In this paper, we review why the use of machine learning in forensic image <span class="search-hit mathjax">analysis</span> is classified as high-risk. We then summarize the mandatory requirements for high-risk <span class="search-hit mathjax">AI</span> systems and discuss these requirements in light of two forensic applications, license plate recognition and deep fake detection. The goal of this paper is to raise awareness of the upcoming <span class="search-hit mathjax">legal</span> requirements and to point out avenues for future research.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.00469v1-abstract-full').style.display = 'none'; document.getElementById('2203.00469v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 March, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2202.02776">arXiv:2202.02776</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2202.02776">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.5281/zenodo.5981676">10.5281/zenodo.5981676 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Human rights, democracy, and the rule of law assurance framework for <span class="search-hit mathjax">AI</span> systems: A proposal
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Leslie%2C+D">David Leslie</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Burr%2C+C">Christopher Burr</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aitken%2C+M">Mhairi Aitken</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Katell%2C+M">Michael Katell</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briggs%2C+M">Morgan Briggs</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rincon%2C+C">Cami Rincon</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2202.02776v1-abstract-short" style="display: inline;">
        &hellip;2020, the Council of Europe&#39;s Ad Hoc Committee on Artificial Intelligence (CAHAI) and its subgroups initiated efforts to formulate and draft its Possible Elements of a <span class="search-hit mathjax">Legal</span> Framework on Artificial Intelligence, based on the Council of Europe&#39;s standards on human rights, democracy, and the rule of law. This document was ultimately adopted by the CAHA&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.02776v1-abstract-full').style.display = 'inline'; document.getElementById('2202.02776v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2202.02776v1-abstract-full" style="display: none;">
        Following on from the publication of its Feasibility Study in December 2020, the Council of Europe&#39;s Ad Hoc Committee on Artificial Intelligence (CAHAI) and its subgroups initiated efforts to formulate and draft its Possible Elements of a <span class="search-hit mathjax">Legal</span> Framework on Artificial Intelligence, based on the Council of Europe&#39;s standards on human rights, democracy, and the rule of law. This document was ultimately adopted by the CAHAI plenary in December 2021. To support this effort, The Alan Turing Institute undertook a programme of research that explored the governance processes and practical tools needed to operationalise the integration of human right due diligence with the assurance of trustworthy <span class="search-hit mathjax">AI</span> innovation practices.
  The resulting framework was completed and submitted to the Council of Europe in September 2021. It presents an end-to-end approach to the assurance of <span class="search-hit mathjax">AI</span> project lifecycles that integrates context-based risk <span class="search-hit mathjax">analysis</span> and appropriate stakeholder engagement with comprehensive impact assessment, and transparent risk management, impact mitigation, and innovation assurance practices. Taken together, these interlocking processes constitute a Human Rights, Democracy and the Rule of Law Assurance Framework (HUDERAF). The HUDERAF combines the procedural requirements for principles-based human rights due diligence with the governance mechanisms needed to set up technical and socio-technical guardrails for responsible and trustworthy <span class="search-hit mathjax">AI</span> innovation practices. Its purpose is to provide an accessible and user-friendly set of mechanisms for facilitating compliance with a binding <span class="search-hit mathjax">legal</span> framework on artificial intelligence, based on the Council of Europe&#39;s standards on human rights, democracy, and the rule of law, and to ensure that <span class="search-hit mathjax">AI</span> innovation projects are carried out with appropriate levels of public accountability, transparency, and democratic governance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.02776v1-abstract-full').style.display = 'none'; document.getElementById('2202.02776v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 February, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">341 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2201.00855">arXiv:2201.00855</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2201.00855">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">AI</span> &amp; Racial Equity: Understanding Sentiment <span class="search-hit mathjax">Analysis</span> Artificial Intelligence, Data Security, and Systemic Theory in Criminal Justice Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Abbas%2C+A">Alia Abbas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2201.00855v1-abstract-short" style="display: inline;">
        &hellip;been leveraged in investigating merits and drawbacks of using algorithms to automate human decision making in racially sensitive environments. It has been asserted through the <span class="search-hit mathjax">analysis</span> of historical systemic patterns, implicit biases, existing algorithmic risks, and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.00855v1-abstract-full').style.display = 'inline'; document.getElementById('2201.00855v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2201.00855v1-abstract-full" style="display: none;">
        Various forms of implications of artificial intelligence that either exacerbate or decrease racial systemic injustice have been explored in this applied research endeavor. Taking each thematic area of identifying, analyzing, and debating an systemic issue have been leveraged in investigating merits and drawbacks of using algorithms to automate human decision making in racially sensitive environments. It has been asserted through the <span class="search-hit mathjax">analysis</span> of historical systemic patterns, implicit biases, existing algorithmic risks, and <span class="search-hit mathjax">legal</span> implications that natural language processing based <span class="search-hit mathjax">AI</span>, such as risk assessment tools, have racially disparate outcomes. It is concluded that more litigative policies are needed to regulate and restrict how internal government institutions and corporations utilize algorithms, privacy and security risks, and auditing requirements in order to diverge from racially injustice outcomes and practices of the past.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.00855v1-abstract-full').style.display = 'none'; document.getElementById('2201.00855v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 January, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">25 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2111.05071">arXiv:2111.05071</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2111.05071">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/s11023-021-09577-4">10.1007/s11023-021-09577-4 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Conformity Assessments and Post-market Monitoring: A Guide to the Role of Auditing in the Proposed European <span class="search-hit mathjax">AI</span> Regulation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mokander%2C+J">Jakob Mokander</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Axente%2C+M">Maria Axente</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Casolari%2C+F">Federico Casolari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Floridi%2C+L">Luciano Floridi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2111.05071v1-abstract-short" style="display: inline;">
        The proposed European Artificial Intelligence Act (AIA) is the first attempt to elaborate a general <span class="search-hit mathjax">legal</span> framework for&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2111.05071v1-abstract-full').style.display = 'inline'; document.getElementById('2111.05071v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2111.05071v1-abstract-full" style="display: none;">
        The proposed European Artificial Intelligence Act (AIA) is the first attempt to elaborate a general <span class="search-hit mathjax">legal</span> framework for <span class="search-hit mathjax">AI</span> carried out by any major global economy. As such, the AIA is likely to become a point of reference in the larger discourse on how <span class="search-hit mathjax">AI</span> systems can (and should) be regulated. In this article, we describe and discuss the two primary enforcement mechanisms proposed in the AIA: the conformity assessments that providers of high-risk <span class="search-hit mathjax">AI</span> systems are expected to conduct, and the post-market monitoring plans that providers must establish to document the performance of high-risk <span class="search-hit mathjax">AI</span> systems throughout their lifetimes. We argue that AIA can be interpreted as a proposal to establish a Europe-wide ecosystem for conducting <span class="search-hit mathjax">AI</span> auditing, albeit in other words. Our <span class="search-hit mathjax">analysis</span> offers two main contributions. First, by describing the enforcement mechanisms included in the AIA in terminology borrowed from existing literature on <span class="search-hit mathjax">AI</span> auditing, we help providers of <span class="search-hit mathjax">AI</span> systems understand how they can prove adherence to the requirements set out in the AIA in practice. Second, by examining the AIA from an auditing perspective, we seek to provide transferable lessons from previous research about how to refine further the regulatory approach outlined in the AIA. We conclude by highlighting seven aspects of the AIA where amendments (or simply clarifications) would be helpful. These include, above all, the need to translate vague concepts into verifiable criteria and to strengthen the institutional safeguards concerning conformity assessments based on internal checks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2111.05071v1-abstract-full').style.display = 'none'; document.getElementById('2111.05071v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 November, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Artificial intelligence, Auditing, Certification, Conformity assessment, European Union, Governance, Regulation, Technology</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          K.5; K.4; K.7
        
      </p>
    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
         Monitoring: A Guide to the Role of Auditing in the Proposed European <span class="search-hit mathjax">AI</span> Regulation. Minds and Machines
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.05164">arXiv:2110.05164</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.05164">pdf</a>, <a href="https://arxiv.org/format/2110.05164">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Ethical Assurance: A practical approach to the responsible design, development, and deployment of data-driven technologies
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Burr%2C+C">Christopher Burr</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Leslie%2C+D">David Leslie</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.05164v1-abstract-short" style="display: inline;">
        This article offers several contributions to the interdisciplinary project of responsible research and innovation in data science and <span class="search-hit mathjax">AI</span>. First, it provides a critical&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.05164v1-abstract-full').style.display = 'inline'; document.getElementById('2110.05164v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.05164v1-abstract-full" style="display: none;">
        This article offers several contributions to the interdisciplinary project of responsible research and innovation in data science and <span class="search-hit mathjax">AI</span>. First, it provides a critical <span class="search-hit mathjax">analysis</span> of current efforts to establish practical mechanisms for algorithmic assessment, which are used to operationalise normative principles, such as sustainability, accountability, transparency, fairness, and explainability, in order to identify limitations and gaps with the current approaches. Second, it provides an accessible introduction to the methodology of argument-based assurance, and explores how it is currently being applied in the development of safety cases for autonomous and intelligent systems. Third, it generalises this method to incorporate wider ethical, social, and <span class="search-hit mathjax">legal</span> considerations, in turn establishing a novel version of argument-based assurance that we call &#39;ethical assurance&#39;. Ethical assurance is presented as a structured means for unifying the myriad practical mechanisms that have been proposed, as it is built upon a process-based form of project governance that supports inclusive and participatory ethical deliberation while also remaining grounded in social and technical realities. Finally, it sets an agenda for ethical assurance, by detailing current challenges, open questions, and next steps, which serve as a springboard to build an active (and interdisciplinary) research programme as well as contribute to ongoing discussions in policy and governance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.05164v1-abstract-full').style.display = 'none'; document.getElementById('2110.05164v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 October, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2108.10665">arXiv:2108.10665</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2108.10665">pdf</a>, <a href="https://arxiv.org/format/2108.10665">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3441852.3471208">10.1145/3441852.3471208 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Sharing Practices for Datasets Related to Accessibility and Aging
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kamikubo%2C+R">Rie Kamikubo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dwivedi%2C+U">Utkarsh Dwivedi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kacorri%2C+H">Hernisa Kacorri</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2108.10665v1-abstract-short" style="display: inline;">
        Datasets sourced from people with disabilities and older adults play an important role in innovation, benchmarking, and mitigating bias for both assistive and inclusive <span class="search-hit mathjax">AI</span>-infused applications. However, they are scarce. We conduct a systematic review of 137 accessibility datasets manually located across different disciplines over the last 35 years. Our&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2108.10665v1-abstract-full').style.display = 'inline'; document.getElementById('2108.10665v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2108.10665v1-abstract-full" style="display: none;">
        Datasets sourced from people with disabilities and older adults play an important role in innovation, benchmarking, and mitigating bias for both assistive and inclusive <span class="search-hit mathjax">AI</span>-infused applications. However, they are scarce. We conduct a systematic review of 137 accessibility datasets manually located across different disciplines over the last 35 years. Our <span class="search-hit mathjax">analysis</span> highlights how researchers navigate tensions between benefits and risks in data collection and sharing. We uncover patterns in data collection purpose, terminology, sample size, data types, and data sharing practices across communities of focus. We conclude by critically reflecting on challenges and opportunities related to locating and sharing accessibility datasets calling for technical, <span class="search-hit mathjax">legal</span>, and institutional privacy frameworks that are more attuned to concerns from these communities.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2108.10665v1-abstract-full').style.display = 'none'; document.getElementById('2108.10665v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 August, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Preprint, The 23rd International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS 2021)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.06071">arXiv:2107.06071</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.06071">pdf</a>, <a href="https://arxiv.org/format/2107.06071">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/ACCESS.2021.3127548">10.1109/ACCESS.2021.3127548 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        aiSTROM -- A roadmap for developing a successful <span class="search-hit mathjax">AI</span> strategy
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Herremans%2C+D">Dorien Herremans</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.06071v2-abstract-short" style="display: inline;">
        A total of 34% of <span class="search-hit mathjax">AI</span> research and development projects fails or are abandoned, according to a recent survey by Rackspace Technology of 1,870 companies. We propose a new strategic framework, aiSTROM, that empowers managers to create a successful&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.06071v2-abstract-full').style.display = 'inline'; document.getElementById('2107.06071v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.06071v2-abstract-full" style="display: none;">
        A total of 34% of <span class="search-hit mathjax">AI</span> research and development projects fails or are abandoned, according to a recent survey by Rackspace Technology of 1,870 companies. We propose a new strategic framework, aiSTROM, that empowers managers to create a successful <span class="search-hit mathjax">AI</span> strategy based on a thorough literature review. This provides a unique and integrated approach that guides managers and lead developers through the various challenges in the implementation process. In the aiSTROM framework, we start by identifying the top n potential projects (typically 3-5). For each of those, seven areas of focus are thoroughly analysed. These areas include creating a data strategy that takes into account unique cross-departmental machine learning data requirements, security, and <span class="search-hit mathjax">legal</span> requirements. aiSTROM then guides managers to think about how to put together an interdisciplinary artificial intelligence (<span class="search-hit mathjax">AI</span>) implementation team given the scarcity of <span class="search-hit mathjax">AI</span> talent. Once an <span class="search-hit mathjax">AI</span> team strategy has been established, it needs to be positioned within the organization, either cross-departmental or as a separate division. Other considerations include <span class="search-hit mathjax">AI</span> as a service (AIaas), or outsourcing development. Looking at new technologies, we have to consider challenges such as bias, <span class="search-hit mathjax">legality</span> of black-box-models, and keeping humans in the loop. Next, like any project, we need value-based key performance indicators (KPIs) to track and validate the progress. Depending on the company&#39;s risk-strategy, a SWOT <span class="search-hit mathjax">analysis</span> (strengths, weaknesses, opportunities, and threats) can help further classify the shortlisted projects. Finally, we should make sure that our strategy includes continuous education of employees to enable a culture of adoption. This unique and comprehensive framework offers a valuable, literature supported, tool for managers and lead developers.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.06071v2-abstract-full').style.display = 'none'; document.getElementById('2107.06071v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 November, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 25 June, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68Txx; 97Pxx
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          K.5; K.6; C.5; D.m; H.2; K.7
        
      </p>
    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        IEEE Access, 2021
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.03192">arXiv:2105.03192</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.03192">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An interdisciplinary conceptual study of Artificial Intelligence (<span class="search-hit mathjax">AI</span>) for helping benefit-risk assessment practices: Towards a comprehensive qualification matrix of <span class="search-hit mathjax">AI</span> programs and devices (pre-print 2020)
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chassang%2C+G">Gauthier Chassang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Thomsen%2C+M">Mogens Thomsen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rumeau%2C+P">Pierre Rumeau</a>, 
      
      <a href="/search/?searchtype=author&amp;query=S%C3%A8des%2C+F">Florence Sèdes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Delfin%2C+A">Alejandra Delfin</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.03192v1-abstract-short" style="display: inline;">
        This paper proposes a comprehensive <span class="search-hit mathjax">analysis</span> of existing concepts coming from different disciplines tackling the notion of intelligence, namely psychology and engineering, and from disciplines aiming to regulate&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.03192v1-abstract-full').style.display = 'inline'; document.getElementById('2105.03192v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.03192v1-abstract-full" style="display: none;">
        This paper proposes a comprehensive <span class="search-hit mathjax">analysis</span> of existing concepts coming from different disciplines tackling the notion of intelligence, namely psychology and engineering, and from disciplines aiming to regulate <span class="search-hit mathjax">AI</span> innovations, namely <span class="search-hit mathjax">AI</span> ethics and law. The aim is to identify shared notions or discrepancies to consider for qualifying <span class="search-hit mathjax">AI</span> systems. Relevant concepts are integrated into a matrix intended to help defining more precisely when and how computing tools (programs or devices) may be qualified as <span class="search-hit mathjax">AI</span> while highlighting critical features to serve a specific technical, ethical and <span class="search-hit mathjax">legal</span> assessment of challenges in <span class="search-hit mathjax">AI</span> development. Some adaptations of existing notions of <span class="search-hit mathjax">AI</span> characteristics are proposed. The matrix is a risk-based conceptual model designed to allow an empirical, flexible and scalable qualification of <span class="search-hit mathjax">AI</span> technologies in the perspective of benefit-risk assessment practices, technological monitoring and regulatory compliance: it offers a structured reflection tool for stakeholders in <span class="search-hit mathjax">AI</span> development that are engaged in responsible research and innovation.Pre-print version (achieved on May 2020)
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.03192v1-abstract-full').style.display = 'none'; document.getElementById('2105.03192v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.15764">arXiv:2103.15764</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.15764">pdf</a>, <a href="https://arxiv.org/format/2103.15764">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        eDarkTrends: Harnessing Social Media Trends in Substance use disorders for Opioid Listings on Cryptomarket
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lokala%2C+U">Usha Lokala</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lamy%2C+F">Francois Lamy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dastidar%2C+T+G">Triyasha Ghosh Dastidar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Roy%2C+K">Kaushik Roy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Daniulaityte%2C+R">Raminta Daniulaityte</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Parthasarathy%2C+S">Srinivasan Parthasarathy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sheth%2C+A">Amit Sheth</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.15764v1-abstract-short" style="display: inline;">
        &hellip;relationship being substance misuse causes poor mental health. However, the lack of evidence on the relationship has resulted in opioids being largely inaccessible through <span class="search-hit mathjax">legal</span> means. This study analyzes the substance misuse posts on social media with the opioids being sold through crypto market listings. We use the Drug Abuse Ontology, state-of-the-art dee&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.15764v1-abstract-full').style.display = 'inline'; document.getElementById('2103.15764v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.15764v1-abstract-full" style="display: none;">
        Opioid and substance misuse is rampant in the United States today, with the phenomenon known as the opioid crisis. The relationship between substance use and mental health has been extensively studied, with one possible relationship being substance misuse causes poor mental health. However, the lack of evidence on the relationship has resulted in opioids being largely inaccessible through <span class="search-hit mathjax">legal</span> means. This study analyzes the substance misuse posts on social media with the opioids being sold through crypto market listings. We use the Drug Abuse Ontology, state-of-the-art deep learning, and BERT-based models to generate sentiment and emotion for the social media posts to understand user perception on social media by investigating questions such as, which synthetic opioids people are optimistic, neutral, or negative about or what kind of drugs induced fear and sorrow or what kind of drugs people love or thankful about or which drug people think negatively about or which opioids cause little to no sentimental reaction. We also perform topic <span class="search-hit mathjax">analysis</span> associated with the generated sentiments and emotions to understand which topics correlate with people&#39;s responses to various drugs. Our findings can help shape policy to help isolate opioid use cases where timely intervention may be required to prevent adverse consequences, prevent overdose-related deaths, and worsen the epidemic.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.15764v1-abstract-full').style.display = 'none'; document.getElementById('2103.15764v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">6 pages, ICLR <span class="search-hit mathjax">AI</span> for Public Health Workshop 2021</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.7
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.08004">arXiv:2102.08004</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.08004">pdf</a>, <a href="https://arxiv.org/format/2102.08004">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Mental Trespass? Unveiling Truth, Exposing Thoughts and Threatening Civil Liberties with Non-Invasive <span class="search-hit mathjax">AI</span> Lie Detection
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sen%2C+T">Taylan Sen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Haut%2C+K">Kurtis Haut</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lomakin%2C+D">Denis Lomakin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hoque%2C+E">Ehsan Hoque</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.08004v1-abstract-short" style="display: inline;">
        &hellip;technologies are likely to experience a rapid advancement in the coming years, and that it would be irresponsible to wait any longer before discussing its implications. <span class="search-hit mathjax">Legal</span> and popular perspectives are reviewed to evaluate the potential for these technologies to cause societal harm. To understand the perspective of a reasonable person, we conducted a surve&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.08004v1-abstract-full').style.display = 'inline'; document.getElementById('2102.08004v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.08004v1-abstract-full" style="display: none;">
        Imagine an app on your phone or computer that can tell if you are being dishonest, just by processing affective features of your facial expressions, body movements, and voice. People could ask about your political preferences, your sexual orientation, and immediately determine which of your responses are honest and which are not. In this paper we argue why artificial intelligence-based, non-invasive lie detection technologies are likely to experience a rapid advancement in the coming years, and that it would be irresponsible to wait any longer before discussing its implications. <span class="search-hit mathjax">Legal</span> and popular perspectives are reviewed to evaluate the potential for these technologies to cause societal harm. To understand the perspective of a reasonable person, we conducted a survey of 129 individuals, and identified consent and accuracy as the major factors in their decision-making process regarding the use of these technologies. In our <span class="search-hit mathjax">analysis</span>, we distinguish two types of lie detection technology, accurate truth metering and accurate thought exposing. We generally find that truth metering is already largely within the scope of existing US federal and state laws, albeit with some notable exceptions. In contrast, we find that current regulation of thought exposing technologies is ambiguous and inadequate to safeguard civil liberties. In order to rectify these shortcomings, we introduce the <span class="search-hit mathjax">legal</span> concept of mental trespass and use this concept as the basis for proposed regulation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.08004v1-abstract-full').style.display = 'none'; document.getElementById('2102.08004v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">11 pages, 3 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.08884">arXiv:2012.08884</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.08884">pdf</a>, <a href="https://arxiv.org/format/2012.08884">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning from the Best: Rationalizing Prediction by Adversarial Information Calibration
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sha%2C+L">Lei Sha</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Camburu%2C+O">Oana-Maria Camburu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lukasiewicz%2C+T">Thomas Lukasiewicz</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.08884v2-abstract-short" style="display: inline;">
        Explaining the predictions of <span class="search-hit mathjax">AI</span> models is paramount in safety-critical applications, such as in&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.08884v2-abstract-full').style.display = 'inline'; document.getElementById('2012.08884v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.08884v2-abstract-full" style="display: none;">
        Explaining the predictions of <span class="search-hit mathjax">AI</span> models is paramount in safety-critical applications, such as in <span class="search-hit mathjax">legal</span> or medical domains. One form of explanation for a prediction is an extractive rationale, i.e., a subset of features of an instance that lead the model to give its prediction on the instance. Previous works on generating extractive rationales usually employ a two-phase model: a selector that selects the most important features (i.e., the rationale) followed by a predictor that makes the prediction based exclusively on the selected features. One disadvantage of these works is that the main signal for learning to select features comes from the comparison of the answers given by the predictor and the ground-truth answers. In this work, we propose to squeeze more information from the predictor via an information calibration method. More precisely, we train two models jointly: one is a typical neural model that solves the task at hand in an accurate but black-box manner, and the other is a selector-predictor model that additionally produces a rationale for its prediction. The first model is used as a guide to the second model. We use an adversarial-based technique to calibrate the information extracted by the two models such that the difference between them is an indicator of the missed or over-selected features. In addition, for natural language tasks, we propose to use a language-model-based regularizer to encourage the extraction of fluent rationales. Experimental results on a sentiment <span class="search-hit mathjax">analysis</span> task as well as on three tasks from the <span class="search-hit mathjax">legal</span> domain show the effectiveness of our approach to rationale extraction.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.08884v2-abstract-full').style.display = 'none'; document.getElementById('2012.08884v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 December, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 16 December, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Proceedings of the 35th AAAI Conference on Artificial Intelligence, 2021
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.08864">arXiv:2012.08864</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.08864">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="General Economics">econ.GN</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Development of cloud, digital technologies and the introduction of chip technologies
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Baghirzade%2C+A+R">Ali R. Baghirzade</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.08864v1-abstract-short" style="display: inline;">
        Hardly any other area of research has recently attracted as much attention as machine learning (ML) through the rapid advances in artificial intelligence (<span class="search-hit mathjax">AI</span>). This publication provides a short introduction to practical concepts and methods of machine learning, problems and emerging research questions, as well as an overview of the participants, an overview&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.08864v1-abstract-full').style.display = 'inline'; document.getElementById('2012.08864v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.08864v1-abstract-full" style="display: none;">
        Hardly any other area of research has recently attracted as much attention as machine learning (ML) through the rapid advances in artificial intelligence (<span class="search-hit mathjax">AI</span>). This publication provides a short introduction to practical concepts and methods of machine learning, problems and emerging research questions, as well as an overview of the participants, an overview of the application areas and the socio-economic framework conditions of the research.
  In expert circles, ML is used as a key technology for modern artificial intelligence techniques, which is why <span class="search-hit mathjax">AI</span> and ML are often used interchangeably, especially in an economic context. Machine learning and, in particular, deep learning (DL) opens up entirely new possibilities in automatic language processing, image <span class="search-hit mathjax">analysis</span>, medical diagnostics, process management and customer management. One of the important aspects in this article is chipization. Due to the rapid development of digitalization, the number of applications will continue to grow as digital technologies advance. In the future, machines will more and more provide results that are important for decision making. To this end, it is important to ensure the safety, reliability and sufficient traceability of automated decision-making processes from the technological side. At the same time, it is necessary to ensure that ML applications are compatible with <span class="search-hit mathjax">legal</span> issues such as responsibility and liability for algorithmic decisions, as well as technically feasible. Its formulation and regulatory implementation is an important and complex issue that requires an interdisciplinary approach. Last but not least, public acceptance is critical to the continued diffusion of machine learning processes in applications. This requires widespread public discussion and the involvement of various social groups.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.08864v1-abstract-full').style.display = 'none'; document.getElementById('2012.08864v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.08712">arXiv:2011.08712</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.08712">pdf</a>, <a href="https://arxiv.org/format/2011.08712">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Image and Video Processing">eess.IV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Simple Framework to Quantify Different Types of Uncertainty in Deep Neural Networks for Image Classification
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Khoshsirat%2C+A">Aria Khoshsirat</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.08712v5-abstract-short" style="display: inline;">
        Quantifying uncertainty in a model&#39;s predictions is important as it enables the safety of an <span class="search-hit mathjax">AI</span> system to be increased by acting on the model&#39;s output in an informed manner. This is crucial for applications where the cost of an error is high, such as in autonomous vehicle control, medical image&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.08712v5-abstract-full').style.display = 'inline'; document.getElementById('2011.08712v5-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.08712v5-abstract-full" style="display: none;">
        Quantifying uncertainty in a model&#39;s predictions is important as it enables the safety of an <span class="search-hit mathjax">AI</span> system to be increased by acting on the model&#39;s output in an informed manner. This is crucial for applications where the cost of an error is high, such as in autonomous vehicle control, medical image <span class="search-hit mathjax">analysis</span>, financial estimations or <span class="search-hit mathjax">legal</span> fields. Deep Neural Networks are powerful predictors that have recently achieved state-of-the-art performance on a wide spectrum of tasks. Quantifying predictive uncertainty in DNNs is a challenging and yet on-going problem. In this paper we propose a complete framework to capture and quantify three known types of uncertainty in DNNs for the task of image classification. This framework includes an ensemble of CNNs for model uncertainty, a supervised reconstruction auto-encoder to capture distributional uncertainty and using the output of activation functions in the last layer of the network, to capture data uncertainty. Finally we demonstrate the efficiency of our method on popular image datasets for classification.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.08712v5-abstract-full').style.display = 'none'; document.getElementById('2011.08712v5-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 May, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 17 November, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.02726">arXiv:2010.02726</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.02726">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Legal</span> Sentiment <span class="search-hit mathjax">Analysis</span> and Opinion Mining (LSAOM): Assimilating Advances in Autonomous <span class="search-hit mathjax">AI</span> <span class="search-hit mathjax">Legal</span> Reasoning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Eliot%2C+L">Lance Eliot</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.02726v1-abstract-short" style="display: inline;">
        An expanding field of substantive interest for the theory of the law and the practice-of-law entails <span class="search-hit mathjax">Legal</span> Sentiment&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.02726v1-abstract-full').style.display = 'inline'; document.getElementById('2010.02726v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.02726v1-abstract-full" style="display: none;">
        An expanding field of substantive interest for the theory of the law and the practice-of-law entails <span class="search-hit mathjax">Legal</span> Sentiment <span class="search-hit mathjax">Analysis</span> and Opinion Mining (LSAOM), consisting of two often intertwined phenomena and actions underlying <span class="search-hit mathjax">legal</span> discussions and narratives: (1) Sentiment <span class="search-hit mathjax">Analysis</span> (SA) for the detection of expressed or implied sentiment about a <span class="search-hit mathjax">legal</span> matter within the context of a <span class="search-hit mathjax">legal</span> milieu, and (2) Opinion Mining (OM) for the identification and illumination of explicit or implicit opinion accompaniments immersed within <span class="search-hit mathjax">legal</span> discourse. Efforts to undertake LSAOM have historically been performed by human hand and cognition, and only thinly aided in more recent times by the use of computer-based approaches. Advances in Artificial Intelligence (<span class="search-hit mathjax">AI</span>) involving especially Natural Language Processing (NLP) and Machine Learning (ML) are increasingly bolstering how automation can systematically perform either or both of Sentiment <span class="search-hit mathjax">Analysis</span> and Opinion Mining, all of which is being inexorably carried over into engagement within a <span class="search-hit mathjax">legal</span> context for improving LSAOM capabilities. This research paper examines the evolving infusion of <span class="search-hit mathjax">AI</span> into <span class="search-hit mathjax">Legal</span> Sentiment <span class="search-hit mathjax">Analysis</span> and Opinion Mining and proposes an alignment with the Levels of Autonomy (LoA) of <span class="search-hit mathjax">AI</span> <span class="search-hit mathjax">Legal</span> Reasoning (AILR), plus provides additional insights regarding <span class="search-hit mathjax">AI</span> LSAOM in its mechanizations and potential impact to the study of law and the practicing of law.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.02726v1-abstract-full').style.display = 'none'; document.getElementById('2010.02726v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 October, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">26 pages, 8 figures. arXiv admin note: text overlap with arXiv:2009.14620</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.0; J.7.0; K.5.9
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2008.10575">arXiv:2008.10575</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2008.10575">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Multidimensionality of <span class="search-hit mathjax">Legal</span> Singularity: Parametric <span class="search-hit mathjax">Analysis</span> and the Autonomous Levels of <span class="search-hit mathjax">AI</span> <span class="search-hit mathjax">Legal</span> Reasoning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Eliot%2C+L">Lance Eliot</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2008.10575v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Legal</span> scholars have in the last several years embarked upon an ongoing discussion and debate over a potential&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.10575v1-abstract-full').style.display = 'inline'; document.getElementById('2008.10575v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2008.10575v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Legal</span> scholars have in the last several years embarked upon an ongoing discussion and debate over a potential <span class="search-hit mathjax">Legal</span> Singularity that might someday occur, involving a variant or law-domain offshoot leveraged from the Artificial Intelligence (<span class="search-hit mathjax">AI</span>) realm amid its many decades of deliberations about an overarching and generalized technological singularity (referred to classically as The Singularity). This paper examines the postulated <span class="search-hit mathjax">Legal</span> Singularity and proffers that such <span class="search-hit mathjax">AI</span> and Law cogitations can be enriched by these three facets addressed herein: (1) dovetail additionally salient considerations of The Singularity into the <span class="search-hit mathjax">Legal</span> Singularity, (2) make use of an in-depth and innovative multidimensional parametric <span class="search-hit mathjax">analysis</span> of the <span class="search-hit mathjax">Legal</span> Singularity as posited in this paper, and (3) align and unify the <span class="search-hit mathjax">Legal</span> Singularity with the Levels of Autonomy (LoA) associated with <span class="search-hit mathjax">AI</span> <span class="search-hit mathjax">Legal</span> Reasoning (AILR) as propounded in this paper.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.10575v1-abstract-full').style.display = 'none'; document.getElementById('2008.10575v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 August, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">28 pages, 7 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.0; J.7.0; K.5.9
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2008.07346">arXiv:2008.07346</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2008.07346">pdf</a>, <a href="https://arxiv.org/format/2008.07346">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Memory networks for consumer protection:unfairness exposed
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ruggeri%2C+F">Federico Ruggeri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lagioia%2C+F">Francesca Lagioia</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lippi%2C+M">Marco Lippi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Torroni%2C+P">Paolo Torroni</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2008.07346v1-abstract-short" style="display: inline;">
        Recent work has demonstrated how data-driven <span class="search-hit mathjax">AI</span> methods can leverage consumer protection by supporting the automated&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.07346v1-abstract-full').style.display = 'inline'; document.getElementById('2008.07346v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2008.07346v1-abstract-full" style="display: none;">
        Recent work has demonstrated how data-driven <span class="search-hit mathjax">AI</span> methods can leverage consumer protection by supporting the automated <span class="search-hit mathjax">analysis</span> of <span class="search-hit mathjax">legal</span> documents. However, a shortcoming of data-driven approaches is poor explainability. We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to <span class="search-hit mathjax">legal</span> rationales. We thus consider several configurations of memory-augmented neural networks where rationales are given a special role in the modeling of context knowledge. Our results show that rationales not only contribute to improve the classification accuracy, but are also able to offer meaningful, natural language explanations of otherwise opaque classifier outcomes.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.07346v1-abstract-full').style.display = 'none'; document.getElementById('2008.07346v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 July, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2004.12158">arXiv:2004.12158</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2004.12158">pdf</a>, <a href="https://arxiv.org/format/2004.12158">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        How Does NLP Benefit <span class="search-hit mathjax">Legal</span> System: A Summary of <span class="search-hit mathjax">Legal</span> Artificial Intelligence
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhong%2C+H">Haoxi Zhong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiao%2C+C">Chaojun Xiao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tu%2C+C">Cunchao Tu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+T">Tianyang Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Z">Zhiyuan Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+M">Maosong Sun</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2004.12158v5-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Legal</span> Artificial Intelligence (LegalAI) focuses on applying the technology of artificial intelligence, especially natural language processing, to benefit tasks in the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2004.12158v5-abstract-full').style.display = 'inline'; document.getElementById('2004.12158v5-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2004.12158v5-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Legal</span> Artificial Intelligence (LegalAI) focuses on applying the technology of artificial intelligence, especially natural language processing, to benefit tasks in the <span class="search-hit mathjax">legal</span> domain. In recent years, LegalAI has drawn increasing attention rapidly from both <span class="search-hit mathjax">AI</span> researchers and <span class="search-hit mathjax">legal</span> professionals, as LegalAI is beneficial to the <span class="search-hit mathjax">legal</span> system for liberating <span class="search-hit mathjax">legal</span> professionals from a maze of paperwork. <span class="search-hit mathjax">Legal</span> professionals often think about how to solve tasks from rule-based and symbol-based methods, while NLP researchers concentrate more on data-driven and embedding methods. In this paper, we introduce the history, the current state, and the future directions of research in LegalAI. We illustrate the tasks from the perspectives of <span class="search-hit mathjax">legal</span> professionals and NLP researchers and show several representative applications in LegalAI. We conduct experiments and provide an in-depth <span class="search-hit mathjax">analysis</span> of the advantages and disadvantages of existing works to explore possible future directions. You can find the implementation of our work from https://github.com/thunlp/CLAIM.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2004.12158v5-abstract-full').style.display = 'none'; document.getElementById('2004.12158v5-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 May, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 25 April, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted by ACL 2020</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1906.09293">arXiv:1906.09293</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1906.09293">pdf</a>, <a href="https://arxiv.org/format/1906.09293">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Generating Counterfactual and Contrastive Explanations using SHAP
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rathi%2C+S">Shubham Rathi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1906.09293v1-abstract-short" style="display: inline;">
        With the advent of GDPR, the domain of explainable <span class="search-hit mathjax">AI</span> and model interpretability has gained added impetus. Methods to extract and communicate visibility into decision-making models have become&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1906.09293v1-abstract-full').style.display = 'inline'; document.getElementById('1906.09293v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1906.09293v1-abstract-full" style="display: none;">
        With the advent of GDPR, the domain of explainable <span class="search-hit mathjax">AI</span> and model interpretability has gained added impetus. Methods to extract and communicate visibility into decision-making models have become <span class="search-hit mathjax">legal</span> requirement. Two specific types of explanations, contrastive and counterfactual have been identified as suitable for human understanding. In this paper, we propose a model agnostic method and its systemic implementation to generate these explanations using shapely additive explanations (SHAP). We discuss a generative pipeline to create contrastive explanations and use it to further to generate counterfactual datapoints. This pipeline is tested and discussed on the IRIS, Wine Quality &amp; Mobile Features dataset. <span class="search-hit mathjax">Analysis</span> of the results obtained follows.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1906.09293v1-abstract-full').style.display = 'none'; document.getElementById('1906.09293v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 June, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This work was presented at 2nd Workshop on Humanizing <span class="search-hit mathjax">AI</span> (HAI) at IJCAI'19 in Macao, China</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1904.09273">arXiv:1904.09273</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1904.09273">pdf</a>, <a href="https://arxiv.org/format/1904.09273">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        &#34;Why did you do that?&#34;: Explaining black box models with Inductive Synthesis
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Pa%C3%A7ac%C4%B1%2C+G">Görkem Paçacı</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Johnson%2C+D">David Johnson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=McKeever%2C+S">Steve McKeever</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hamfelt%2C+A">Andreas Hamfelt</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1904.09273v1-abstract-short" style="display: inline;">
        &hellip;ability to generate explanations for the response to stimuli challenging. The importance of explaining black box models has become increasingly important given the prevalence of <span class="search-hit mathjax">AI</span> and ML systems and the need to build&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1904.09273v1-abstract-full').style.display = 'inline'; document.getElementById('1904.09273v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1904.09273v1-abstract-full" style="display: none;">
        By their nature, the composition of black box models is opaque. This makes the ability to generate explanations for the response to stimuli challenging. The importance of explaining black box models has become increasingly important given the prevalence of <span class="search-hit mathjax">AI</span> and ML systems and the need to build <span class="search-hit mathjax">legal</span> and regulatory frameworks around them. Such explanations can also increase trust in these uncertain systems. In our paper we present RICE, a method for generating explanations of the behaviour of black box models by (1) probing a model to extract model output examples using sensitivity <span class="search-hit mathjax">analysis</span>; (2) applying CNPInduce, a method for inductive logic program synthesis, to generate logic programs based on critical input-output pairs; and (3) interpreting the target program as a human-readable explanation. We demonstrate the application of our method by generating explanations of an artificial neural network trained to follow simple traffic rules in a hypothetical self-driving car simulation. We conclude with a discussion on the scalability and usability of our approach and its potential applications to explanation-critical scenarios.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1904.09273v1-abstract-full').style.display = 'none'; document.getElementById('1904.09273v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 April, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages, 1 figure, accepted for publication at the Solving Problems with Uncertainties workshop as part of ICCS 2019, Faro, Portugal, June 12-14</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          97R40 (Primary) 03B48 (Secondary)
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.3; D.2.1; I.2.2
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1812.02953">arXiv:1812.02953</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1812.02953">pdf</a>, <a href="https://arxiv.org/ps/1812.02953">ps</a>, <a href="https://arxiv.org/format/1812.02953">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Building Ethics into Artificial Intelligence
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+H">Han Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shen%2C+Z">Zhiqi Shen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Miao%2C+C">Chunyan Miao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Leung%2C+C">Cyril Leung</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lesser%2C+V+R">Victor R. Lesser</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+Q">Qiang Yang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1812.02953v1-abstract-short" style="display: inline;">
        As artificial intelligence (<span class="search-hit mathjax">AI</span>) systems become increasingly ubiquitous, the topic of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1812.02953v1-abstract-full').style.display = 'inline'; document.getElementById('1812.02953v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1812.02953v1-abstract-full" style="display: none;">
        As artificial intelligence (<span class="search-hit mathjax">AI</span>) systems become increasingly ubiquitous, the topic of <span class="search-hit mathjax">AI</span> governance for ethical decision-making by <span class="search-hit mathjax">AI</span> has captured public imagination. Within the <span class="search-hit mathjax">AI</span> research community, this topic remains less familiar to many researchers. In this paper, we complement existing surveys, which largely focused on the psychological, social and <span class="search-hit mathjax">legal</span> discussions of the topic, with an <span class="search-hit mathjax">analysis</span> of recent advances in technical solutions for <span class="search-hit mathjax">AI</span> governance. By reviewing publications in leading <span class="search-hit mathjax">AI</span> conferences including AAAI, AAMAS, ECAI and IJCAI, we propose a taxonomy which divides the field into four areas: 1) exploring ethical dilemmas; 2) individual ethical decision frameworks; 3) collective ethical decision frameworks; and 4) ethics in human-<span class="search-hit mathjax">AI</span> interactions. We highlight the intuitions and key techniques used in each approach, and discuss promising future research directions towards successful integration of ethical <span class="search-hit mathjax">AI</span> systems into human societies.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1812.02953v1-abstract-full').style.display = 'none'; document.getElementById('1812.02953v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 December, 2018; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2018.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        H. Yu, Z. Shen, C. Miao, C. Leung, V. R. Lesser &amp; Q. Yang, &#34;Building Ethics into Artificial Intelligence,&#34; in Proceedings of the 27th International Joint Conference on Artificial Intelligence (IJCAI&#39;18), pp. 5527-5533, 2018
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1809.04262">arXiv:1809.04262</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1809.04262">pdf</a>, <a href="https://arxiv.org/ps/1809.04262">ps</a>, <a href="https://arxiv.org/format/1809.04262">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Extracting Fairness Policies from <span class="search-hit mathjax">Legal</span> Documents
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Nagpal%2C+R">Rashmi Nagpal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wadhwa%2C+C">Chetna Wadhwa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gupta%2C+M">Mallika Gupta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shaikh%2C+S">Samiulla Shaikh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mehta%2C+S">Sameep Mehta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Goyal%2C+V">Vikram Goyal</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1809.04262v1-abstract-short" style="display: inline;">
        Machine Learning community is recently exploring the implications of bias and fairness with respect to the <span class="search-hit mathjax">AI</span> applications. The definition of fairness for such applications varies based on their domain of application. The policies governing the use of such machine learning system in a given context are defined by the constitutional laws of nations and regula&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1809.04262v1-abstract-full').style.display = 'inline'; document.getElementById('1809.04262v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1809.04262v1-abstract-full" style="display: none;">
        Machine Learning community is recently exploring the implications of bias and fairness with respect to the <span class="search-hit mathjax">AI</span> applications. The definition of fairness for such applications varies based on their domain of application. The policies governing the use of such machine learning system in a given context are defined by the constitutional laws of nations and regulatory policies enforced by the organizations that are involved in the usage. Fairness related laws and policies are often spread across the large documents like constitution, agreements, and organizational regulations. These <span class="search-hit mathjax">legal</span> documents have long complex sentences in order to achieve rigorousness and robustness. Automatic extraction of fairness policies, or in general, any specific kind of policies from large <span class="search-hit mathjax">legal</span> corpus can be very useful for the study of bias and fairness in the context of <span class="search-hit mathjax">AI</span> applications.
  We attempted to automatically extract fairness policies from publicly available law documents using two approaches based on semantic relatedness. The experiments reveal how classical Wordnet-based similarity and vector-based similarity differ in addressing this task. We have shown that similarity based on word vectors beats the classical approach with a large margin, whereas other vector representations of senses and sentences fail to even match the classical baseline. Further, we have presented thorough error <span class="search-hit mathjax">analysis</span> and reasoning to explain the results with appropriate examples from the dataset for deeper insights.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1809.04262v1-abstract-full').style.display = 'none'; document.getElementById('1809.04262v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 September, 2018; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2018.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1806.10018">arXiv:1806.10018</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1806.10018">pdf</a>, <a href="https://arxiv.org/format/1806.10018">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Science and Game Theory">cs.GT</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1016/j.artint.2018.12.010">10.1016/j.artint.2018.12.010 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Complexity Results for Preference Aggregation over (m)CP-nets: Pareto and Majority Voting
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lukasiewicz%2C+T">Thomas Lukasiewicz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Malizia%2C+E">Enrico Malizia</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1806.10018v1-abstract-short" style="display: inline;">
        Combinatorial preference aggregation has many applications in <span class="search-hit mathjax">AI</span>. Given the exponential nature of these preferences, compact representations are needed and ($m$)CP-nets are among the most studied ones. Sequential and global voting are two ways to aggregate preferences over CP-nets. In the former, preferences are aggregated feature-by-feature. Hence, when pre&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1806.10018v1-abstract-full').style.display = 'inline'; document.getElementById('1806.10018v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1806.10018v1-abstract-full" style="display: none;">
        Combinatorial preference aggregation has many applications in <span class="search-hit mathjax">AI</span>. Given the exponential nature of these preferences, compact representations are needed and ($m$)CP-nets are among the most studied ones. Sequential and global voting are two ways to aggregate preferences over CP-nets. In the former, preferences are aggregated feature-by-feature. Hence, when preferences have specific feature dependencies, sequential voting may exhibit voting paradoxes, i.e., it might select sub-optimal outcomes. To avoid paradoxes in sequential voting, one has often assumed the $\mathcal{O}$-<span class="search-hit mathjax">legality</span> restriction, which imposes a shared topological order among all the CP-nets. On the contrary, in global voting, CP-nets are considered as a whole during preference aggregation. For this reason, global voting is immune from paradoxes, and there is no need to impose restrictions over the CP-nets&#39; topological structure. Sequential voting over $\mathcal{O}$-<span class="search-hit mathjax">legal</span> CP-nets has extensively been investigated. On the other hand, global voting over non-$\mathcal{O}$-<span class="search-hit mathjax">legal</span> CP-nets has not carefully been analyzed, despite it was stated in the literature that a theoretical comparison between global and sequential voting was promising and a precise complexity <span class="search-hit mathjax">analysis</span> for global voting has been asked for multiple times. In quite few works, very partial results on the complexity of global voting over CP-nets have been given. We start to fill this gap by carrying out a thorough complexity <span class="search-hit mathjax">analysis</span> of Pareto and majority global voting over not necessarily $\mathcal{O}$-<span class="search-hit mathjax">legal</span> acyclic binary polynomially connected (m)CP-nets. We settle these problems in the polynomial hierarchy, and some of them in PTIME or LOGSPACE, whereas EXPTIME was the previously known upper bound for most of them. We show various tight lower bounds and matching upper bounds for problems that up to date did not have any explicit non-obvious lower bound.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1806.10018v1-abstract-full').style.display = 'none'; document.getElementById('1806.10018v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 June, 2018; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2018.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Artificial Intelligence, vol. 272, pp. 101-142, 2019
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1806.03243">arXiv:1806.03243</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1806.03243">pdf</a>, <a href="https://arxiv.org/format/1806.03243">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        In-vehicle data recording, storage and access management in autonomous vehicles
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Veitas%2C+V+K">Viktoras Kabir Veitas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Delaere%2C+S">Simon Delaere</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1806.03243v1-abstract-short" style="display: inline;">
        &hellip;for the device are still in the development internationally, but it is clear that it will be included into vehicle type-approval requirements at UNECE level. We present an <span class="search-hit mathjax">analysis</span> of the context of the usage of the EDR/AD in collaborative intelligent transport systems, related security, data provenance and privacy, other regulatory and technical issues cons&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1806.03243v1-abstract-full').style.display = 'inline'; document.getElementById('1806.03243v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1806.03243v1-abstract-full" style="display: none;">
        Transport sector is in the process of being rapidly and fundamentally reshaped by autonomous and collaborative driving technologies. This reshaping promises huge economic and social benefits as well as challenges in terms of developing and deploying secure and safe transportations systems, their smooth integration to social fabric. We have employed Policy Scan and Technology Strategy Design methodology in order to identify concrete societal expectations and problems and map them with mitigating technological availabilities in the domain of autonomous driving and smart mobility.
  Event Data Recorder for Autonomous Driving (EDR/AD) is an envisioned subsystem of a vehicular Controller Area Network which ensures the confidentiality, integrity and availability of data related to operation of a vehicle in order to permit recovery of exact situation following the occurrence of an event or on demand. The exact technical and regulatory requirements for the device are still in the development internationally, but it is clear that it will be included into vehicle type-approval requirements at UNECE level. We present an <span class="search-hit mathjax">analysis</span> of the context of the usage of the EDR/AD in collaborative intelligent transport systems, related security, data provenance and privacy, other regulatory and technical issues considering many interest groups and stakeholders involved. We present a concrete proposal for developing a EDR/AD proof of the concept prototype with clear market deployment potential and urge security researchers, vehicle manufacturers, and component suppliers to form a collaboration towards implementing important technology for making future autonomous vehicles more socially acceptable and <span class="search-hit mathjax">legally</span> compliant. Furthermore, EDR/AD technology, apart from its immediate use in autonomous driving and smart mobility domain has a potential to be extended to general autonomous robot and <span class="search-hit mathjax">AI</span> applications.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1806.03243v1-abstract-full').style.display = 'none'; document.getElementById('1806.03243v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 May, 2018; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2018.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Unpublished draft: 21 pages (with references); 8 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1804.04268">arXiv:1804.04268</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1804.04268">pdf</a>, <a href="https://arxiv.org/format/1804.04268">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Incomplete Contracting and <span class="search-hit mathjax">AI</span> Alignment
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hadfield-Menell%2C+D">Dylan Hadfield-Menell</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hadfield%2C+G">Gillian Hadfield</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1804.04268v1-abstract-short" style="display: inline;">
        We suggest that the <span class="search-hit mathjax">analysis</span> of incomplete contracting developed by law and economics researchers can provide a useful framework for understanding the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1804.04268v1-abstract-full').style.display = 'inline'; document.getElementById('1804.04268v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1804.04268v1-abstract-full" style="display: none;">
        We suggest that the <span class="search-hit mathjax">analysis</span> of incomplete contracting developed by law and economics researchers can provide a useful framework for understanding the <span class="search-hit mathjax">AI</span> alignment problem and help to generate a systematic approach to finding solutions. We first provide an overview of the incomplete contracting literature and explore parallels between this work and the problem of <span class="search-hit mathjax">AI</span> alignment. As we emphasize, misalignment between principal and agent is a core focus of economic <span class="search-hit mathjax">analysis</span>. We highlight some technical results from the economics literature on incomplete contracts that may provide insights for <span class="search-hit mathjax">AI</span> alignment researchers. Our core contribution, however, is to bring to bear an insight that economists have been urged to absorb from <span class="search-hit mathjax">legal</span> scholars and other behavioral scientists: the fact that human contracting is supported by substantial amounts of external structure, such as generally available institutions (culture, law) that can supply implied terms to fill the gaps in incomplete contracts. We propose a research agenda for <span class="search-hit mathjax">AI</span> alignment work that focuses on the problem of how to build <span class="search-hit mathjax">AI</span> that can replicate the human cognitive processes that connect individual incomplete contracts with this supporting external structure.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1804.04268v1-abstract-full').style.display = 'none'; document.getElementById('1804.04268v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 April, 2018; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2018.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1709.00396">arXiv:1709.00396</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1709.00396">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Smile for the Camera: Privacy and Policy Implications of Emotion <span class="search-hit mathjax">AI</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sedenberg%2C+E">Elaine Sedenberg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chuang%2C+J">John Chuang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1709.00396v1-abstract-short" style="display: inline;">
        The introduction of artificial intelligence (<span class="search-hit mathjax">AI</span>) on visual images for emotional&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1709.00396v1-abstract-full').style.display = 'inline'; document.getElementById('1709.00396v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1709.00396v1-abstract-full" style="display: none;">
        The introduction of artificial intelligence (<span class="search-hit mathjax">AI</span>) on visual images for emotional <span class="search-hit mathjax">analysis</span> obliterates the natural subjectivity and contextual dependence of our facial displays. Emotion <span class="search-hit mathjax">AI</span> places itself as an algorithmic lens on our digital artifacts and real-time interactions, creating the illusion of a new, objective class of data: our emotional and mental states. Building upon a rich network of existing public photographs--as well as fresh feeds from surveillance footage or smart phone cameras--these emotion algorithms require no additional infrastructure or improvements on image quality. In order to examine the potential policy and <span class="search-hit mathjax">legal</span> remedies for emotion <span class="search-hit mathjax">AI</span> as an emerging technology, we first establish a framework of actors, collection motivations, time scales, and space considerations that differentiates emotion <span class="search-hit mathjax">AI</span> from other algorithmic lenses. Each of these elements influences available policy remedies, and should shape continuing discussions on the antecedent conditions that make emotional <span class="search-hit mathjax">AI</span> acceptable or not in particular contexts. Based on our framework of unique elements, we examine potential available policy remedies to prevent or remediate harm. Specifically, our paper looks toward the regulatory role of the Federal Trade Commission in the US, gaps in the EU&#39;s General Data Protection Regulation (GDPR) allowing for emotion data collection, and precedent set by polygraph technologies in evidentiary and use restrictions set by law. We also examine the way social norms and adaptations could grow to also modulate broader use. Given the challenges in controlling the flow of these data, we call for further research and attention as emotion <span class="search-hit mathjax">AI</span> technology remains poised for adoption.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1709.00396v1-abstract-full').style.display = 'none'; document.getElementById('1709.00396v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 September, 2017; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2017.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1608.07398">arXiv:1608.07398</a>
        <span>&nbsp;&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.4204/EPTCS.224">10.4204/EPTCS.224 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Proceedings First Workshop on Causal Reasoning for Embedded and safety-critical Systems Technologies
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=G%C3%B6ssler%2C+G">Gregor Gössler</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sokolsky%2C+O">Oleg Sokolsky</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1608.07398v1-abstract-short" style="display: inline;">
        Formal approaches for automated causality <span class="search-hit mathjax">analysis</span>, fault localization, explanation of events, accountability and blaming have been proposed independently by several communities --- in particular,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1608.07398v1-abstract-full').style.display = 'inline'; document.getElementById('1608.07398v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1608.07398v1-abstract-full" style="display: none;">
        Formal approaches for automated causality <span class="search-hit mathjax">analysis</span>, fault localization, explanation of events, accountability and blaming have been proposed independently by several communities --- in particular, <span class="search-hit mathjax">AI</span>, concurrency, model-based diagnosis, formal methods. Work on these topics has significantly gained speed during the last years. The goals of CREST are to bring together and foster exchange between researchers from the different communities, and to present and discuss recent advances and new ideas in the field.
  The workshop program consisted of a set of invited and contributed presentations that illustrate different techniques for, and applications of, causality <span class="search-hit mathjax">analysis</span> and fault localization.
  The program was anchored by two keynote talks. The keynote by Hana Chockler (King&#39;s College) provided a broad perspective on the application of causal reasoning based on Halpern and Pearl&#39;s definitions of actual causality to a variety of application domains ranging from formal verification to <span class="search-hit mathjax">legal</span> reasoning. The keynote by Chao Wang (Virginia Tech) concentrated on constraint-based <span class="search-hit mathjax">analysis</span> techniques for debugging and verifying concurrent programs.
  Workshop papers deal with compositional causality <span class="search-hit mathjax">analysis</span> and a wide spectrum of application for causal reasoning, such as debugging of probabilistic models, accountability and responsibility, hazard <span class="search-hit mathjax">analysis</span> in practice based on Lewis&#39; counterfactuals, and fault localization and repair.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1608.07398v1-abstract-full').style.display = 'none'; document.getElementById('1608.07398v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 August, 2016; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2016.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        EPTCS 224, 2016
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1201.1259">arXiv:1201.1259</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1201.1259">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Digital Libraries">cs.DL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Physics and Society">physics.soc-ph</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/978-3-642-16524-5_4">10.1007/978-3-642-16524-5_4 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Network <span class="search-hit mathjax">Analysis</span> of the French Environmental Code
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Boulet%2C+R">Romain Boulet</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mazzega%2C+P">Pierre Mazzega</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bourcier%2C+D">Danièle Bourcier</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1201.1259v1-abstract-short" style="display: inline;">
        We perform a detailed <span class="search-hit mathjax">analysis</span> of the network constituted by the citations in a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1201.1259v1-abstract-full').style.display = 'inline'; document.getElementById('1201.1259v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1201.1259v1-abstract-full" style="display: none;">
        We perform a detailed <span class="search-hit mathjax">analysis</span> of the network constituted by the citations in a <span class="search-hit mathjax">legal</span> code, we search for hidden structures and properties. The graph associated to the Environmental code has a small-world structure and it is partitioned in several hidden communities of articles that only partially coincide with the organization of the code as given by its table of content. Several articles are also connected with a low number of articles but are intermediate between large communities. The structure of the Environmental Code is contrasting with the reference network of all the French <span class="search-hit mathjax">Legal</span> Codes that presents a rich-club of ten codes very central to the whole French <span class="search-hit mathjax">legal</span> system, but no small-world property. This comparison shows that the structural properties of the reference network associated to a <span class="search-hit mathjax">legal</span> system strongly depends on the scale and granularity of the <span class="search-hit mathjax">analysis</span>, as is the case for many complex systems
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1201.1259v1-abstract-full').style.display = 'none'; document.getElementById('1201.1259v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 November, 2011; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2012.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax"><span class="search-hit mathjax">AI</span> Approaches to the Complexity of <span class="search-hit mathjax">Legal</span> Systems (AICOL 2009), Rotterdam : Netherlands (2009)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/cs/0106005">arXiv:cs/0106005</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/cs/0106005">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Representation of <span class="search-hit mathjax">Legal</span> Contracts
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Daskalopulu%2C+A">Aspassia Daskalopulu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sergot%2C+M">Marek Sergot</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="cs/0106005v1-abstract-short" style="display: inline;">
        The paper outlines ongoing research on logic-based tools for the <span class="search-hit mathjax">analysis</span> and representation of <span class="search-hit mathjax">legal</span> contracts of the kind frequently encountered in large-scale engineering projects and complex, long-term trading agreements. We consider both contract formation and contract performance, in each case identifying the rep&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('cs/0106005v1-abstract-full').style.display = 'inline'; document.getElementById('cs/0106005v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="cs/0106005v1-abstract-full" style="display: none;">
        The paper outlines ongoing research on logic-based tools for the <span class="search-hit mathjax">analysis</span> and representation of <span class="search-hit mathjax">legal</span> contracts of the kind frequently encountered in large-scale engineering projects and complex, long-term trading agreements. We consider both contract formation and contract performance, in each case identifying the representational issues and the prospects for providing automated support tools.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('cs/0106005v1-abstract-full').style.display = 'none'; document.getElementById('cs/0106005v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 June, 2001; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2001.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2
        
      </p>
    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        <span class="search-hit mathjax">AI</span> & Society, vol. 11, Nos 1/2, pp. 6-17, 1997
      </p>
    
  </li>

</ol>


  


      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/about">About</a></li>
          <li><a href="https://info.arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://info.arxiv.org/help/contact.html"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://info.arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/license/index.html">Copyright</a></li>
          <li><a href="https://info.arxiv.org/help/policies/privacy_policy.html">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/web_accessibility.html">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  <script src="https://static.arxiv.org/static/base/1.0.0a5/js/member_acknowledgement.js"></script>
  </body>
</html>